TRT-101401-EntropyCalibration2
pixel_values: 3c010a14
ONNXTRT_Broadcast_5676_output: 32074ebd
/model/language_model/model/layers.12/input_layernorm/Mul_output_0: 3de80632
/Gather_output_0: 3c010a14
ONNXTRT_Broadcast_3571_output: 3ae5e8d2
/Gather_1_output_0: 3c010a14
/model/language_model/model/layers.9/post_attention_layernorm/Cast_output_0: 40ff9f46
/Gather_2_output_0: 3c010a14
/model/language_model/model/layers.13/self_attn/q_norm/Mul_1_output_0: 3dc473ae
/Gather_3_output_0: 3c010a14
/model/embed_tokens/Gather_output_0: 3a3e96ce
/model/vision_model/vision_model/embeddings/Reshape_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Transpose_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_1_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_2_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Transpose_1_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_3_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_4_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Transpose_2_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_5_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_6_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Transpose_3_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Reshape_7_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Concat_output_0: 3c010a14
/model/vision_model/vision_model/embeddings/Cast_output_0: 3c010a14
backbone.model.vision_model.vision_model.embeddings.patch_embedding.weight_output: 3a123295
/model/vision_model/vision_model/embeddings/patch_embedding/Gemm_output: 3c337d65
backbone.model.vision_model.vision_model.embeddings.patch_embedding.bias_output: 3c9036fe
ONNXTRT_Broadcast_output: 3c9036fe
/model/vision_model/vision_model/embeddings/patch_embedding/Gemm_output_0: 3ccd79d9
onnx::Resize_8769_output: 3d90a68d
/model/vision_model/vision_model/embeddings/Resize_output_0: 3d5d6ba1
/model/vision_model/vision_model/embeddings/Reshape_8_output_0: 3d5d6ba1
/model/vision_model/vision_model/embeddings/Transpose_4_output_0: 3d5d6ba1
/model/vision_model/vision_model/embeddings/Cast_1_output_0: 3d5d6ba1
/model/vision_model/vision_model/embeddings/Concat_1_output_0: 3d5d6ba1
/model/language_model/model/layers.2/self_attn/k_norm/Pow_output_0: 3cb0c2c6
/model/vision_model/vision_model/embeddings/Unsqueeze_output_0: 3d5d6ba1
ONNXTRT_Broadcast_14_output: 3ccd79d9
/model/vision_model/vision_model/embeddings/Add_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Gather_output_0: 3d68fca7
/model/language_model/model/layers.4/self_attn/q_proj/MatMul_output_0: 3d33d716
/model/language_model/model/layers.5/mlp/down_proj/MatMul_output_0: 3dcbe646
ONNXTRT_Broadcast_7009_output: 3c810a14
ONNXTRT_Broadcast_6764_output: 3b18553a
/model/language_model/model/layers.3/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.14/self_attn/Add_2_output_0: 4480ff02
ONNXTRT_Broadcast_5449_output: 3d953b16
/model/language_model/model/layers.13/mlp/gate_proj/MatMul_output_0: 3d67af5a
/model/language_model/model/layers.8/self_attn/q_norm/Cast_output_0: 3dadc3be
/model/language_model/model/layers.7/self_attn/Unsqueeze_10_output_0: 3ef3d49c
/model/language_model/model/layers.7/post_attention_layernorm/Sqrt_output_0: 40546a58
/model/language_model/model/layers.7/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.2/mlp/down_proj/MatMul_output_0: 41004139
/model/language_model/model/layers.3/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.13/post_attention_layernorm/Cast_output_0: 429e66b2
/model/language_model/model/layers.12/self_attn/Mul_output_0: 3d6db596
/model/language_model/model/layers.8/post_attention_layernorm/Mul_1_output_0: 3d490945
/model/language_model/model/layers.9/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/mlp/act_fn/Sigmoid_output_0: 3bf1a9d7
/model/language_model/model/layers.7/self_attn/Concat_4_output_0: 3ef3d484
ONNXTRT_Broadcast_5983_output: 3d2962e6
/model/language_model/model/layers.7/self_attn/Neg_1_output_0: 3efc8893
ONNXTRT_Broadcast_6252_output: 3ac3af1e
onnx::MatMul_9917_output: 3b265dfc
/model/language_model/model/layers.3/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
onnx::MatMul_10018_output: 3ac3af1e
/model/vision_model/vision_model/embeddings/Slice_output_0: 3d68b08c
/model/vision_model/vision_model/embeddings/Transpose_5_output_0: 3d68b08c
/model/vision_model/vision_model/embeddings/Reshape_9_output_0: 3d68b08c
/model/language_model/model/layers.12/self_attn/Transpose_1_output_0: 3e9b2fdf
/model/language_model/model/layers.14/input_layernorm/Div_output_0: 3b1a6525
backbone.model.language_model.model.layers.2.self_attn.k_norm.weight_output: 3d657dfc
/model/language_model/model/layers.13/self_attn/Transpose_3_output_0: 3db3f66a
ONNXTRT_Broadcast_6214_output: 3c257163
ONNXTRT_Broadcast_5951_output: 3ab4a489
/model/language_model/model/layers.12/self_attn/k_norm/Cast_1_output_0: 3d3d1a09
/model/language_model/model/layers.8/post_attention_layernorm/Sqrt_output_0: 40546a03
/model/language_model/model/layers.11/self_attn/k_norm/Div_output_0: 3c3fbc78
/model/language_model/model/layers.12/self_attn/Expand_1_output_0: 3e54e1d5
ONNXTRT_Broadcast_5692_output: 3c010a14
/model/language_model/model/layers.14/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_6210_output: 32074ebd
/model/language_model/model/layers.10/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.12/self_attn/Slice_3_output_0: 3d8cb086
/model/language_model/model/layers.4/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.10/self_attn/k_norm/Mul_1_output_0: 3f0fea9f
/model/language_model/model/layers.12/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.5/mlp/up_proj/MatMul_output_0: 3cf54d8c
/model/language_model/model/layers.11/input_layernorm/Pow_output_0: 49fb7917
/model/language_model/model/layers.12/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.7/self_attn/Slice_2_output_0: 3e4c58bc
/model/language_model/model/layers.2/post_attention_layernorm/ReduceMean_output_0: 3d47ec9e
/model/language_model/model/layers.8/self_attn/Concat_3_output_0: 3e1d6b1f
/model/language_model/model/layers.4/self_attn/Reshape_1_output_0: 3d01c692
ONNXTRT_Broadcast_6246_output: 32074ebd
/model/vision_model/vision_model/embeddings/Slice_1_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Transpose_6_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Reshape_10_output_0: 3d68fca7
/model/language_model/model/layers.11/post_attention_layernorm/Mul_1_output_0: 3d736df2
/model/language_model/model/layers.9/mlp/down_proj/MatMul_output_0: 3d35203d
backbone.model.language_model.model.layers.12.self_attn.q_norm.weight_output: 3ced06de
backbone.model.language_model.model.layers.12.input_layernorm.weight_output: 3cd3cd1a
onnx::MatMul_10038_output: 3ad7e7d0
ONNXTRT_Broadcast_5423_output: 32074ebd
/model/language_model/model/layers.8/self_attn/Softmax_output_0: 3a14a953
/model/language_model/model/layers.8/self_attn/MatMul_1_output_0: 3c2e9f4e
/model/language_model/model/layers.15/self_attn/k_norm/Pow_output_0: 414455dd
/model/language_model/model/layers.8/self_attn/Transpose_output_0: 3e1d6b1f
/model/language_model/model/layers.2/self_attn/o_proj/MatMul_output_0: 3cc966e3
/model/language_model/model/layers.13/input_layernorm/ReduceMean_output_0: 44aecdf4
onnx::MatMul_9882_output: 3b0938d2
ONNXTRT_Broadcast_3548_output: 3b053bf8
/model/language_model/model/layers.12/mlp/up_proj/MatMul_output_0: 3d2e71a0
/model/language_model/model/layers.8/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.13/self_attn/q_norm/Pow_output_0: 402d9301
ONNXTRT_Broadcast_5160_output: 3c348143
/model/language_model/model/layers.7/self_attn/q_norm/Mul_1_output_0: 3e04c9ec
/model/language_model/model/layers.15/self_attn/Unsqueeze_19_output_0: 3e974f2f
/model/language_model/model/layers.9/Add_1_output_0: 40ff9f2b
/model/language_model/model/layers.6/self_attn/Neg_1_output_0: 3f302559
/model/language_model/model/layers.13/self_attn/Mul_8_output_0: 3e22898e
ONNXTRT_Broadcast_6226_output: 3c010a14
/model/language_model/model/layers.11/self_attn/Mul_3_output_0: 3d22725e
backbone.model.language_model.model.layers.6.self_attn.k_norm.weight_output: 3d8e40c2
/model/vision_model/vision_model/embeddings/Slice_2_output_0: 3d6908d4
/model/vision_model/vision_model/embeddings/Transpose_7_output_0: 3d6908d4
/model/vision_model/vision_model/embeddings/Reshape_11_output_0: 3d6908d4
/model/language_model/model/layers.3/self_attn/Slice_3_output_0: 3f3dbb6c
/model/language_model/model/layers.12/self_attn/k_norm/Cast_output_0: 3ef4d723
/model/language_model/model/layers.12/self_attn/q_norm/ReduceMean_output_0: 3f2d0426
/model/language_model/model/layers.12/self_attn/q_norm/Pow_output_0: 40bf03c9
ONNXTRT_Broadcast_6233_output: 3c810a14
ONNXTRT_Broadcast_6237_output: 3c010a14
/model/language_model/model/layers.12/self_attn/q_norm/Div_output_0: 3b993d5a
/model/language_model/model/layers.12/self_attn/q_norm/Add_output_0: 3f2d0426
ONNXTRT_Broadcast_6244_output: 3c810a14
ONNXTRT_Broadcast_4898_output: 3c810a14
ONNXTRT_Broadcast_6235_output: 32074ebd
backbone.model.language_model.model.layers.9.post_attention_layernorm.weight_output: 3bfd2c59
/model/language_model/model/layers.12/self_attn/k_proj/MatMul_output_0: 3ef4d723
/model/language_model/model/layers.13/self_attn/q_norm/ReduceMean_output_0: 3eda7444
ONNXTRT_Broadcast_5096_output: 3a367841
/model/language_model/model/layers.10/self_attn/q_norm/Mul_1_output_0: 3e0ca13b
/model/language_model/model/layers.9/self_attn/Cast_5_output_0: 3a19b367
ONNXTRT_Broadcast_7045_output: 3c810a14
/model/language_model/model/layers.13/input_layernorm/Add_output_0: 44aecdf4
/model/language_model/model/layers.7/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_5974_output: 3b000d5b
/model/language_model/model/layers.12/self_attn/Unsqueeze_10_output_0: 3e9b2d41
/model/language_model/model/layers.9/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
onnx::MatMul_10009_output: 3aace0c2
ONNXTRT_Broadcast_5968_output: 32074ebd
onnx::MatMul_9894_output: 3aab7b67
/model/vision_model/vision_model/embeddings/Slice_3_output_0: 3d696a14
/model/vision_model/vision_model/embeddings/Transpose_8_output_0: 3d696a14
/model/vision_model/vision_model/embeddings/Reshape_12_output_0: 3d696a14
/model/language_model/model/layers.14/Add_output_0: 429e81c3
/model/vision_model/vision_model/embeddings/Unsqueeze_1_output_0: 3d68b08c
ONNXTRT_Broadcast_3578_output: 3c010a14
/model/vision_model/vision_model/embeddings/Unsqueeze_2_output_0: 3d68fca7
/model/language_model/model/layers.11/self_attn/Mul_2_output_0: 3e0cc566
/model/vision_model/vision_model/embeddings/Unsqueeze_3_output_0: 3d6908d4
/model/language_model/model/layers.9/mlp/gate_proj/MatMul_output_0: 3d5df1f3
/model/vision_model/vision_model/embeddings/Unsqueeze_4_output_0: 3d696a14
/model/vision_model/vision_model/embeddings/Concat_2_output_0: 3d68fca7
/model/language_model/model/layers.14/self_attn/Neg_1_output_0: 3d9f31dc
ONNXTRT_Broadcast_6241_output: 3b092316
onnx::MatMul_10017_output: 3b092316
ONNXTRT_Broadcast_6481_output: 3c184214
/model/language_model/model/layers.10/self_attn/Transpose_output_0: 3e0ca13b
/model/language_model/model/layers.12/self_attn/Cast_5_output_0: 3a400000
backbone.model.language_model.model.layers.13.post_attention_layernorm.weight_output: 3c48a6fe
/model/language_model/model/layers.6/self_attn/k_norm/Constant_output_0_output: 3c810a14
onnx::MatMul_10071_output: 3aa4f0e2
/model/language_model/model/layers.2/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.15/self_attn/Mul_2_output_0: 3eab928c
/model/language_model/model/layers.10/input_layernorm/Cast_output_0: 40ff9f2b
ONNXTRT_Broadcast_6220_output: 3aace0c2
ONNXTRT_Broadcast_6431_output: 3a367841
/model/language_model/model/layers.11/self_attn/q_norm/Cast_output_0: 3e5419ec
ONNXTRT_Broadcast_4349_output: 3a8c6f1e
backbone.model.language_model.model.layers.6.input_layernorm.weight_output: 3c1745fc
/model/language_model/model/layers.9/mlp/up_proj/MatMul_output_0: 3d6f441d
/model/language_model/model/layers.7/post_attention_layernorm/ReduceMean_output_0: 44aed4e1
backbone.model.language_model.model.layers.5.input_layernorm.weight_output: 3be81163
ONNXTRT_Broadcast_6742_output: 3c810a14
/model/language_model/model/layers.11/mlp/down_proj/MatMul_output_0: 3d83b232
ONNXTRT_Broadcast_5173_output: 3ac3f6ee
onnx::MatMul_9945_output: 3b195851
ONNXTRT_Broadcast_4383_output: 3ad9e9d4
backbone.model.language_model.model.layers.3.input_layernorm.weight_output: 3beaf102
/model/language_model/model/layers.3/input_layernorm/Div_output_0: 3ca24c20
/model/language_model/model/layers.1/post_attention_layernorm/Sqrt_output_0: 3ca41faa
/model/language_model/model/layers.9/self_attn/Mul_3_output_0: 3d6851e0
/model/language_model/model/layers.4/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.8/self_attn/k_norm/Sqrt_output_0: 3d7e2b3c
/model/language_model/model/layers.3/self_attn/Reshape_output_0: 3d72cb6c
/model/language_model/model/layers.11/self_attn/Reshape_6_output_0: 3dc1336e
/model/language_model/model/layers.9/self_attn/Mul_8_output_0: 3e0ed76b
/model/language_model/model/layers.14/self_attn/Mul_1_output_0: 3d757e5b
/model/language_model/model/layers.8/self_attn/Mul_8_output_0: 3e48d9c8
/model/language_model/model/layers.13/self_attn/k_norm/Mul_1_output_0: 3db3f66a
ONNXTRT_Broadcast_5432_output: 3c810a14
/model/language_model/model/layers.12/self_attn/Transpose_output_0: 3d95d327
ONNXTRT_Broadcast_6239_output: 3ced06de
/model/language_model/model/layers.8/self_attn/Softmax_output: 3a14a953
/model/language_model/model/layers.15/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.15/self_attn/q_norm/Cast_output_0: 3f0973f4
/model/language_model/model/layers.14/post_attention_layernorm/Cast_1_output_0: 3e116d17
/model/language_model/model/layers.2/self_attn/Softmax_output: 3a814285
/model/language_model/model/layers.4/self_attn/q_norm/Pow_output_0: 3dd97b8a
/model/language_model/model/layers.9/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.12/self_attn/Reshape_7_output_0: 3cfb0776
/model/vision_model/vision_model/embeddings/Pad_output_0: 3d68fca7
/model/language_model/model/layers.14/self_attn/Slice_3_output_0: 3d9f31dc
/model/language_model/model/layers.3/self_attn/Slice_1_output_0: 3e03708e
ONNXTRT_Broadcast_6515_output: 3c010a14
/model/language_model/model/layers.10/Add_output_0: 40ffb039
/model/language_model/model/layers.6/self_attn/Cast_5_output_0: 3a7c78f2
/model/language_model/model/layers.7/input_layernorm/Mul_1_output_0: 3d3b8f3d
onnx::MatMul_9944_output: 3b2f7c99
/model/language_model/model/layers.10/self_attn/Cast_5_output_0: 3a7468d2
ONNXTRT_Broadcast_3845_output: 3c010a14
/model/language_model/model/layers.11/self_attn/Cast_4_output_0: 3a80c183
ONNXTRT_Broadcast_3546_output: 3ad9f52a
ONNXTRT_Broadcast_5966_output: 3c810a14
/model/language_model/model/layers.14/self_attn/Expand_1_output_0: 3e681d68
ONNXTRT_Broadcast_6164_output: 3a367841
/model/language_model/model/layers.11/self_attn/k_norm/Pow_output_0: 407bab6a
/model/language_model/model/layers.3/mlp/up_proj/MatMul_output_0: 3d704f27
/model/language_model/model/layers.12/mlp/act_fn/Mul_output_0: 3cb70f07
/model/language_model/model/layers.7/self_attn/Add_output_0: 3e0ad4d7
/model/language_model/model/layers.7/self_attn/Slice_1_output_0: 3e001f9a
/model/language_model/model/layers.4/self_attn/Transpose_2_output_0: 3cbadcd9
onnx::MatMul_9956_output: 3aab6c49
/model/language_model/model/layers.9/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.14/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.1/self_attn/Unsqueeze_19_output_0: 3c0d858a
/model/language_model/model/layers.12/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_5176_output: 3c810a14
onnx::MatMul_9883_output: 3b00b163
/model/language_model/model/layers.9/Add_output_0: 40ff9f46
/model/language_model/model/layers.8/post_attention_layernorm/Add_output_0: 44aed455
/model/language_model/model/layers.10/self_attn/Add_1_output_0: 3f0feba7
/model/language_model/model/layers.8/self_attn/o_proj/MatMul_output_0: 3cc2b2f0
ONNXTRT_Broadcast_6773_output: 3d4fac38
/model/language_model/model/layers.8/self_attn/Reshape_7_output_0: 3c2e9f4e
/model/language_model/model/layers.14/self_attn/Expand_output_0: 3e4fac74
/model/language_model/model/layers.11/input_layernorm/Mul_output_0: 3ded12dd
backbone.model.language_model.model.layers.14.self_attn.k_norm.weight_output: 3d094a95
/model/language_model/model/layers.6/self_attn/Slice_4_output_0: 4400f9f3
ONNXTRT_Broadcast_3554_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Neg_output_0: 3ddfdeea
ONNXTRT_Broadcast_4366_output: 32074ebd
/model/language_model/model/layers.11/post_attention_layernorm/Cast_1_output_0: 3deabecc
/model/language_model/model/layers.12/self_attn/q_proj/MatMul_output_0: 3eb0fd1b
/model/language_model/model/layers.6/self_attn/o_proj/MatMul_output_0: 3d126e61
ONNXTRT_Broadcast_5716_output: 3d258285
/model/language_model/model/layers.14/Add_1_output_0: 429e818f
/model/language_model/model/layers.5/self_attn/Unsqueeze_19_output_0: 3cb925a3
/model/language_model/model/layers.10/self_attn/Mul_3_output_0: 3d870b45
/model/language_model/model/layers.9/post_attention_layernorm/Add_output_0: 44aed0a7
/model/language_model/model/layers.8/self_attn/Reshape_1_output_0: 3de64e9d
/model/language_model/model/layers.3/self_attn/Softmax_output: 3a24c993
/model/language_model/model/layers.11/self_attn/Mul_1_output_0: 3d1e9803
/model/language_model/model/layers.2/self_attn/Reshape_2_output_0: 3c334541
/model/language_model/model/layers.14/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.10/self_attn/Unsqueeze_10_output_0: 3f0feba7
/model/language_model/model/layers.10/post_attention_layernorm/Add_output_0: 44aed2b2
/model/language_model/model/layers.9/mlp/act_fn/Sigmoid_output_0: 3c00c993
/model/language_model/model/layers.14/mlp/up_proj/MatMul_output_0: 3de52020
/model/vision_model/vision_model/embeddings/Pad_1_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Gather_6_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Transpose_10_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Reshape_15_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Reshape_16_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Transpose_11_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Reshape_17_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Concat_5_output_0: 3d68fca7
/model/language_model/model/layers.15/self_attn/k_proj/MatMul_output_0: 3f21bc78
/model/vision_model/vision_model/embeddings/Gather_7_output_0: 3d68fca7
/model/vision_model/vision_model/embeddings/Split_output_0: 3d5c5d51
/model/vision_model/vision_model/embeddings/Split_output_1: 3d68b08c
/model/vision_model/vision_model/embeddings/Split_output_2: 3d63857e
/model/vision_model/vision_model/embeddings/Split_output_3: 3d764782
/model/vision_model/vision_model/embeddings/Split_output_4: 3d5c6328
/model/vision_model/vision_model/embeddings/Split_output_5: 3d6cace5
/model/vision_model/vision_model/embeddings/Split_output_6: 3d62c87e
/model/vision_model/vision_model/embeddings/Split_output_7: 3d76c5c1
/model/vision_model/vision_model/embeddings/Split_output_8: 3d5c7cde
/model/vision_model/vision_model/embeddings/Split_output_9: 3d5a6e8a
/model/vision_model/vision_model/embeddings/Split_output_10: 3d630a83
/model/vision_model/vision_model/embeddings/Split_output_11: 3d76a69f
/model/vision_model/vision_model/embeddings/Split_output_12: 3d5c9af9
/model/vision_model/vision_model/embeddings/Split_output_13: 3d5ac9b2
/model/vision_model/vision_model/embeddings/Split_output_14: 3d63b6d6
/model/vision_model/vision_model/embeddings/Split_output_15: 3d7651b0
ONNXTRT_Broadcast_4906_output: 3ad7e54b
/model/vision_model/vision_model/embeddings/Squeeze_output_0: 3d5c5d51
ONNXTRT_Broadcast_6230_output: 3b245f2e
/model/vision_model/vision_model/embeddings/Squeeze_1_output_0: 3d68b08c
/model/language_model/model/layers.9/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/embeddings/Squeeze_2_output_0: 3d63857e
/model/language_model/model/layers.3/mlp/Mul_output_0: 3c0916ec
/model/vision_model/vision_model/embeddings/Squeeze_3_output_0: 3d764782
/model/language_model/model/layers.4/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/embeddings/Squeeze_4_output_0: 3d5c6328
/model/language_model/model/layers.13/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/embeddings/Squeeze_5_output_0: 3d6cace5
/model/language_model/model/layers.4/self_attn/q_norm/Div_output_0: 3cb36863
/model/vision_model/vision_model/embeddings/Squeeze_6_output_0: 3d62c87e
/model/language_model/model/layers.11/self_attn/q_norm/Add_output_0: 3e45eec6
/model/vision_model/vision_model/embeddings/Squeeze_7_output_0: 3d76c5c1
/model/language_model/model/layers.9/self_attn/Add_output_0: 3e11eff8
/model/vision_model/vision_model/embeddings/Squeeze_8_output_0: 3d5c7cde
ONNXTRT_Broadcast_3560_output: 3b1d6f3e
/model/vision_model/vision_model/embeddings/Squeeze_9_output_0: 3d5a6e8a
/model/language_model/model/layers.2/input_layernorm/Cast_1_output_0: 3d823dd0
/model/vision_model/vision_model/embeddings/Squeeze_10_output_0: 3d630a83
/model/language_model/model/layers.12/input_layernorm/Mul_1_output_0: 3d9953ab
/model/vision_model/vision_model/embeddings/Squeeze_11_output_0: 3d76a69f
/model/language_model/model/layers.11/self_attn/Slice_4_output_0: 4400f9f3
/model/vision_model/vision_model/embeddings/Squeeze_12_output_0: 3d5c9af9
/model/language_model/model/layers.14/self_attn/k_norm/Sqrt_output_0: 3e33e3b4
/model/vision_model/vision_model/embeddings/Squeeze_13_output_0: 3d5ac9b2
/model/language_model/model/layers.5/self_attn/Add_2_output_0: 448101f7
/model/vision_model/vision_model/embeddings/Squeeze_14_output_0: 3d63b6d6
/model/language_model/model/layers.15/self_attn/q_proj/MatMul_output_0: 3f0973f4
/model/vision_model/vision_model/embeddings/Squeeze_15_output_0: 3d7651b0
/model/vision_model/vision_model/embeddings/Reshape_18_output_0: 3d68b08c
/model/language_model/model/layers.14/self_attn/Slice_output_0: 3e0891a0
onnx::MatMul_9728_output: 3b0e3000
ONNXTRT_Broadcast_4904_output: 3d52b275
/model/language_model/model/layers.7/self_attn/Transpose_2_output_0: 3d04058d
/model/language_model/model/layers.10/self_attn/q_norm/Sqrt_output_0: 3ca33282
/model/language_model/model/layers.12/post_attention_layernorm/Cast_1_output_0: 3d24e6cd
/model/language_model/model/layers.15/self_attn/Mul_output_0: 3d95d491
/model/language_model/model/layers.15/self_attn/Reshape_2_output_0: 3e974f2f
/model/language_model/model/layers.12/input_layernorm/Div_output_0: 3b96c1f1
/model/language_model/model/layers.11/self_attn/Slice_2_output_0: 3e1ab47a
ONNXTRT_Broadcast_5178_output: 32074ebd
/model/language_model/model/layers.11/self_attn/Softmax_output: 3a80c183
/model/language_model/model/layers.2/self_attn/Mul_8_output_0: 3e510b22
/model/language_model/model/layers.13/self_attn/Mul_1_output_0: 3d262963
/model/language_model/model/layers.7/self_attn/v_proj/MatMul_output_0: 3d04058d
/model/language_model/model/layers.7/self_attn/Transpose_1_output_0: 3ef3d484
/model/language_model/model/layers.7/self_attn/Reshape_2_output_0: 3d04058d
/model/language_model/model/layers.6/post_attention_layernorm/Cast_output_0: 40ff6589
/model/language_model/model/layers.7/self_attn/k_norm/Mul_1_output_0: 3ef3d484
backbone.model.language_model.model.layers.7.self_attn.k_norm.weight_output: 3d7c5f3e
/model/language_model/model/layers.7/self_attn/Mul_output_0: 3dd6f810
/model/language_model/model/layers.6/self_attn/Mul_1_output_0: 3d8bd3a9
/model/language_model/model/layers.7/self_attn/k_norm/Cast_1_output_0: 3d5b4687
/model/language_model/model/layers.4/input_layernorm/Sqrt_output_0: 40546813
/model/language_model/model/layers.13/mlp/Mul_output_0: 3d8e8521
backbone.model.language_model.model.layers.13.input_layernorm.weight_output: 3cd3fefe
/model/vision_model/vision_model/embeddings/Slice_5_output_0: 3d68b08c
/model/language_model/model/layers.9/self_attn/MatMul_1_output_0: 3c97f057
/model/language_model/model/layers.15/self_attn/q_norm/Sqrt_output_0: 3e1d5ab9
/model/language_model/model/layers.4/input_layernorm/Pow_output_0: 49fabf9a
/model/language_model/model/layers.2/input_layernorm/Sqrt_output_0: 3cd90518
/model/language_model/model/layers.15/self_attn/Add_output_0: 3dc722ce
ONNXTRT_Broadcast_7007_output: 3ab3d4ea
/model/language_model/model/layers.9/input_layernorm/Mul_output_0: 3e015180
/model/language_model/model/layers.12/post_attention_layernorm/Add_output_0: 44aecd5c
/model/language_model/model/layers.2/input_layernorm/Mul_output_0: 3d823dd0
/model/language_model/model/layers.10/self_attn/Transpose_3_output_0: 3f0feba7
/model/language_model/model/layers.13/input_layernorm/Cast_1_output_0: 3d008495
/model/language_model/model/layers.4/self_attn/k_norm/Mul_1_output_0: 3f68f628
onnx::MatMul_10049_output: 3ad8cebd
/model/language_model/model/layers.11/self_attn/Softmax_output_0: 3a80c183
/model/language_model/model/layers.2/self_attn/Expand_output_0: 3f6cb2f2
/model/language_model/model/layers.11/self_attn/q_norm/Mul_output_0: 3d793a38
ONNXTRT_Broadcast_6477_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Concat_4_output_0: 3f2c1c7f
ONNXTRT_Broadcast_5421_output: 3c810a14
/model/language_model/model/layers.13/self_attn/q_norm/Sqrt_output_0: 3d724589
ONNXTRT_Broadcast_4891_output: 3c010a14
/model/language_model/model/layers.12/input_layernorm/Cast_output_0: 429e0de4
/model/language_model/model/layers.10/post_attention_layernorm/Div_output_0: 3bd6d927
/model/language_model/model/layers.7/self_attn/Cast_5_output_0: 3a7f7efe
ONNXTRT_Broadcast_5945_output: 3c010a14
/model/language_model/model/layers.12/self_attn/k_norm/Mul_output_0: 3d3d1a09
/model/vision_model/vision_model/embeddings/Slice_6_output_0: 3d68b08c
/model/vision_model/vision_model/embeddings/Reshape_19_output_0: 3d68b08c
/model/vision_model/vision_model/embeddings/Reshape_20_output_0: 3d63857e
/model/language_model/model/layers.9/post_attention_layernorm/Pow_output_0: 49fb585b
/model/language_model/model/layers.14/self_attn/q_norm/Div_output_0: 3b5afe5f
/model/language_model/model/layers.10/self_attn/Softmax_output: 3a7468d2
/model/language_model/model/layers.7/self_attn/q_norm/Cast_1_output_0: 3d648304
/model/language_model/model/layers.8/self_attn/Reshape_2_output_0: 3d8cc845
/model/language_model/model/layers.12/post_attention_layernorm/ReduceMean_output_0: 44aecd5c
/model/language_model/model/layers.15/self_attn/Slice_2_output_0: 3e8c2aae
/model/language_model/model/layers.9/self_attn/Slice_2_output_0: 3e9bd24e
/model/language_model/model/layers.4/self_attn/Softmax_output: 3a7f7efe
/model/language_model/model/layers.7/self_attn/k_norm/Sqrt_output_0: 3c614410
/model/language_model/model/layers.7/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_6740_output: 3a998c99
ONNXTRT_Broadcast_4909_output: 3c810a14
/model/language_model/model/layers.7/self_attn/Reshape_1_output_0: 3d3e9feb
/model/language_model/model/layers.7/self_attn/q_norm/Add_output_0: 3cd7466a
/model/language_model/model/layers.3/self_attn/Mul_3_output_0: 3d6de001
/model/language_model/model/layers.7/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.7/self_attn/q_norm/ReduceMean_output_0: 3cd74668
/model/language_model/model/layers.7/self_attn/q_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_4110_output: 32074ebd
/model/language_model/model/layers.7/self_attn/Transpose_output_0: 3e04c9ec
/model/language_model/model/layers.9/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_4105_output: 3b0938d2
/model/language_model/model/layers.12/self_attn/Unsqueeze_19_output_0: 3e54e1d5
/model/language_model/model/layers.14/self_attn/q_norm/ReduceMean_output_0: 3f3163a1
/model/language_model/model/layers.13/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/embeddings/Slice_7_output_0: 3d63857e
/model/language_model/model/layers.11/self_attn/Expand_1_output_0: 3dc1336e
/model/language_model/model/layers.2/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_4078_output: 3c1c68d2
/model/language_model/model/layers.8/Add_output_0: 40ff7f95
/model/language_model/model/layers.11/post_attention_layernorm/Cast_output_0: 429e0ded
onnx::MatMul_9832_output: 3aab7122
/model/language_model/model/layers.10/self_attn/Unsqueeze_19_output_0: 3d9d216c
/model/language_model/model/layers.10/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.13/Add_output_0: 429e66b2
/model/language_model/model/layers.7/self_attn/Mul_2_output_0: 3ef3d482
ONNXTRT_Broadcast_5152_output: 3a9576ad
/model/language_model/model/layers.10/self_attn/Reshape_7_output_0: 3cc72ccc
/model/language_model/model/layers.10/input_layernorm/Add_output_0: 44aed0cb
/model/language_model/model/layers.8/self_attn/Cast_4_output_0: 3a14a953
/model/language_model/model/layers.13/self_attn/Transpose_1_output_0: 3db3f66a
ONNXTRT_Broadcast_5171_output: 3c9142a5
onnx::MatMul_10103_output: 3b3c89e4
onnx::MatMul_10040_output: 3ab1068d
/model/language_model/model/layers.7/self_attn/Reshape_7_output_0: 3c7efdc6
ONNXTRT_Broadcast_5953_output: 3aa58041
ONNXTRT_Broadcast_5963_output: 3b053bf8
/model/language_model/model/layers.1/self_attn/o_proj/MatMul_output_0: 3c80c3b8
ONNXTRT_Broadcast_6222_output: 3c810a14
backbone.model.language_model.model.layers.8.input_layernorm.weight_output: 3c348143
/model/language_model/model/layers.5/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.13/self_attn/k_norm/Div_output_0: 3c0d1a96
/model/vision_model/vision_model/embeddings/Slice_8_output_0: 3d63857e
/model/vision_model/vision_model/embeddings/Reshape_21_output_0: 3d63857e
/model/vision_model/vision_model/embeddings/Reshape_22_output_0: 3d764782
/model/language_model/model/layers.9/self_attn/Neg_output_0: 3dfa3d78
/model/language_model/model/layers.15/self_attn/q_norm/Pow_output_0: 4196b6da
onnx::MatMul_10010_output: 3b245f2e
/model/language_model/model/layers.11/self_attn/Add_output_0: 3d9fe1e7
/model/language_model/model/layers.14/self_attn/Reshape_7_output_0: 3dccc1ae
/model/language_model/model/layers.2/mlp/gate_proj/MatMul_output_0: 3d95715d
/model/language_model/model/layers.10/self_attn/k_norm/Add_output_0: 3daae894
/model/language_model/model/layers.13/post_attention_layernorm/Add_output_0: 44aec77a
/model/language_model/model/layers.5/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.13/self_attn/Reshape_7_output_0: 3d40349a
/model/language_model/model/layers.13/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_6746_output: 3c010a14
/model/language_model/model/layers.7/self_attn/Reshape_4_output_0: 3ef3d49c
/model/language_model/model/layers.13/self_attn/Neg_1_output_0: 3da454da
/model/language_model/model/layers.13/self_attn/Reshape_output_0: 3e71b327
/model/language_model/model/layers.11/post_attention_layernorm/Pow_output_0: 49fba46b
/model/language_model/model/layers.15/self_attn/q_norm/Mul_1_output_0: 3dc873a4
/model/language_model/model/layers.8/input_layernorm/Cast_1_output_0: 3e01bf27
/model/language_model/model/layers.14/self_attn/Transpose_2_output_0: 3e681d68
/model/language_model/model/layers.14/self_attn/Slice_2_output_0: 3e2d3700
/model/language_model/model/layers.13/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.10/self_attn/q_norm/Mul_output_0: 3d8283a6
/model/language_model/model/layers.15/input_layernorm/Div_output_0: 3ad306cb
/model/language_model/model/layers.4/self_attn/k_norm/Div_output_0: 3d1428eb
onnx::MatMul_9978_output: 3aa58041
/model/language_model/model/layers.12/self_attn/k_norm/Add_output_0: 3eb85d4b
/model/vision_model/vision_model/embeddings/Slice_9_output_0: 3d764782
/model/language_model/model/layers.13/self_attn/Slice_1_output_0: 3de13708
ONNXTRT_Broadcast_5447_output: 3c010a14
/model/language_model/model/layers.15/self_attn/Reshape_1_output_0: 3f21bc78
/model/language_model/model/layers.2/self_attn/Reshape_output_0: 3cd3da30
/model/language_model/model/layers.10/self_attn/Expand_1_output_0: 3d9d216c
ONNXTRT_Broadcast_5162_output: 3b2c76ee
/model/language_model/model/layers.6/self_attn/Transpose_4_output_0: 3c1e72a8
ONNXTRT_Broadcast_5701_output: 32074ebd
ONNXTRT_Broadcast_6206_output: 3b3db0e2
/model/language_model/model/layers.7/post_attention_layernorm/Mul_output_0: 3e0089e5
backbone.model.language_model.model.layers.10.input_layernorm.weight_output: 3c701285
/model/language_model/model/layers.8/mlp/Mul_output_0: 3c7228ff
/model/language_model/model/layers.2/self_attn/MatMul_1_output_0: 3c190a1e
/model/language_model/model/layers.15/input_layernorm/Mul_output_0: 3e140d7e
/model/language_model/model/layers.14/input_layernorm/Add_output_0: 44aec7d0
/model/language_model/model/layers.6/self_attn/Slice_2_output_0: 3e872e0b
/model/language_model/model/layers.10/self_attn/Add_output_0: 3e1d950b
/model/language_model/model/layers.13/self_attn/k_norm/ReduceMean_output_0: 3ebe90f5
/model/language_model/model/layers.11/self_attn/q_norm/Sqrt_output_0: 3d217ccd
/model/language_model/model/layers.12/self_attn/MatMul_output_0: 3fd3d2e0
/model/language_model/model/layers.14/self_attn/k_norm/Add_output_0: 3f35f99f
/model/language_model/model/layers.13/self_attn/Add_output_0: 3dd7df58
/model/language_model/model/layers.10/input_layernorm/Mul_output_0: 3df74aa8
/model/language_model/model/layers.7/self_attn/MatMul_1_output_0: 3c7efdc6
/model/language_model/model/layers.13/mlp/down_proj/MatMul_output_0: 3e94dc0f
ONNXTRT_Broadcast_6519_output: 3ad8cebd
/model/vision_model/vision_model/embeddings/Slice_10_output_0: 3d764782
/model/vision_model/vision_model/embeddings/Reshape_23_output_0: 3d764782
/model/vision_model/vision_model/embeddings/Reshape_24_output_0: 3d6cace5
onnx::MatMul_10110_output: 3ae51143
ONNXTRT_Broadcast_6748_output: 3c48a6fe
/model/language_model/model/layers.7/input_layernorm/ReduceMean_output_0: 44aed7bf
/model/language_model/model/layers.11/self_attn/Transpose_3_output_0: 3e1ad653
/model/language_model/model/layers.11/self_attn/k_norm/ReduceMean_output_0: 3e1da6f4
backbone.model.language_model.model.layers.7.input_layernorm.weight_output: 3c1c8265
ONNXTRT_Broadcast_4893_output: 3c1c8265
/model/language_model/model/layers.7/input_layernorm/Cast_1_output_0: 3dfd64a1
/model/language_model/model/layers.2/self_attn/Transpose_4_output_0: 3c190a1e
/model/language_model/model/layers.7/input_layernorm/Mul_output_0: 3dfd64a1
/model/language_model/model/layers.7/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.13/input_layernorm/Mul_1_output_0: 3d9d3394
/model/language_model/model/layers.14/self_attn/Mul_2_output_0: 3e2d32d4
/model/language_model/model/layers.7/input_layernorm/Add_output_0: 44aed7bf
/model/language_model/model/layers.6/mlp/down_proj/MatMul_output_0: 3d4b2e6d
ONNXTRT_Broadcast_4885_output: 3a84a1c4
/model/language_model/model/layers.7/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.6/mlp/Mul_output_0: 3c80c524
/model/language_model/model/layers.6/mlp/up_proj/MatMul_output_0: 3d1576c2
ONNXTRT_Broadcast_4883_output: 3ac3c245
/model/language_model/model/layers.7/input_layernorm/Constant_2_output_0_output: 32074ebd
onnx::MatMul_9853_output: 3ac3c245
/model/language_model/model/layers.6/mlp/act_fn/Sigmoid_output_0: 3bfd5386
/model/language_model/model/layers.6/mlp/gate_proj/MatMul_output_0: 3d4d6b5d
ONNXTRT_Broadcast_4889_output: 32074ebd
ONNXTRT_Broadcast_4881_output: 3aec1c38
/model/vision_model/vision_model/embeddings/Slice_11_output_0: 3d6cace5
/model/language_model/model/layers.4/self_attn/Add_2_output_0: 44810249
ONNXTRT_Broadcast_4628_output: 3b032081
/model/language_model/model/layers.11/self_attn/MatMul_output_0: 405b2155
/model/language_model/model/layers.10/Add_1_output_0: 40ffafeb
/model/language_model/model/layers.3/self_attn/k_proj/MatMul_output_0: 3d074a7f
/model/language_model/model/layers.4/self_attn/Mul_1_output_0: 3d0b1626
/model/language_model/model/layers.8/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.8/input_layernorm/Cast_output_0: 40ff734f
/model/language_model/model/layers.3/input_layernorm/Mul_output_0: 3dcf26ad
ONNXTRT_Broadcast_6485_output: 3aeafcda
/model/language_model/model/layers.6/input_layernorm/ReduceMean_output_0: 44aed4ea
/model/language_model/model/layers.9/self_attn/MatMul_output_0: 3fc9d197
/model/language_model/model/layers.9/input_layernorm/Sqrt_output_0: 40546a12
backbone.model.language_model.model.layers.10.post_attention_layernorm.weight_output: 3c0b2336
/model/language_model/model/layers.9/self_attn/Neg_1_output_0: 3e992e04
ONNXTRT_Broadcast_5148_output: 3b00b163
/model/language_model/model/layers.1/self_attn/Softmax_output: 3a7f7efe
ONNXTRT_Broadcast_4097_output: 3c810a14
ONNXTRT_Broadcast_6780_output: 32074ebd
/model/language_model/model/layers.13/self_attn/Concat_3_output_0: 3dc473ae
ONNXTRT_Broadcast_6513_output: 32074ebd
ONNXTRT_Broadcast_5955_output: 3c810a14
/model/language_model/model/layers.14/self_attn/q_norm/Pow_output_0: 40b64e13
/model/language_model/model/layers.6/self_attn/Mul_2_output_0: 3eeaeb83
/model/language_model/model/layers.15/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Add_output_0: 3ddd5209
/model/vision_model/vision_model/embeddings/Slice_12_output_0: 3d6cace5
/model/vision_model/vision_model/embeddings/Reshape_25_output_0: 3d6cace5
/model/vision_model/vision_model/embeddings/Reshape_26_output_0: 3d62c87e
/model/language_model/model/layers.8/self_attn/k_norm/Mul_1_output_0: 3e6bdfa5
/model/language_model/model/layers.12/post_attention_layernorm/Div_output_0: 3b5b1e96
ONNXTRT_Broadcast_4875_output: 32074ebd
/model/language_model/model/layers.6/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.9/self_attn/Reshape_output_0: 3de848b0
backbone.model.language_model.model.layers.6.post_attention_layernorm.weight_output: 3bfa1871
ONNXTRT_Broadcast_4879_output: 3bfa1871
ONNXTRT_Broadcast_5712_output: 32074ebd
/model/language_model/model/layers.11/self_attn/o_proj/MatMul_output_0: 3d989961
/model/language_model/model/layers.6/post_attention_layernorm/Cast_1_output_0: 3dfdff3e
/model/language_model/model/layers.6/post_attention_layernorm/Mul_output_0: 3dfdff3e
/model/language_model/model/layers.6/post_attention_layernorm/Mul_1_output_0: 3d2dd5c7
onnx::MatMul_9700_output: 3b1d6f3e
/model/language_model/model/layers.6/post_attention_layernorm/Div_output_0: 3c2e09a2
/model/language_model/model/layers.6/post_attention_layernorm/Pow_output_0: 49fae6de
ONNXTRT_Broadcast_5694_output: 3c701285
/model/language_model/model/layers.6/post_attention_layernorm/ReduceMean_output_0: 44aed7b3
ONNXTRT_Broadcast_4873_output: 3c810a14
/model/language_model/model/layers.6/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.6/Add_output_0: 40ff6589
onnx::MatMul_9762_output: 3af33d7b
ONNXTRT_Broadcast_4871_output: 3a8f7020
onnx::MatMul_9851_output: 3a8f7020
ONNXTRT_Broadcast_3569_output: 3d204a85
/model/language_model/model/layers.6/post_attention_layernorm/Sqrt_output_0: 40546c0f
/model/language_model/model/layers.6/self_attn/Reshape_7_output_0: 3c1e72a8
/model/vision_model/vision_model/embeddings/Slice_13_output_0: 3d62c87e
/model/language_model/model/layers.6/self_attn/Slice_1_output_0: 3ddfdeea
onnx::MatMul_9800_output: 3aae98b1
ONNXTRT_Broadcast_5415_output: 3ad83224
/model/language_model/model/layers.6/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.9/self_attn/q_norm/Pow_output_0: 3f5021b8
/model/language_model/model/layers.7/self_attn/k_norm/Cast_output_0: 3d3e9feb
ONNXTRT_Broadcast_5451_output: 3aab8e1c
/model/language_model/model/layers.8/input_layernorm/Mul_output_0: 3e01bf27
/model/language_model/model/layers.9/self_attn/k_norm/Mul_1_output_0: 3e9ea5bc
/model/language_model/model/layers.11/self_attn/q_proj/MatMul_output_0: 3e5419ec
/model/language_model/model/layers.3/self_attn/q_norm/Div_output_0: 3c95feed
/model/language_model/model/layers.8/self_attn/q_norm/Mul_1_output_0: 3e1d6b1f
/model/language_model/model/layers.9/self_attn/Transpose_1_output_0: 3e9ea5bc
ONNXTRT_Broadcast_5409_output: 32074ebd
backbone.model.language_model.model.layers.9.self_attn.k_norm.weight_output: 3d953b16
/model/language_model/model/layers.14/self_attn/k_norm/ReduceMean_output_0: 3f35f99f
ONNXTRT_Broadcast_5977_output: 3c810a14
ONNXTRT_Broadcast_7034_output: 3c810a14
/model/language_model/model/layers.14/self_attn/v_proj/MatMul_output_0: 3e681d68
/model/language_model/model/layers.9/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.9/self_attn/Transpose_output_0: 3e165bfa
/model/language_model/model/layers.14/mlp/down_proj/MatMul_output_0: 3fa4ecb8
/model/language_model/model/layers.10/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.7/self_attn/Mul_3_output_0: 3d5ed0b6
ONNXTRT_Broadcast_5363_output: 3a367841
/model/language_model/model/layers.15/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/embeddings/Slice_14_output_0: 3d62c87e
/model/vision_model/vision_model/embeddings/Reshape_27_output_0: 3d62c87e
/model/vision_model/vision_model/embeddings/Reshape_28_output_0: 3d76c5c1
/model/language_model/model/layers.13/self_attn/Expand_output_0: 3db3f66a
ONNXTRT_Broadcast_3552_output: 3c810a14
ONNXTRT_Broadcast_4887_output: 3c810a14
/model/language_model/model/layers.2/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.7/mlp/gate_proj/MatMul_output_0: 3d9022a8
/model/language_model/model/layers.6/self_attn/MatMul_1_output_0: 3c1e72a8
/model/language_model/model/layers.13/self_attn/Reshape_6_output_0: 3e407804
/model/language_model/model/layers.10/self_attn/Cast_4_output_0: 3a7468d2
/model/language_model/model/layers.10/mlp/act_fn/Sigmoid_output_0: 3c010a14
/model/language_model/model/layers.6/self_attn/Cast_4_output_0: 3a7c78f2
/model/language_model/model/layers.4/self_attn/k_proj/MatMul_output_0: 3d01c692
onnx::MatMul_10069_output: 3af76912
/model/language_model/model/layers.7/Add_1_output_0: 40ff734f
/model/language_model/model/layers.6/self_attn/Softmax_output: 3a7c78f2
/model/language_model/model/layers.12/self_attn/Mul_2_output_0: 3e8156a1
ONNXTRT_Broadcast_5705_output: 3d8818a1
/model/language_model/model/layers.4/self_attn/q_norm/Cast_1_output_0: 3d557519
/model/language_model/model/layers.8/self_attn/Mul_1_output_0: 3ccebc3a
/model/language_model/model/layers.15/input_layernorm/Sqrt_output_0: 3ef6c4c5
/model/language_model/model/layers.6/self_attn/k_norm/Cast_1_output_0: 3d3ee0b7
/model/language_model/model/layers.1/self_attn/Unsqueeze_10_output_0: 3f784da5
ONNXTRT_Broadcast_6511_output: 3c810a14
/model/language_model/model/layers.7/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.6/self_attn/v_proj/MatMul_output_0: 3ca09e10
/model/language_model/model/layers.6/self_attn/Add_2_output_0: 448101d3
/model/language_model/model/layers.6/self_attn/Transpose_2_output_0: 3ca09e10
/model/vision_model/vision_model/embeddings/Slice_15_output_0: 3d76c5c1
/model/language_model/model/layers.11/self_attn/q_norm/ReduceMean_output_0: 3e3fc003
ONNXTRT_Broadcast_5144_output: 3c010a14
backbone.model.language_model.model.layers.12.post_attention_layernorm.weight_output: 3c184214
/model/language_model/model/layers.6/self_attn/MatMul_output_0: 4040207b
ONNXTRT_Broadcast_7019_output: 3aef3f3e
/model/language_model/model/layers.1/self_attn/MatMul_output_0: 40203f5b
ONNXTRT_Broadcast_3574_output: 3c810a14
/model/language_model/model/layers.1/self_attn/MatMul_1_output_0: 3bc8cfb1
/model/language_model/model/layers.11/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.3/self_attn/Reshape_1_output_0: 3d074a7f
/model/language_model/model/layers.3/self_attn/MatMul_1_output_0: 3c068415
/model/language_model/model/layers.9/self_attn/k_norm/Mul_output_0: 3d432d15
/model/language_model/model/layers.10/self_attn/Transpose_1_output_0: 3f0fea9f
/model/language_model/model/layers.6/self_attn/Slice_output_0: 3ddd8501
ONNXTRT_Broadcast_4639_output: 3b45a66d
/model/language_model/model/layers.9/self_attn/Concat_3_output_0: 3e165bfa
/model/language_model/model/layers.7/self_attn/k_norm/Div_output_0: 3ccc5a57
/model/language_model/model/layers.6/self_attn/k_norm/Cast_output_0: 3d07b641
/model/language_model/model/layers.8/self_attn/q_norm/Pow_output_0: 3f28994c
ONNXTRT_Broadcast_5972_output: 3cb78387
/model/language_model/model/layers.12/post_attention_layernorm/Mul_1_output_0: 3cf0e105
/model/language_model/model/layers.7/self_attn/Transpose_4_output_0: 3c7efdc6
ONNXTRT_Broadcast_6769_output: 32074ebd
/model/language_model/model/layers.11/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_5703_output: 3c010a14
/model/language_model/model/layers.8/input_layernorm/Mul_1_output_0: 3d1a5a46
/model/vision_model/vision_model/embeddings/Slice_16_output_0: 3d76c5c1
/model/vision_model/vision_model/embeddings/Reshape_29_output_0: 3d76c5c1
/model/vision_model/vision_model/embeddings/Reshape_30_output_0: 3d5a6e8a
/model/language_model/model/layers.6/input_layernorm/Sqrt_output_0: 40546a5e
/model/language_model/model/layers.10/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.13/self_attn/Transpose_2_output_0: 3e407804
ONNXTRT_Broadcast_4829_output: 3a367841
/model/language_model/model/layers.14/self_attn/k_norm/Constant_output_0_output: 3c810a14
onnx::MatMul_9975_output: 3b1158b1
/model/language_model/model/layers.13/self_attn/Cast_4_output_0: 3a776ede
/model/language_model/model/layers.12/input_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_4295_output: 3a367841
ONNXTRT_Broadcast_7029_output: 3d40d306
/model/language_model/model/layers.3/self_attn/Mul_1_output_0: 3d80f5cf
/model/language_model/model/layers.1/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.11/self_attn/Concat_3_output_0: 3dadf90e
/model/language_model/model/layers.12/self_attn/Add_2_output_0: 4480fecb
/model/language_model/model/layers.2/self_attn/k_norm/ReduceMean_output_0: 3b2a3996
/model/language_model/model/layers.11/input_layernorm/Cast_1_output_0: 3ded12dd
/model/language_model/model/layers.7/self_attn/Unsqueeze_19_output_0: 3d04058d
/model/language_model/model/layers.9/self_attn/Add_2_output_0: 4480fff7
/model/language_model/model/layers.13/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.10/self_attn/Mul_1_output_0: 3d87b80c
ONNXTRT_Broadcast_5961_output: 3c9c8306
onnx::MatMul_9914_output: 3ad83224
/model/language_model/model/layers.12/self_attn/k_norm/Mul_1_output_0: 3e9b2fdf
ONNXTRT_Broadcast_6698_output: 3a367841
/model/language_model/model/layers.12/mlp/act_fn/Sigmoid_output_0: 3c00c993
/model/language_model/model/layers.14/self_attn/Reshape_6_output_0: 3e681d68
/model/vision_model/vision_model/embeddings/Slice_17_output_0: 3d5a6e8a
ONNXTRT_Broadcast_5979_output: 32074ebd
ONNXTRT_Broadcast_4101_output: 3c010a14
/model/language_model/model/layers.9/self_attn/q_norm/Mul_1_output_0: 3e165bfa
/model/language_model/model/layers.11/self_attn/Slice_3_output_0: 3e1ac842
/model/language_model/model/layers.2/input_layernorm/Cast_output_0: 3e56e37e
/model/language_model/model/layers.15/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.1/self_attn/Slice_2_output_0: 3f784d53
/model/language_model/model/layers.8/self_attn/Neg_1_output_0: 3dc71f38
/model/language_model/model/layers.8/self_attn/k_norm/Cast_output_0: 3de64e9d
/model/language_model/model/layers.9/input_layernorm/ReduceMean_output_0: 44aed46d
/model/language_model/model/layers.14/self_attn/k_norm/Pow_output_0: 41146d2a
ONNXTRT_Broadcast_3836_output: 3d184a95
/model/language_model/model/layers.10/post_attention_layernorm/Mul_1_output_0: 3d54f488
ONNXTRT_Broadcast_5688_output: 3c810a14
/model/language_model/model/layers.9/self_attn/q_norm/Cast_output_0: 3de848b0
/model/language_model/model/layers.8/self_attn/Slice_output_0: 3da8709d
/model/language_model/model/layers.14/self_attn/Neg_output_0: 3de41e48
/model/language_model/model/layers.4/self_attn/q_norm/Sqrt_output_0: 3c30413b
ONNXTRT_Broadcast_6248_output: 3c010a14
/model/language_model/model/layers.4/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.12/post_attention_layernorm/Pow_output_0: 49fb2441
/model/language_model/model/layers.9/self_attn/Concat_4_output_0: 3e9ea5bc
/model/language_model/model/layers.3/self_attn/Slice_output_0: 3e016505
/model/language_model/model/layers.14/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3567_output: 3c010a14
/model/language_model/model/layers.4/self_attn/Transpose_1_output_0: 3f68f628
/model/vision_model/vision_model/embeddings/Slice_18_output_0: 3d5a6e8a
/model/vision_model/vision_model/embeddings/Reshape_31_output_0: 3d5a6e8a
/model/vision_model/vision_model/embeddings/Reshape_32_output_0: 3d630a83
/model/language_model/model/layers.4/self_attn/Mul_output_0: 3e053289
/model/language_model/model/layers.10/self_attn/Transpose_4_output_0: 3cc72ccc
/model/language_model/model/layers.4/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_4076_output: 3c010a14
backbone.model.language_model.model.layers.2.post_attention_layernorm.weight_output: 3bb3cf9f
/model/language_model/model/layers.1/self_attn/Cast_5_output_0: 3a7f7efe
/model/language_model/model/layers.1/self_attn/Transpose_4_output_0: 3bc8cfb1
backbone.model.language_model.model.layers.9.input_layernorm.weight_output: 3c7513e8
/model/language_model/model/layers.5/self_attn/q_norm/Add_output_0: 3c920e7a
backbone.model.language_model.model.layers.11.self_attn.k_norm.weight_output: 3d2962e6
/model/language_model/model/layers.5/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.8/self_attn/Mul_output_0: 3e1bb774
backbone.model.language_model.model.layers.8.self_attn.k_norm.weight_output: 3cf10953
onnx::MatMul_10070_output: 3b194f5f
/model/language_model/model/layers.10/mlp/up_proj/MatMul_output_0: 3d150fd1
onnx::MatMul_10080_output: 3acdbfaf
/model/language_model/model/layers.6/self_attn/Expand_1_output_0: 3ca09e10
/model/language_model/model/layers.14/input_layernorm/Cast_output_0: 429e669d
/model/language_model/model/layers.6/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.4/self_attn/Transpose_output_0: 3e050bfe
/model/language_model/model/layers.9/self_attn/k_norm/Cast_1_output_0: 3d432d15
/model/language_model/model/layers.8/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.8/self_attn/q_norm/Div_output_0: 3c836a8f
ONNXTRT_Broadcast_4606_output: 3c810a14
/model/language_model/model/layers.9/self_attn/k_norm/Sqrt_output_0: 3c8fd4b7
/model/language_model/model/layers.11/mlp/up_proj/MatMul_output_0: 3d48d6e7
/model/vision_model/vision_model/embeddings/Slice_19_output_0: 3d630a83
/model/language_model/model/layers.6/self_attn/Mul_output_0: 3dc16501
/model/language_model/model/layers.11/self_attn/Unsqueeze_10_output_0: 3e1ad653
onnx::MatMul_9987_output: 3ac4bf1e
/model/language_model/model/layers.6/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.1/post_attention_layernorm/ReduceMean_output_0: 3d376278
/model/language_model/model/layers.13/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Reshape_2_output_0: 3ca09e10
ONNXTRT_Broadcast_4650_output: 3aab7122
/model/language_model/model/layers.13/self_attn/MatMul_1_output_0: 3d40349a
ONNXTRT_Broadcast_5154_output: 3c810a14
/model/language_model/model/layers.6/self_attn/Transpose_1_output_0: 3f2c1c7f
/model/language_model/model/layers.4/self_attn/Reshape_2_output_0: 3cbadcd9
ONNXTRT_Broadcast_4648_output: 3d8e40c2
/model/language_model/model/layers.4/self_attn/q_norm/Add_output_0: 3c4f68a9
/model/language_model/model/layers.6/self_attn/k_norm/Mul_output_0: 3d3ee0b7
onnx::MatMul_10100_output: 3ab2c4ca
ONNXTRT_Broadcast_4103_output: 3cae8204
/model/language_model/model/layers.6/input_layernorm/Mul_output_0: 3dfb3d78
/model/language_model/model/layers.12/self_attn/Transpose_4_output_0: 3cfb0776
/model/language_model/model/layers.7/self_attn/Expand_1_output_0: 3d04058d
/model/language_model/model/layers.13/self_attn/MatMul_output_0: 3fe5e315
ONNXTRT_Broadcast_4114_output: 3d8d4204
onnx::MatMul_9913_output: 3acdfbf8
ONNXTRT_Broadcast_7027_output: 3c010a14
/model/language_model/model/layers.4/self_attn/k_norm/Sqrt_output_0: 3c25832b
/model/language_model/model/layers.4/self_attn/q_norm/Mul_output_0: 3d557519
/model/vision_model/vision_model/embeddings/Slice_20_output_0: 3d630a83
/model/vision_model/vision_model/embeddings/Reshape_33_output_0: 3d630a83
/model/vision_model/vision_model/embeddings/Reshape_34_output_0: 3d76a69f
/model/language_model/model/layers.10/post_attention_layernorm/ReduceMean_output_0: 44aed2b2
/model/language_model/model/layers.8/self_attn/Cast_5_output_0: 3a14a953
ONNXTRT_Broadcast_4112_output: 3c010a14
/model/language_model/model/layers.14/mlp/act_fn/Sigmoid_output_0: 3c010a14
/model/language_model/model/layers.3/self_attn/q_norm/Cast_1_output_0: 3d7d0422
/model/language_model/model/layers.1/mlp/Mul_output_0: 3d1bc1ef
/model/language_model/model/layers.14/self_attn/q_norm/Mul_output_0: 3d4e9853
/model/language_model/model/layers.7/self_attn/Expand_output_0: 3ef3d49c
ONNXTRT_Broadcast_4913_output: 3c010a14
/model/language_model/model/layers.14/self_attn/Mul_8_output_0: 3e1239ef
/model/language_model/model/layers.10/self_attn/k_norm/ReduceMean_output_0: 3daae894
/model/language_model/model/layers.2/input_layernorm/ReduceMean_output_0: 3db67e47
/model/language_model/model/layers.9/self_attn/Expand_1_output_0: 3d323dd6
backbone.model.language_model.model.layers.14.input_layernorm.weight_output: 3d165c38
/model/language_model/model/layers.9/post_attention_layernorm/Mul_1_output_0: 3d6e3ff2
/model/language_model/model/layers.11/input_layernorm/ReduceMean_output_0: 44aed32a
/model/language_model/model/layers.11/self_attn/Mul_output_0: 3d9bf74e
/model/language_model/model/layers.4/self_attn/Concat_4_output_0: 3f68f628
ONNXTRT_Broadcast_6218_output: 3a96764d
/model/language_model/model/layers.13/post_attention_layernorm/ReduceMean_output_0: 44aec77a
ONNXTRT_Broadcast_5707_output: 3ad9d8d2
ONNXTRT_Broadcast_4347_output: 3ad7e7d0
backbone.model.language_model.model.layers.15.self_attn.k_norm.weight_output: 3e306bc8
/model/language_model/model/layers.2/post_attention_layernorm/Add_output_0: 3d47ec9f
/model/language_model/model/layers.11/self_attn/k_norm/Cast_output_0: 3e341aac
ONNXTRT_Broadcast_3834_output: 3c010a14
/model/vision_model/vision_model/embeddings/Slice_21_output_0: 3d76a69f
/model/language_model/model/layers.13/self_attn/Slice_2_output_0: 3db3be83
/model/language_model/model/layers.6/self_attn/k_norm/Add_output_0: 3c31f188
ONNXTRT_Broadcast_4637_output: 3d62d3b7
/model/language_model/model/layers.14/self_attn/Mul_3_output_0: 3d2c0600
ONNXTRT_Broadcast_5682_output: 3b195851
ONNXTRT_Broadcast_6483_output: 3ad7e7d0
/model/language_model/model/layers.11/self_attn/q_norm/Pow_output_0: 3fdeebe7
/model/language_model/model/layers.7/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.6/self_attn/k_norm/Sqrt_output_0: 3c108dcc
/model/language_model/model/layers.15/input_layernorm/Add_output_0: 44aecd3c
ONNXTRT_Broadcast_4644_output: 32074ebd
/model/language_model/model/layers.12/self_attn/MatMul_1_output_0: 3cfb0776
/model/language_model/model/layers.6/self_attn/k_norm/Pow_output_0: 3d3f170e
/model/language_model/model/layers.6/self_attn/Reshape_1_output_0: 3d07b641
backbone.model.language_model.model.layers.6.self_attn.q_norm.weight_output: 3d62d3b7
/model/language_model/model/layers.15/input_layernorm/Cast_1_output_0: 3e140d7e
backbone.model.language_model.model.layers.15.self_attn.q_norm.weight_output: 3cae70b1
/model/language_model/model/layers.8/post_attention_layernorm/Cast_1_output_0: 3dff0383
/model/language_model/model/layers.2/self_attn/Mul_3_output_0: 3da5bc7f
/model/language_model/model/layers.6/self_attn/q_norm/Mul_output_0: 3d789504
/model/language_model/model/layers.6/self_attn/q_norm/Mul_1_output_0: 3ddfdb1f
/model/language_model/model/layers.15/self_attn/Neg_output_0: 3da0592a
/model/language_model/model/layers.6/self_attn/q_norm/Div_output_0: 3d66f8fe
ONNXTRT_Broadcast_4635_output: 3c010a14
onnx::MatMul_9831_output: 3b45a66d
/model/language_model/model/layers.6/self_attn/q_norm/Sqrt_output_0: 3c61be07
/model/vision_model/vision_model/embeddings/Slice_22_output_0: 3d76a69f
/model/vision_model/vision_model/embeddings/Reshape_35_output_0: 3d76a69f
/model/vision_model/vision_model/embeddings/Reshape_36_output_0: 3d5ac9b2
/model/language_model/model/layers.10/post_attention_layernorm/Sqrt_output_0: 40546905
/model/language_model/model/layers.1/self_attn/Softmax_output_0: 3a7f7efe
/model/language_model/model/layers.6/self_attn/Unsqueeze_19_output_0: 3ca09e10
/model/language_model/model/layers.3/self_attn/Unsqueeze_10_output_0: 3f3dba3d
ONNXTRT_Broadcast_4116_output: 3ae4f5dc
/model/language_model/model/layers.2/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.6/self_attn/k_norm/Div_output_0: 3d2b0fc7
ONNXTRT_Broadcast_4900_output: 32074ebd
/model/language_model/model/layers.15/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
onnx::MatMul_9821_output: 3af76953
/model/language_model/model/layers.7/self_attn/q_norm/Mul_output_0: 3d648304
/model/language_model/model/layers.11/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.10/self_attn/Expand_output_0: 3f0feba7
ONNXTRT_Broadcast_4090_output: 3c010a14
/model/language_model/model/layers.2/self_attn/q_norm/Mul_1_output_0: 3e14fbb5
/model/language_model/model/layers.5/post_attention_layernorm/Cast_1_output_0: 3dfd5a5b
onnx::MatMul_9976_output: 3b003dbb
/model/language_model/model/layers.14/self_attn/k_proj/MatMul_output_0: 3ed3dc33
/model/language_model/model/layers.3/self_attn/k_norm/Cast_output_0: 3d074a7f
/model/language_model/model/layers.14/self_attn/Reshape_1_output_0: 3ed3dc33
ONNXTRT_Broadcast_6487_output: 3ab1068d
/model/language_model/model/layers.12/self_attn/v_proj/MatMul_output_0: 3e54e1d5
/model/language_model/model/layers.8/mlp/act_fn/Mul_output_0: 3c3cab81
/model/language_model/model/layers.14/self_attn/k_norm/Cast_1_output_0: 3d413962
/model/language_model/model/layers.3/self_attn/Expand_output_0: 3f3dba3d
/model/language_model/model/layers.8/self_attn/Mul_2_output_0: 3e6bdecd
/model/vision_model/vision_model/embeddings/Slice_23_output_0: 3d5ac9b2
/model/language_model/model/layers.1/self_attn/Mul_8_output_0: 3e629997
/model/language_model/model/layers.6/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Reshape_output_0: 3d680110
onnx::MatMul_9696_output: 3af30a34
/model/language_model/model/layers.6/self_attn/q_norm/Pow_output_0: 3dfceb2d
ONNXTRT_Broadcast_4631_output: 3c810a14
/model/language_model/model/layers.6/self_attn/q_norm/ReduceMean_output_0: 3cbed021
/model/language_model/model/layers.9/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_7047_output: 32074ebd
/model/language_model/model/layers.2/input_layernorm/Pow_output_0: 3fc97a6f
/model/language_model/model/layers.2/post_attention_layernorm/Cast_1_output_0: 3d91954b
ONNXTRT_Broadcast_6489_output: 3c810a14
/model/language_model/model/layers.8/input_layernorm/ReduceMean_output_0: 44aed4bb
/model/language_model/model/layers.10/input_layernorm/Mul_1_output_0: 3dd41b5c
/model/language_model/model/layers.9/self_attn/Expand_output_0: 3e992ea2
/model/language_model/model/layers.2/self_attn/Mul_2_output_0: 3f6cb688
/model/language_model/model/layers.1/mlp/down_proj/MatMul_output_0: 3d6066d0
/model/language_model/model/layers.8/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.11/self_attn/Transpose_2_output_0: 3dc1336e
/model/language_model/model/layers.6/self_attn/Mul_3_output_0: 3d929ad0
/model/language_model/model/layers.6/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.10/self_attn/k_proj/MatMul_output_0: 3dfee05a
ONNXTRT_Broadcast_3536_output: 3af30a34
/model/language_model/model/layers.5/self_attn/Slice_output_0: 3e15f448
/model/language_model/model/layers.14/input_layernorm/Cast_1_output_0: 3e1766e9
onnx::MatMul_9759_output: 3ad7e9d4
/model/vision_model/vision_model/embeddings/Slice_24_output_0: 3d5ac9b2
/model/vision_model/vision_model/embeddings/Reshape_37_output_0: 3d5ac9b2
/model/vision_model/vision_model/embeddings/Reshape_38_output_0: 3d63b6d6
ONNXTRT_Broadcast_3830_output: 3c810a14
backbone.model.language_model.model.layers.3.self_attn.k_norm.weight_output: 3d30d428
backbone.model.language_model.model.layers.15.input_layernorm.weight_output: 3d40d306
backbone.model.language_model.model.layers.5.post_attention_layernorm.weight_output: 3bfa0387
/model/language_model/model/layers.4/input_layernorm/Mul_1_output_0: 3d1cef15
/model/language_model/model/layers.11/self_attn/Add_1_output_0: 3e1ad653
/model/language_model/model/layers.10/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.12/self_attn/q_norm/Cast_output_0: 3eb0fd1b
/model/language_model/model/layers.7/self_attn/q_proj/MatMul_output_0: 3da1b8fd
/model/language_model/model/layers.8/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.8/self_attn/k_norm/Div_output_0: 3cd1b757
ONNXTRT_Broadcast_5419_output: 3a887020
/model/language_model/model/layers.14/input_layernorm/ReduceMean_output_0: 44aec7d0
/model/language_model/model/layers.14/self_attn/Add_1_output_0: 3e4fac74
ONNXTRT_Broadcast_3811_output: 3bb3cf9f
/model/language_model/model/layers.7/self_attn/Concat_3_output_0: 3e04c9ec
ONNXTRT_Broadcast_5440_output: 3b4cbcda
ONNXTRT_Broadcast_6475_output: 3c810a14
backbone.model.language_model.model.layers.13.self_attn.k_norm.weight_output: 3d193bf8
/model/language_model/model/layers.11/self_attn/Slice_1_output_0: 3d948ddc
/model/language_model/model/layers.10/input_layernorm/ReduceMean_output_0: 44aed0cb
ONNXTRT_Broadcast_5947_output: 3c0b2336
/model/language_model/model/layers.10/self_attn/q_norm/ReduceMean_output_0: 3d605bcb
onnx::MatMul_9885_output: 3a9576ad
ONNXTRT_Broadcast_5690_output: 32074ebd
/model/language_model/model/layers.11/self_attn/k_norm/Add_output_0: 3e1da6f4
/model/vision_model/vision_model/embeddings/Slice_25_output_0: 3d63b6d6
/model/language_model/model/layers.12/self_attn/o_proj/MatMul_output_0: 3e62ca36
/model/language_model/model/layers.1/self_attn/Add_1_output_0: 3f784da5
/model/language_model/model/layers.10/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/self_attn/Transpose_2_output_0: 3cbdf29d
/model/language_model/model/layers.7/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.14/post_attention_layernorm/Mul_output_0: 3e116d17
/model/language_model/model/layers.14/post_attention_layernorm/Constant_output_0_output: 3c810a14
onnx::MatMul_9770_output: 3ae4f5dc
ONNXTRT_Broadcast_7025_output: 32074ebd
/model/language_model/model/layers.13/self_attn/Neg_output_0: 3de13708
/model/language_model/model/layers.2/mlp/act_fn/Sigmoid_output_0: 3be1d3a7
backbone.model.language_model.model.layers.10.self_attn.q_norm.weight_output: 3d8818a1
/model/language_model/model/layers.9/input_layernorm/Mul_1_output_0: 3db739b3
/model/language_model/model/layers.1/post_attention_layernorm/Cast_output_0: 3e0be544
/model/language_model/model/layers.14/self_attn/Cast_5_output_0: 3a7f7efe
/model/language_model/model/layers.14/mlp/Mul_output_0: 3fc33900
/model/language_model/model/layers.3/self_attn/Transpose_1_output_0: 3f3dbb6c
onnx::MatMul_9730_output: 3a8269d4
/model/language_model/model/layers.1/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_6778_output: 3c810a14
/model/language_model/model/layers.12/self_attn/Transpose_3_output_0: 3e9b2d41
/model/language_model/model/layers.1/post_attention_layernorm/Div_output_0: 3cfea5c8
/model/language_model/model/layers.6/self_attn/q_proj/MatMul_output_0: 3d680110
/model/language_model/model/layers.12/input_layernorm/ReduceMean_output_0: 44aecf48
/model/language_model/model/layers.13/self_attn/Slice_output_0: 3dbaff38
onnx::MatMul_9824_output: 3b032081
/model/vision_model/vision_model/embeddings/Slice_26_output_0: 3d63b6d6
/model/vision_model/vision_model/embeddings/Reshape_39_output_0: 3d63b6d6
/model/vision_model/vision_model/embeddings/Reshape_40_output_0: 3d7651b0
/model/language_model/model/layers.1/self_attn/Slice_3_output_0: 3e2a6b8b
/model/language_model/model/layers.11/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.9/self_attn/q_norm/Div_output_0: 3cd2ddbd
ONNXTRT_Broadcast_7042_output: 3ae51143
/model/language_model/model/layers.3/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.13/post_attention_layernorm/Mul_output_0: 3cfdfd11
/model/language_model/model/layers.6/self_attn/Transpose_3_output_0: 3f246ce7
/model/language_model/model/layers.6/self_attn/Expand_output_0: 3f246ce7
/model/language_model/model/layers.9/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.13/input_layernorm/Div_output_0: 3b1e0682
/model/language_model/model/layers.4/self_attn/Neg_1_output_0: 3f66a344
/model/language_model/model/layers.11/post_attention_layernorm/ReduceMean_output_0: 44aecf3e
/model/language_model/model/layers.3/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.6/self_attn/k_norm/ReduceMean_output_0: 3c31f181
/model/language_model/model/layers.4/mlp/gate_proj/MatMul_output_0: 3d81f559
/model/language_model/model/layers.5/self_attn/MatMul_1_output_0: 3c24678b
/model/language_model/model/layers.13/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.1/self_attn/Transpose_3_output_0: 3f784da5
/model/language_model/model/layers.2/self_attn/Slice_3_output_0: 3f6cb711
/model/language_model/model/layers.3/self_attn/Add_1_output_0: 3f3dba3d
/model/language_model/model/layers.5/self_attn/v_proj/MatMul_output_0: 3cb925a3
/model/language_model/model/layers.8/self_attn/q_norm/Mul_output_0: 3d737355
/model/language_model/model/layers.12/Add_output_0: 40ff84c6
/model/language_model/model/layers.10/post_attention_layernorm/Cast_1_output_0: 3df31eb9
/model/language_model/model/layers.1/self_attn/Expand_output_0: 3f784da5
ONNXTRT_Broadcast_4642_output: 3c810a14
/model/vision_model/vision_model/embeddings/Slice_27_output_0: 3d7651b0
ONNXTRT_Broadcast_3807_output: 32074ebd
/model/language_model/model/layers.4/self_attn/k_norm/Mul_output_0: 3d40042e
/model/language_model/model/layers.12/self_attn/Mul_3_output_0: 3d1a7fc7
/model/language_model/model/layers.6/input_layernorm/Mul_1_output_0: 3d00c19d
/model/language_model/model/layers.9/mlp/Mul_output_0: 3d17e7e7
/model/language_model/model/layers.12/input_layernorm/Sqrt_output_0: 405466f2
/model/language_model/model/layers.2/self_attn/Concat_4_output_0: 3f6cb711
/model/language_model/model/layers.15/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.1/post_attention_layernorm/Pow_output_0: 3ee398d5
/model/language_model/model/layers.1/post_attention_layernorm/Add_output_0: 3d37627b
/model/language_model/model/layers.3/self_attn/Reshape_7_output_0: 3c068415
ONNXTRT_Broadcast_3540_output: 32074ebd
onnx::MatMul_10041_output: 3b3b9234
onnx::MatMul_9761_output: 3a876cda
/model/language_model/model/layers.13/self_attn/Unsqueeze_19_output_0: 3e407804
/model/language_model/model/layers.8/self_attn/Mul_3_output_0: 3d22b29f
onnx::MatMul_10008_output: 3a96764d
ONNXTRT_Broadcast_4626_output: 3c1745fc
/model/language_model/model/layers.11/self_attn/Neg_output_0: 3d948ddc
/model/language_model/model/layers.6/input_layernorm/Cast_1_output_0: 3dfb3d78
/model/language_model/model/layers.10/self_attn/MatMul_output_0: 3fc118a6
/model/language_model/model/layers.13/self_attn/Reshape_1_output_0: 3eb41665
/model/language_model/model/layers.8/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.9/self_attn/Slice_output_0: 3e18ddf9
/model/language_model/model/layers.15/self_attn/k_norm/Cast_output_0: 3f21bc78
/model/language_model/model/layers.13/self_attn/Reshape_4_output_0: 3db3f66a
/model/vision_model/vision_model/embeddings/Slice_28_output_0: 3d7651b0
/model/vision_model/vision_model/embeddings/Reshape_41_output_0: 3d7651b0
/model/vision_model/vision_model/embeddings/Concat_6_output_0: 3d68fca7
onnx::MatMul_10111_output: 3b337912
/model/vision_model/vision_model/embeddings/Unsqueeze_9_output_0: 3d68fca7
/model/vision_model/vision_model/encoder/layers.0/layer_norm1/LayerNormalization_output_0: 3c96d161
onnx::MatMul_8921_output: 3ac7d2e6
ONNXTRT_Broadcast_1088_output: 3ac7d2e6
/model/vision_model/vision_model/encoder/layers.0/self_attn/q_proj/MatMul_output_0: 3cd70bbb
backbone.model.vision_model.vision_model.encoder.layers.0.self_attn.q_proj.bias_output: 3d479b97
ONNXTRT_Broadcast_1090_output: 3d479b97
/model/vision_model/vision_model/encoder/layers.0/self_attn/q_proj/Add_output_0: 3d51491f
onnx::MatMul_8922_output: 3ad8d76f
ONNXTRT_Broadcast_1092_output: 3ad8d76f
/model/vision_model/vision_model/encoder/layers.0/self_attn/k_proj/MatMul_output_0: 3d12c7f5
backbone.model.vision_model.vision_model.encoder.layers.0.self_attn.k_proj.bias_output: 3c7314ca
ONNXTRT_Broadcast_1094_output: 3c7314ca
/model/vision_model/vision_model/encoder/layers.0/self_attn/k_proj/Add_output_0: 3d26b033
onnx::MatMul_8923_output: 3a5adf7f
ONNXTRT_Broadcast_1096_output: 3a5adf7f
/model/vision_model/vision_model/encoder/layers.0/self_attn/v_proj/MatMul_output_0: 3c86f729
backbone.model.vision_model.vision_model.encoder.layers.0.self_attn.v_proj.bias_output: 3abc98d2
ONNXTRT_Broadcast_1098_output: 3abc98d2
/model/vision_model/vision_model/encoder/layers.0/self_attn/v_proj/Add_output_0: 3c7a182b
/model/vision_model/vision_model/encoder/layers.0/self_attn/Reshape_output_0: 3d51491f
/model/vision_model/vision_model/encoder/layers.0/self_attn/Reshape_1_output_0: 3d26b033
/model/vision_model/vision_model/encoder/layers.0/self_attn/Reshape_2_output_0: 3c7a182b
/model/vision_model/vision_model/encoder/layers.0/self_attn/Transpose_output_0: 3c7a182b
/model/vision_model/vision_model/encoder/layers.0/self_attn/Transpose_1_output_0: 3d51491f
/model/vision_model/vision_model/encoder/layers.0/self_attn/Transpose_2_output_0: 3d26b033
/model/vision_model/vision_model/encoder/layers.0/self_attn/MatMul_output_0: 3fbf2e5f
/model/vision_model/vision_model/encoder/layers.0/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1103_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.0/self_attn/Mul_output_0: 3e344259
/model/vision_model/vision_model/encoder/layers.0/self_attn/Softmax_output: 3a7b7e63
/model/vision_model/vision_model/encoder/layers.0/self_attn/Softmax_output_0: 3a7b7e63
/model/vision_model/vision_model/encoder/layers.0/self_attn/Cast_output_0: 3a7b7e63
/model/vision_model/vision_model/encoder/layers.0/self_attn/Cast_1_output_0: 3a7b7e63
/model/vision_model/vision_model/encoder/layers.0/self_attn/MatMul_1_output_0: 3bd6e2ea
/model/vision_model/vision_model/encoder/layers.0/self_attn/Transpose_3_output_0: 3bd6e2ea
/model/vision_model/vision_model/encoder/layers.0/self_attn/Reshape_3_output_0: 3bd6e2ea
onnx::MatMul_8943_output: 3a863993
ONNXTRT_Broadcast_1107_output: 3a863993
/model/vision_model/vision_model/encoder/layers.0/self_attn/out_proj/MatMul_output_0: 3cb9a9a0
backbone.model.vision_model.vision_model.encoder.layers.0.self_attn.out_proj.bias_output: 3ccdb4b9
ONNXTRT_Broadcast_1109_output: 3ccdb4b9
/model/vision_model/vision_model/encoder/layers.0/self_attn/out_proj/Add_output_0: 3d0778d7
/model/vision_model/vision_model/encoder/layers.0/Add_output_0: 3d4bc9da
/model/vision_model/vision_model/encoder/layers.0/layer_norm2/LayerNormalization_output_0: 3d47cbbb
onnx::MatMul_8944_output: 3a722347
ONNXTRT_Broadcast_1117_output: 3a722347
/model/vision_model/vision_model/encoder/layers.0/mlp/fc1/MatMul_output_0: 3cff2147
backbone.model.vision_model.vision_model.encoder.layers.0.mlp.fc1.bias_output: 3d46a58b
ONNXTRT_Broadcast_1119_output: 3d46a58b
/model/vision_model/vision_model/encoder/layers.0/mlp/fc1/Add_output_0: 3da40678
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Mul_output_0: 3f79d409
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Mul_1_output_0: 408fc023
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1121_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Mul_2_output_0: 3e4da8a3
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Add_output_0: 3e30d63d
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1123_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Mul_3_output_0: 3e0d16ef
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1125_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Add_1_output_0: 3c71f3e8
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Mul_4_output_0: 3cf271ea
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1127_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.0/mlp/activation_fn/Mul_5_output_0: 3c7271ea
onnx::MatMul_8945_output: 3aa65dfc
ONNXTRT_Broadcast_1129_output: 3aa65dfc
/model/vision_model/vision_model/encoder/layers.0/mlp/fc2/MatMul_output_0: 3db44405
backbone.model.vision_model.vision_model.encoder.layers.0.mlp.fc2.bias_output: 3d808cfa
ONNXTRT_Broadcast_1131_output: 3d808cfa
/model/vision_model/vision_model/encoder/layers.0/mlp/fc2/Add_output_0: 3d11b087
/model/vision_model/vision_model/encoder/layers.0/Add_1_output_0: 3d823d69
/model/vision_model/vision_model/encoder/layers.1/layer_norm1/LayerNormalization_output_0: 3d884afc
onnx::MatMul_8946_output: 3aae89f4
ONNXTRT_Broadcast_1139_output: 3aae89f4
/model/vision_model/vision_model/encoder/layers.1/self_attn/q_proj/MatMul_output_0: 3d4c971d
backbone.model.vision_model.vision_model.encoder.layers.1.self_attn.q_proj.bias_output: 3d164d8b
ONNXTRT_Broadcast_1141_output: 3d164d8b
/model/vision_model/vision_model/encoder/layers.1/self_attn/q_proj/Add_output_0: 3d94d002
onnx::MatMul_8947_output: 3ab4862c
ONNXTRT_Broadcast_1143_output: 3ab4862c
/model/vision_model/vision_model/encoder/layers.1/self_attn/k_proj/MatMul_output_0: 3d5cfc26
backbone.model.vision_model.vision_model.encoder.layers.1.self_attn.k_proj.bias_output: 3c2963d8
ONNXTRT_Broadcast_1145_output: 3c2963d8
/model/vision_model/vision_model/encoder/layers.1/self_attn/k_proj/Add_output_0: 3d73f9c6
onnx::MatMul_8948_output: 3a62f4ca
ONNXTRT_Broadcast_1147_output: 3a62f4ca
/model/vision_model/vision_model/encoder/layers.1/self_attn/v_proj/MatMul_output_0: 3cf51d8b
backbone.model.vision_model.vision_model.encoder.layers.1.self_attn.v_proj.bias_output: 3ad3c993
ONNXTRT_Broadcast_1149_output: 3ad3c993
/model/vision_model/vision_model/encoder/layers.1/self_attn/v_proj/Add_output_0: 3d0085f8
/model/vision_model/vision_model/encoder/layers.1/self_attn/Reshape_output_0: 3d94d002
/model/vision_model/vision_model/encoder/layers.1/self_attn/Reshape_1_output_0: 3d73f9c6
/model/vision_model/vision_model/encoder/layers.1/self_attn/Reshape_2_output_0: 3d0085f8
/model/vision_model/vision_model/encoder/layers.1/self_attn/Transpose_output_0: 3d0085f8
/model/vision_model/vision_model/encoder/layers.1/self_attn/Transpose_1_output_0: 3d94d002
/model/vision_model/vision_model/encoder/layers.1/self_attn/Transpose_2_output_0: 3d73f9c6
/model/vision_model/vision_model/encoder/layers.1/self_attn/MatMul_output_0: 4020376c
/model/vision_model/vision_model/encoder/layers.1/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1154_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.1/self_attn/Mul_output_0: 3e971042
/model/vision_model/vision_model/encoder/layers.1/self_attn/Softmax_output: 3aa88b3b
/model/vision_model/vision_model/encoder/layers.1/self_attn/Softmax_output_0: 3aa88b3b
/model/vision_model/vision_model/encoder/layers.1/self_attn/Cast_output_0: 3aa88b3b
/model/vision_model/vision_model/encoder/layers.1/self_attn/Cast_1_output_0: 3aa88b3b
/model/vision_model/vision_model/encoder/layers.1/self_attn/MatMul_1_output_0: 3c94c5f0
/model/vision_model/vision_model/encoder/layers.1/self_attn/Transpose_3_output_0: 3c94c5f0
/model/vision_model/vision_model/encoder/layers.1/self_attn/Reshape_3_output_0: 3c94c5f0
onnx::MatMul_8968_output: 3a7638f2
ONNXTRT_Broadcast_1158_output: 3a7638f2
/model/vision_model/vision_model/encoder/layers.1/self_attn/out_proj/MatMul_output_0: 3d20d081
backbone.model.vision_model.vision_model.encoder.layers.1.self_attn.out_proj.bias_output: 3d67f973
ONNXTRT_Broadcast_1160_output: 3d67f973
/model/vision_model/vision_model/encoder/layers.1/self_attn/out_proj/Add_output_0: 3d20b71f
/model/vision_model/vision_model/encoder/layers.1/Add_output_0: 3d162e14
hidden_states: 3e9b2357
ONNXTRT_Broadcast_7296_output: 3d1964a9
/model/vision_model/vision_model/encoder/layers.1/layer_norm2/LayerNormalization_output_0: 3d693133
onnx::MatMul_8969_output: 3a4bfc38
ONNXTRT_Broadcast_1168_output: 3a4bfc38
/model/vision_model/vision_model/encoder/layers.1/mlp/fc1/MatMul_output_0: 3d14a6ee
backbone.model.vision_model.vision_model.encoder.layers.1.mlp.fc1.bias_output: 3d112dab
ONNXTRT_Broadcast_1170_output: 3d112dab
/model/vision_model/vision_model/encoder/layers.1/mlp/fc1/Add_output_0: 3d6c16cb
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Mul_output_0: 3e926cb2
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Mul_1_output_0: 3ffd7a29
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1172_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Mul_2_output_0: 3db55202
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Add_output_0: 3dfeb238
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1174_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Mul_3_output_0: 3dcb35b1
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1176_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Add_1_output_0: 3c71f3e8
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Mul_4_output_0: 3cf37c0e
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1178_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.1/mlp/activation_fn/Mul_5_output_0: 3c737c0e
onnx::MatMul_8970_output: 3a995851
ONNXTRT_Broadcast_1180_output: 3a995851
/model/vision_model/vision_model/encoder/layers.1/mlp/fc2/MatMul_output_0: 3d84b9ce
backbone.model.vision_model.vision_model.encoder.layers.1.mlp.fc2.bias_output: 3ce4250a
ONNXTRT_Broadcast_1182_output: 3ce4250a
/model/vision_model/vision_model/encoder/layers.1/mlp/fc2/Add_output_0: 3cada1b3
/model/vision_model/vision_model/encoder/layers.1/Add_1_output_0: 3d3003fe
backbone.model.language_model.model.norm.weight_output: 3d1964a9
/model/language_model/model/norm/Cast_1_output_0: 3e27a1dd
/model/vision_model/vision_model/encoder/layers.2/layer_norm1/LayerNormalization_output_0: 3d95af9f
onnx::MatMul_8971_output: 3aa476ce
ONNXTRT_Broadcast_1190_output: 3aa476ce
/model/vision_model/vision_model/encoder/layers.2/self_attn/q_proj/MatMul_output_0: 3d3721b9
backbone.model.vision_model.vision_model.encoder.layers.2.self_attn.q_proj.bias_output: 3d51b9e4
ONNXTRT_Broadcast_1192_output: 3d51b9e4
/model/vision_model/vision_model/encoder/layers.2/self_attn/q_proj/Add_output_0: 3d8701f3
onnx::MatMul_8972_output: 3a9f65ab
ONNXTRT_Broadcast_1194_output: 3a9f65ab
/model/vision_model/vision_model/encoder/layers.2/self_attn/k_proj/MatMul_output_0: 3d443b75
backbone.model.vision_model.vision_model.encoder.layers.2.self_attn.k_proj.bias_output: 3c53be3c
ONNXTRT_Broadcast_1196_output: 3c53be3c
/model/vision_model/vision_model/encoder/layers.2/self_attn/k_proj/Add_output_0: 3d559f17
onnx::MatMul_8973_output: 3a4dc891
ONNXTRT_Broadcast_1198_output: 3a4dc891
/model/vision_model/vision_model/encoder/layers.2/self_attn/v_proj/MatMul_output_0: 3cb0a74f
backbone.model.vision_model.vision_model.encoder.layers.2.self_attn.v_proj.bias_output: 3ac2a030
ONNXTRT_Broadcast_1200_output: 3ac2a030
/model/vision_model/vision_model/encoder/layers.2/self_attn/v_proj/Add_output_0: 3cb03baa
/model/vision_model/vision_model/encoder/layers.2/self_attn/Reshape_output_0: 3d8701f3
/model/vision_model/vision_model/encoder/layers.2/self_attn/Reshape_1_output_0: 3d559f17
/model/vision_model/vision_model/encoder/layers.2/self_attn/Reshape_2_output_0: 3cb03baa
/model/vision_model/vision_model/encoder/layers.2/self_attn/Transpose_output_0: 3cb03baa
/model/vision_model/vision_model/encoder/layers.2/self_attn/Transpose_1_output_0: 3d8701f3
/model/vision_model/vision_model/encoder/layers.2/self_attn/Transpose_2_output_0: 3d559f17
/model/vision_model/vision_model/encoder/layers.2/self_attn/MatMul_output_0: 3fcbdd26
/model/vision_model/vision_model/encoder/layers.2/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1205_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.2/self_attn/Mul_output_0: 3e4037a4
/model/vision_model/vision_model/encoder/layers.2/self_attn/Softmax_output: 3a928d9c
/model/vision_model/vision_model/encoder/layers.2/self_attn/Softmax_output_0: 3a928d9c
/model/vision_model/vision_model/encoder/layers.2/self_attn/Cast_output_0: 3a928d9c
/model/vision_model/vision_model/encoder/layers.2/self_attn/Cast_1_output_0: 3a928d9c
/model/vision_model/vision_model/encoder/layers.2/self_attn/MatMul_1_output_0: 3c527823
/model/vision_model/vision_model/encoder/layers.2/self_attn/Transpose_3_output_0: 3c527823
/model/vision_model/vision_model/encoder/layers.2/self_attn/Reshape_3_output_0: 3c527823
onnx::MatMul_8993_output: 3ad7e9b3
ONNXTRT_Broadcast_1209_output: 3ad7e9b3
/model/vision_model/vision_model/encoder/layers.2/self_attn/out_proj/MatMul_output_0: 3c93e625
backbone.model.vision_model.vision_model.encoder.layers.2.self_attn.out_proj.bias_output: 3cc4af7f
ONNXTRT_Broadcast_1211_output: 3cc4af7f
/model/vision_model/vision_model/encoder/layers.2/self_attn/out_proj/Add_output_0: 3ccebd1e
/model/vision_model/vision_model/encoder/layers.2/Add_output_0: 3cf92478
/model/language_model/model/norm/Mul_output_0: 3e27a1dd
/model/language_model/model/norm/Div_output_0: 3aa0c0ae
/model/vision_model/vision_model/encoder/layers.2/layer_norm2/LayerNormalization_output_0: 3d6b40cb
onnx::MatMul_8994_output: 3a246204
ONNXTRT_Broadcast_1219_output: 3a246204
/model/vision_model/vision_model/encoder/layers.2/mlp/fc1/MatMul_output_0: 3d0dfb69
backbone.model.vision_model.vision_model.encoder.layers.2.mlp.fc1.bias_output: 3d1737d0
ONNXTRT_Broadcast_1221_output: 3d1737d0
/model/vision_model/vision_model/encoder/layers.2/mlp/fc1/Add_output_0: 3d42cdbd
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Mul_output_0: 3e8b15e2
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Mul_1_output_0: 3f915607
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1223_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Mul_2_output_0: 3d4fed53
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Add_output_0: 3e067b7a
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1225_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Mul_3_output_0: 3dd69809
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1227_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Add_1_output_0: 3c61d3a7
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Mul_4_output_0: 3cb38944
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1229_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.2/mlp/activation_fn/Mul_5_output_0: 3c338944
onnx::MatMul_8995_output: 3a44c5ec
ONNXTRT_Broadcast_1231_output: 3a44c5ec
/model/vision_model/vision_model/encoder/layers.2/mlp/fc2/MatMul_output_0: 3d66c10e
backbone.model.vision_model.vision_model.encoder.layers.2.mlp.fc2.bias_output: 3bf8162c
ONNXTRT_Broadcast_1233_output: 3bf8162c
/model/vision_model/vision_model/encoder/layers.2/mlp/fc2/Add_output_0: 3c9db331
/model/vision_model/vision_model/encoder/layers.2/Add_1_output_0: 3cf7268d
ONNXTRT_Broadcast_7294_output: 3c010a14
/model/language_model/model/norm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.3/layer_norm1/LayerNormalization_output_0: 3dcdfdea
onnx::MatMul_8996_output: 3a893275
ONNXTRT_Broadcast_1241_output: 3a893275
/model/vision_model/vision_model/encoder/layers.3/self_attn/q_proj/MatMul_output_0: 3d48ed54
backbone.model.vision_model.vision_model.encoder.layers.3.self_attn.q_proj.bias_output: 3d60d851
ONNXTRT_Broadcast_1243_output: 3d60d851
/model/vision_model/vision_model/encoder/layers.3/self_attn/q_proj/Add_output_0: 3db6a6d9
onnx::MatMul_8997_output: 3aa5761c
ONNXTRT_Broadcast_1245_output: 3aa5761c
/model/vision_model/vision_model/encoder/layers.3/self_attn/k_proj/MatMul_output_0: 3d49a074
backbone.model.vision_model.vision_model.encoder.layers.3.self_attn.k_proj.bias_output: 3c44aa75
ONNXTRT_Broadcast_1247_output: 3c44aa75
/model/vision_model/vision_model/encoder/layers.3/self_attn/k_proj/Add_output_0: 3d58069e
onnx::MatMul_8998_output: 3a66e5ec
ONNXTRT_Broadcast_1249_output: 3a66e5ec
/model/vision_model/vision_model/encoder/layers.3/self_attn/v_proj/MatMul_output_0: 3cb13f6e
backbone.model.vision_model.vision_model.encoder.layers.3.self_attn.v_proj.bias_output: 3ab89326
ONNXTRT_Broadcast_1251_output: 3ab89326
/model/vision_model/vision_model/encoder/layers.3/self_attn/v_proj/Add_output_0: 3cac35cc
/model/vision_model/vision_model/encoder/layers.3/self_attn/Reshape_output_0: 3db6a6d9
/model/vision_model/vision_model/encoder/layers.3/self_attn/Reshape_1_output_0: 3d58069e
/model/vision_model/vision_model/encoder/layers.3/self_attn/Reshape_2_output_0: 3cac35cc
/model/vision_model/vision_model/encoder/layers.3/self_attn/Transpose_output_0: 3cac35cc
/model/vision_model/vision_model/encoder/layers.3/self_attn/Transpose_1_output_0: 3db6a6d9
/model/vision_model/vision_model/encoder/layers.3/self_attn/Transpose_2_output_0: 3d58069e
/model/vision_model/vision_model/encoder/layers.3/self_attn/MatMul_output_0: 3fced6e5
/model/vision_model/vision_model/encoder/layers.3/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1256_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.3/self_attn/Mul_output_0: 3e4305de
/model/vision_model/vision_model/encoder/layers.3/self_attn/Softmax_output: 3a9ab40e
/model/vision_model/vision_model/encoder/layers.3/self_attn/Softmax_output_0: 3a9ab40e
/model/vision_model/vision_model/encoder/layers.3/self_attn/Cast_output_0: 3a9ab40e
/model/vision_model/vision_model/encoder/layers.3/self_attn/Cast_1_output_0: 3a9ab40e
/model/vision_model/vision_model/encoder/layers.3/self_attn/MatMul_1_output_0: 3c683aa4
/model/vision_model/vision_model/encoder/layers.3/self_attn/Transpose_3_output_0: 3c683aa4
/model/vision_model/vision_model/encoder/layers.3/self_attn/Reshape_3_output_0: 3c683aa4
onnx::MatMul_9018_output: 3a894285
ONNXTRT_Broadcast_1260_output: 3a894285
/model/vision_model/vision_model/encoder/layers.3/self_attn/out_proj/MatMul_output_0: 3c8cd25d
backbone.model.vision_model.vision_model.encoder.layers.3.self_attn.out_proj.bias_output: 3c1e5b97
ONNXTRT_Broadcast_1262_output: 3c1e5b97
/model/vision_model/vision_model/encoder/layers.3/self_attn/out_proj/Add_output_0: 3c916c4a
/model/vision_model/vision_model/encoder/layers.3/Add_output_0: 3d0823ae
/model/language_model/model/norm/Sqrt_output_0: 3f2335f3
/model/language_model/model/norm/Add_output_0: 44aed3a2
/model/vision_model/vision_model/encoder/layers.3/layer_norm2/LayerNormalization_output_0: 3d745935
onnx::MatMul_9019_output: 3a227b16
ONNXTRT_Broadcast_1270_output: 3a227b16
/model/vision_model/vision_model/encoder/layers.3/mlp/fc1/MatMul_output_0: 3cf61edb
backbone.model.vision_model.vision_model.encoder.layers.3.mlp.fc1.bias_output: 3d1635bb
ONNXTRT_Broadcast_1272_output: 3d1635bb
/model/vision_model/vision_model/encoder/layers.3/mlp/fc1/Add_output_0: 3d51ced2
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Mul_output_0: 3e926345
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Mul_1_output_0: 3faa2c45
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1274_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Mul_2_output_0: 3d7375d6
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Add_output_0: 3e260ae9
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1276_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Mul_3_output_0: 3e047a34
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1278_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Add_1_output_0: 3c6185ac
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Mul_4_output_0: 3c305df5
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1280_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.3/mlp/activation_fn/Mul_5_output_0: 3bb05df5
onnx::MatMul_9020_output: 3a6b0d5b
ONNXTRT_Broadcast_1282_output: 3a6b0d5b
/model/vision_model/vision_model/encoder/layers.3/mlp/fc2/MatMul_output_0: 3d5ee4e3
backbone.model.vision_model.vision_model.encoder.layers.3.mlp.fc2.bias_output: 3c58f4ea
ONNXTRT_Broadcast_1284_output: 3c58f4ea
/model/vision_model/vision_model/encoder/layers.3/mlp/fc2/Add_output_0: 3c921bc4
/model/vision_model/vision_model/encoder/layers.3/Add_1_output_0: 3cea566d
ONNXTRT_Broadcast_7292_output: 32074ebd
/model/language_model/model/norm/Constant_2_output_0_output: 32074ebd
/model/vision_model/vision_model/encoder/layers.4/layer_norm1/LayerNormalization_output_0: 3dce0f6a
onnx::MatMul_9021_output: 3a7b3367
ONNXTRT_Broadcast_1292_output: 3a7b3367
/model/vision_model/vision_model/encoder/layers.4/self_attn/q_proj/MatMul_output_0: 3d31fdd9
backbone.model.vision_model.vision_model.encoder.layers.4.self_attn.q_proj.bias_output: 3d923ede
ONNXTRT_Broadcast_1294_output: 3d923ede
/model/vision_model/vision_model/encoder/layers.4/self_attn/q_proj/Add_output_0: 3dcb5539
onnx::MatMul_9022_output: 3abc97bf
ONNXTRT_Broadcast_1296_output: 3abc97bf
/model/vision_model/vision_model/encoder/layers.4/self_attn/k_proj/MatMul_output_0: 3d39055a
backbone.model.vision_model.vision_model.encoder.layers.4.self_attn.k_proj.bias_output: 3c4cc275
ONNXTRT_Broadcast_1298_output: 3c4cc275
/model/vision_model/vision_model/encoder/layers.4/self_attn/k_proj/Add_output_0: 3d548616
onnx::MatMul_9023_output: 3a0938d2
ONNXTRT_Broadcast_1300_output: 3a0938d2
/model/vision_model/vision_model/encoder/layers.4/self_attn/v_proj/MatMul_output_0: 3cca9394
backbone.model.vision_model.vision_model.encoder.layers.4.self_attn.v_proj.bias_output: 3ac9b143
ONNXTRT_Broadcast_1302_output: 3ac9b143
/model/vision_model/vision_model/encoder/layers.4/self_attn/v_proj/Add_output_0: 3cc8bd29
/model/vision_model/vision_model/encoder/layers.4/self_attn/Reshape_output_0: 3dcb5539
/model/vision_model/vision_model/encoder/layers.4/self_attn/Reshape_1_output_0: 3d548616
/model/vision_model/vision_model/encoder/layers.4/self_attn/Reshape_2_output_0: 3cc8bd29
/model/vision_model/vision_model/encoder/layers.4/self_attn/Transpose_output_0: 3cc8bd29
/model/vision_model/vision_model/encoder/layers.4/self_attn/Transpose_1_output_0: 3dcb5539
/model/vision_model/vision_model/encoder/layers.4/self_attn/Transpose_2_output_0: 3d548616
/model/vision_model/vision_model/encoder/layers.4/self_attn/MatMul_output_0: 3fa96942
/model/vision_model/vision_model/encoder/layers.4/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1307_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.4/self_attn/Mul_output_0: 3e1fbb9e
/model/vision_model/vision_model/encoder/layers.4/self_attn/Softmax_output: 3a98d264
/model/vision_model/vision_model/encoder/layers.4/self_attn/Softmax_output_0: 3a98d264
/model/vision_model/vision_model/encoder/layers.4/self_attn/Cast_output_0: 3a98d264
/model/vision_model/vision_model/encoder/layers.4/self_attn/Cast_1_output_0: 3a98d264
/model/vision_model/vision_model/encoder/layers.4/self_attn/MatMul_1_output_0: 3c5e6ecd
/model/vision_model/vision_model/encoder/layers.4/self_attn/Transpose_3_output_0: 3c5e6ecd
/model/vision_model/vision_model/encoder/layers.4/self_attn/Reshape_3_output_0: 3c5e6ecd
onnx::MatMul_9043_output: 3a49b0e2
ONNXTRT_Broadcast_1311_output: 3a49b0e2
/model/vision_model/vision_model/encoder/layers.4/self_attn/out_proj/MatMul_output_0: 3caa2ef5
backbone.model.vision_model.vision_model.encoder.layers.4.self_attn.out_proj.bias_output: 3bbf34ea
ONNXTRT_Broadcast_1313_output: 3bbf34ea
/model/vision_model/vision_model/encoder/layers.4/self_attn/out_proj/Add_output_0: 3ca4bcdf
/model/vision_model/vision_model/encoder/layers.4/Add_output_0: 3ce04a64
/model/language_model/model/norm/ReduceMean_output_0: 44aed3a2
/model/language_model/model/norm/Pow_output_0: 49420ee2
/model/vision_model/vision_model/encoder/layers.4/layer_norm2/LayerNormalization_output_0: 3d927d15
onnx::MatMul_9044_output: 3a20d1a3
ONNXTRT_Broadcast_1321_output: 3a20d1a3
/model/vision_model/vision_model/encoder/layers.4/mlp/fc1/MatMul_output_0: 3d0c6c8e
backbone.model.vision_model.vision_model.encoder.layers.4.mlp.fc1.bias_output: 3d1533a7
ONNXTRT_Broadcast_1323_output: 3d1533a7
/model/vision_model/vision_model/encoder/layers.4/mlp/fc1/Add_output_0: 3d5355e2
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Mul_output_0: 3e8f2ac3
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Mul_1_output_0: 3fc0c197
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1325_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Mul_2_output_0: 3d89e27c
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Add_output_0: 3e101dcc
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1327_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Mul_3_output_0: 3de5f78c
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1329_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Add_1_output_0: 3c51b367
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Mul_4_output_0: 3c76e78b
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1331_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.4/mlp/activation_fn/Mul_5_output_0: 3bf6e78b
onnx::MatMul_9045_output: 3a29a9d4
ONNXTRT_Broadcast_1333_output: 3a29a9d4
/model/vision_model/vision_model/encoder/layers.4/mlp/fc2/MatMul_output_0: 3d47c578
backbone.model.vision_model.vision_model.encoder.layers.4.mlp.fc2.bias_output: 3b84bdbb
ONNXTRT_Broadcast_1335_output: 3b84bdbb
/model/vision_model/vision_model/encoder/layers.4/mlp/fc2/Add_output_0: 3c9ab1a1
/model/vision_model/vision_model/encoder/layers.4/Add_1_output_0: 3cdc5f70
ONNXTRT_Broadcast_7290_output: 3c810a14
/model/language_model/model/norm/Constant_output_0_output: 3c810a14
/model/vision_model/vision_model/encoder/layers.5/layer_norm1/LayerNormalization_output_0: 3de1313d
onnx::MatMul_9046_output: 3a811932
ONNXTRT_Broadcast_1343_output: 3a811932
/model/vision_model/vision_model/encoder/layers.5/self_attn/q_proj/MatMul_output_0: 3d3397e0
backbone.model.vision_model.vision_model.encoder.layers.5.self_attn.q_proj.bias_output: 3d4ac0e2
ONNXTRT_Broadcast_1345_output: 3d4ac0e2
/model/vision_model/vision_model/encoder/layers.5/self_attn/q_proj/Add_output_0: 3d9e2a1d
onnx::MatMul_9047_output: 3aab8316
ONNXTRT_Broadcast_1347_output: 3aab8316
/model/vision_model/vision_model/encoder/layers.5/self_attn/k_proj/MatMul_output_0: 3d3af5cc
backbone.model.vision_model.vision_model.encoder.layers.5.self_attn.k_proj.bias_output: 3c3a81d4
ONNXTRT_Broadcast_1349_output: 3c3a81d4
/model/vision_model/vision_model/encoder/layers.5/self_attn/k_proj/Add_output_0: 3d551ecd
onnx::MatMul_9048_output: 3a195851
ONNXTRT_Broadcast_1351_output: 3a195851
/model/vision_model/vision_model/encoder/layers.5/self_attn/v_proj/MatMul_output_0: 3cc6fdbe
backbone.model.vision_model.vision_model.encoder.layers.5.self_attn.v_proj.bias_output: 3a7810e2
ONNXTRT_Broadcast_1353_output: 3a7810e2
/model/vision_model/vision_model/encoder/layers.5/self_attn/v_proj/Add_output_0: 3cc71d6b
/model/vision_model/vision_model/encoder/layers.5/self_attn/Reshape_output_0: 3d9e2a1d
/model/vision_model/vision_model/encoder/layers.5/self_attn/Reshape_1_output_0: 3d551ecd
/model/vision_model/vision_model/encoder/layers.5/self_attn/Reshape_2_output_0: 3cc71d6b
/model/vision_model/vision_model/encoder/layers.5/self_attn/Transpose_output_0: 3cc71d6b
/model/vision_model/vision_model/encoder/layers.5/self_attn/Transpose_1_output_0: 3d9e2a1d
/model/vision_model/vision_model/encoder/layers.5/self_attn/Transpose_2_output_0: 3d551ecd
/model/vision_model/vision_model/encoder/layers.5/self_attn/MatMul_output_0: 3fc1ba70
/model/vision_model/vision_model/encoder/layers.5/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1358_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.5/self_attn/Mul_output_0: 3e36a929
/model/vision_model/vision_model/encoder/layers.5/self_attn/Softmax_output: 3a967369
/model/vision_model/vision_model/encoder/layers.5/self_attn/Softmax_output_0: 3a967369
/model/vision_model/vision_model/encoder/layers.5/self_attn/Cast_output_0: 3a967369
/model/vision_model/vision_model/encoder/layers.5/self_attn/Cast_1_output_0: 3a967369
/model/vision_model/vision_model/encoder/layers.5/self_attn/MatMul_1_output_0: 3c50262f
/model/vision_model/vision_model/encoder/layers.5/self_attn/Transpose_3_output_0: 3c50262f
/model/vision_model/vision_model/encoder/layers.5/self_attn/Reshape_3_output_0: 3c50262f
onnx::MatMul_9068_output: 3a49bfe0
ONNXTRT_Broadcast_1362_output: 3a49bfe0
/model/vision_model/vision_model/encoder/layers.5/self_attn/out_proj/MatMul_output_0: 3c6b9f3a
backbone.model.vision_model.vision_model.encoder.layers.5.self_attn.out_proj.bias_output: 3ba0b5ec
ONNXTRT_Broadcast_1364_output: 3ba0b5ec
/model/vision_model/vision_model/encoder/layers.5/self_attn/out_proj/Add_output_0: 3ca73bc2
/model/vision_model/vision_model/encoder/layers.5/Add_output_0: 3cc2381b
/model/language_model/model/norm/Cast_output_0: 410bc5fb
/model/language_model/model/layers.15/Add_1_output_0: 410bc5fb
/model/vision_model/vision_model/encoder/layers.5/layer_norm2/LayerNormalization_output_0: 3d8f1246
onnx::MatMul_9069_output: 3a076cda
ONNXTRT_Broadcast_1372_output: 3a076cda
/model/vision_model/vision_model/encoder/layers.5/mlp/fc1/MatMul_output_0: 3d0f228f
backbone.model.vision_model.vision_model.encoder.layers.5.mlp.fc1.bias_output: 3d12372e
ONNXTRT_Broadcast_1374_output: 3d12372e
/model/vision_model/vision_model/encoder/layers.5/mlp/fc1/Add_output_0: 3d69f617
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Mul_output_0: 3e82aca2
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Mul_1_output_0: 3f97e919
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1376_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Mul_2_output_0: 3d59553d
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Add_output_0: 3e0555f3
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1378_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Mul_3_output_0: 3dd4c3a5
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1380_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Add_1_output_0: 3c61d3a7
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Mul_4_output_0: 3c7629f4
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1382_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.5/mlp/activation_fn/Mul_5_output_0: 3bf629f4
onnx::MatMul_9070_output: 3a38bfbf
ONNXTRT_Broadcast_1384_output: 3a38bfbf
/model/vision_model/vision_model/encoder/layers.5/mlp/fc2/MatMul_output_0: 3cea966b
backbone.model.vision_model.vision_model.encoder.layers.5.mlp.fc2.bias_output: 3bb790c2
ONNXTRT_Broadcast_1386_output: 3bb790c2
/model/vision_model/vision_model/encoder/layers.5/mlp/fc2/Add_output_0: 3c9e3581
/model/vision_model/vision_model/encoder/layers.5/Add_1_output_0: 3cb8f5a1
/model/language_model/model/layers.15/mlp/down_proj/MatMul_output_0: 402f48a9
ONNXTRT_Broadcast_7288_output: 3ae04449
/model/vision_model/vision_model/encoder/layers.6/layer_norm1/LayerNormalization_output_0: 3dc6c413
onnx::MatMul_9071_output: 3a76166d
ONNXTRT_Broadcast_1394_output: 3a76166d
/model/vision_model/vision_model/encoder/layers.6/self_attn/q_proj/MatMul_output_0: 3d39584a
backbone.model.vision_model.vision_model.encoder.layers.6.self_attn.q_proj.bias_output: 3d54ccda
ONNXTRT_Broadcast_1396_output: 3d54ccda
/model/vision_model/vision_model/encoder/layers.6/self_attn/q_proj/Add_output_0: 3da14a27
onnx::MatMul_9072_output: 3a61f66d
ONNXTRT_Broadcast_1398_output: 3a61f66d
/model/vision_model/vision_model/encoder/layers.6/self_attn/k_proj/MatMul_output_0: 3d32f6b8
backbone.model.vision_model.vision_model.encoder.layers.6.self_attn.k_proj.bias_output: 3c449891
ONNXTRT_Broadcast_1400_output: 3c449891
/model/vision_model/vision_model/encoder/layers.6/self_attn/k_proj/Add_output_0: 3d3ad658
onnx::MatMul_9073_output: 3a2470c2
ONNXTRT_Broadcast_1402_output: 3a2470c2
/model/vision_model/vision_model/encoder/layers.6/self_attn/v_proj/MatMul_output_0: 3ce4e291
backbone.model.vision_model.vision_model.encoder.layers.6.self_attn.v_proj.bias_output: 3b25679f
ONNXTRT_Broadcast_1404_output: 3b25679f
/model/vision_model/vision_model/encoder/layers.6/self_attn/v_proj/Add_output_0: 3ce72cca
/model/vision_model/vision_model/encoder/layers.6/self_attn/Reshape_output_0: 3da14a27
/model/vision_model/vision_model/encoder/layers.6/self_attn/Reshape_1_output_0: 3d3ad658
/model/vision_model/vision_model/encoder/layers.6/self_attn/Reshape_2_output_0: 3ce72cca
/model/vision_model/vision_model/encoder/layers.6/self_attn/Transpose_output_0: 3ce72cca
/model/vision_model/vision_model/encoder/layers.6/self_attn/Transpose_1_output_0: 3da14a27
/model/vision_model/vision_model/encoder/layers.6/self_attn/Transpose_2_output_0: 3d3ad658
/model/vision_model/vision_model/encoder/layers.6/self_attn/MatMul_output_0: 3f69e96d
/model/vision_model/vision_model/encoder/layers.6/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1409_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.6/self_attn/Mul_output_0: 3ddc8c77
/model/vision_model/vision_model/encoder/layers.6/self_attn/Softmax_output: 3a8e5806
/model/vision_model/vision_model/encoder/layers.6/self_attn/Softmax_output_0: 3a8e5806
/model/vision_model/vision_model/encoder/layers.6/self_attn/Cast_output_0: 3a8e5806
/model/vision_model/vision_model/encoder/layers.6/self_attn/Cast_1_output_0: 3a8e5806
/model/vision_model/vision_model/encoder/layers.6/self_attn/MatMul_1_output_0: 3c907965
/model/vision_model/vision_model/encoder/layers.6/self_attn/Transpose_3_output_0: 3c907965
/model/vision_model/vision_model/encoder/layers.6/self_attn/Reshape_3_output_0: 3c907965
onnx::MatMul_9093_output: 3a0830a1
ONNXTRT_Broadcast_1413_output: 3a0830a1
/model/vision_model/vision_model/encoder/layers.6/self_attn/out_proj/MatMul_output_0: 3c9afbf8
backbone.model.vision_model.vision_model.encoder.layers.6.self_attn.out_proj.bias_output: 3b87d8b1
ONNXTRT_Broadcast_1415_output: 3b87d8b1
/model/vision_model/vision_model/encoder/layers.6/self_attn/out_proj/Add_output_0: 3ca10cc4
/model/vision_model/vision_model/encoder/layers.6/Add_output_0: 3cbbd8b5
onnx::MatMul_10133_output: 3ae04449
/model/language_model/model/layers.15/mlp/Mul_output_0: 3fb5035e
/model/vision_model/vision_model/encoder/layers.6/layer_norm2/LayerNormalization_output_0: 3d6f38ba
onnx::MatMul_9094_output: 3a158347
ONNXTRT_Broadcast_1423_output: 3a158347
/model/vision_model/vision_model/encoder/layers.6/mlp/fc1/MatMul_output_0: 3d0bdca1
backbone.model.vision_model.vision_model.encoder.layers.6.mlp.fc1.bias_output: 3d0a1ece
ONNXTRT_Broadcast_1425_output: 3d0a1ece
/model/vision_model/vision_model/encoder/layers.6/mlp/fc1/Add_output_0: 3d51364a
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Mul_output_0: 3e64a7e0
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Mul_1_output_0: 3f99fe24
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1427_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Mul_2_output_0: 3d5c4fd8
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Add_output_0: 3e04a4b0
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1429_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Mul_3_output_0: 3dd3a8cc
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1431_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Add_1_output_0: 3c71f3e8
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Mul_4_output_0: 3cbc7165
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1433_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.6/mlp/activation_fn/Mul_5_output_0: 3c3c7165
onnx::MatMul_9095_output: 39e8664d
ONNXTRT_Broadcast_1435_output: 39e8664d
/model/vision_model/vision_model/encoder/layers.6/mlp/fc2/MatMul_output_0: 3d2fa89b
backbone.model.vision_model.vision_model.encoder.layers.6.mlp.fc2.bias_output: 3c094a95
ONNXTRT_Broadcast_1437_output: 3c094a95
/model/vision_model/vision_model/encoder/layers.6/mlp/fc2/Add_output_0: 3ca113f2
/model/vision_model/vision_model/encoder/layers.6/Add_1_output_0: 3caf03be
/model/language_model/model/layers.15/mlp/up_proj/MatMul_output_0: 3e3f3a12
ONNXTRT_Broadcast_7286_output: 3af94ad6
/model/vision_model/vision_model/encoder/layers.7/layer_norm1/LayerNormalization_output_0: 3dcc5745
onnx::MatMul_9096_output: 3a9e4bb7
ONNXTRT_Broadcast_1445_output: 3a9e4bb7
/model/vision_model/vision_model/encoder/layers.7/self_attn/q_proj/MatMul_output_0: 3d2d90e1
backbone.model.vision_model.vision_model.encoder.layers.7.self_attn.q_proj.bias_output: 3d0e3000
ONNXTRT_Broadcast_1447_output: 3d0e3000
/model/vision_model/vision_model/encoder/layers.7/self_attn/q_proj/Add_output_0: 3d98040a
onnx::MatMul_9097_output: 3a653830
ONNXTRT_Broadcast_1449_output: 3a653830
/model/vision_model/vision_model/encoder/layers.7/self_attn/k_proj/MatMul_output_0: 3d2f07b1
backbone.model.vision_model.vision_model.encoder.layers.7.self_attn.k_proj.bias_output: 3c2b6bf8
ONNXTRT_Broadcast_1451_output: 3c2b6bf8
/model/vision_model/vision_model/encoder/layers.7/self_attn/k_proj/Add_output_0: 3d436533
onnx::MatMul_9098_output: 3a2b77af
ONNXTRT_Broadcast_1453_output: 3a2b77af
/model/vision_model/vision_model/encoder/layers.7/self_attn/v_proj/MatMul_output_0: 3cfcca82
backbone.model.vision_model.vision_model.encoder.layers.7.self_attn.v_proj.bias_output: 3acfd7f0
ONNXTRT_Broadcast_1455_output: 3acfd7f0
/model/vision_model/vision_model/encoder/layers.7/self_attn/v_proj/Add_output_0: 3d002665
/model/vision_model/vision_model/encoder/layers.7/self_attn/Reshape_output_0: 3d98040a
/model/vision_model/vision_model/encoder/layers.7/self_attn/Reshape_1_output_0: 3d436533
/model/vision_model/vision_model/encoder/layers.7/self_attn/Reshape_2_output_0: 3d002665
/model/vision_model/vision_model/encoder/layers.7/self_attn/Transpose_output_0: 3d002665
/model/vision_model/vision_model/encoder/layers.7/self_attn/Transpose_1_output_0: 3d98040a
/model/vision_model/vision_model/encoder/layers.7/self_attn/Transpose_2_output_0: 3d436533
/model/vision_model/vision_model/encoder/layers.7/self_attn/MatMul_output_0: 3f91bc25
/model/vision_model/vision_model/encoder/layers.7/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1460_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.7/self_attn/Mul_output_0: 3e0968c6
/model/vision_model/vision_model/encoder/layers.7/self_attn/Softmax_output: 3a8b2e8c
/model/vision_model/vision_model/encoder/layers.7/self_attn/Softmax_output_0: 3a8b2e8c
/model/vision_model/vision_model/encoder/layers.7/self_attn/Cast_output_0: 3a8b2e8c
/model/vision_model/vision_model/encoder/layers.7/self_attn/Cast_1_output_0: 3a8b2e8c
/model/vision_model/vision_model/encoder/layers.7/self_attn/MatMul_1_output_0: 3ca555f8
/model/vision_model/vision_model/encoder/layers.7/self_attn/Transpose_3_output_0: 3ca555f8
/model/vision_model/vision_model/encoder/layers.7/self_attn/Reshape_3_output_0: 3ca555f8
onnx::MatMul_9118_output: 3a227b16
ONNXTRT_Broadcast_1464_output: 3a227b16
/model/vision_model/vision_model/encoder/layers.7/self_attn/out_proj/MatMul_output_0: 3ccfc283
backbone.model.vision_model.vision_model.encoder.layers.7.self_attn.out_proj.bias_output: 3baef5ec
ONNXTRT_Broadcast_1466_output: 3baef5ec
/model/vision_model/vision_model/encoder/layers.7/self_attn/out_proj/Add_output_0: 3cc5b750
/model/vision_model/vision_model/encoder/layers.7/Add_output_0: 3cb0a1ba
onnx::MatMul_10132_output: 3af94ad6
/model/language_model/model/layers.15/mlp/act_fn/Mul_output_0: 3d958033
/model/vision_model/vision_model/encoder/layers.7/layer_norm2/LayerNormalization_output_0: 3d7c7db6
onnx::MatMul_9119_output: 3a4be9d4
ONNXTRT_Broadcast_1474_output: 3a4be9d4
/model/vision_model/vision_model/encoder/layers.7/mlp/fc1/MatMul_output_0: 3d15a246
backbone.model.vision_model.vision_model.encoder.layers.7.mlp.fc1.bias_output: 3d0f2d0a
ONNXTRT_Broadcast_1476_output: 3d0f2d0a
/model/vision_model/vision_model/encoder/layers.7/mlp/fc1/Add_output_0: 3d5a79dc
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Mul_output_0: 3e5a1f77
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Mul_1_output_0: 3f9663e0
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1478_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Mul_2_output_0: 3d572864
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Add_output_0: 3e18648e
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1480_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Mul_3_output_0: 3df32c75
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1482_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Add_1_output_0: 3c81121f
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Mul_4_output_0: 3c8d09a5
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1484_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.7/mlp/activation_fn/Mul_5_output_0: 3c0d09a5
onnx::MatMul_9120_output: 3a47c5cc
ONNXTRT_Broadcast_1486_output: 3a47c5cc
/model/vision_model/vision_model/encoder/layers.7/mlp/fc2/MatMul_output_0: 3d50aec9
backbone.model.vision_model.vision_model.encoder.layers.7.mlp.fc2.bias_output: 3b502d5b
ONNXTRT_Broadcast_1488_output: 3b502d5b
/model/vision_model/vision_model/encoder/layers.7/mlp/fc2/Add_output_0: 3cb7d72e
/model/vision_model/vision_model/encoder/layers.7/Add_1_output_0: 3cbb3c87
/model/language_model/model/layers.15/mlp/act_fn/Sigmoid_output_0: 3c010a14
/model/language_model/model/layers.15/mlp/gate_proj/MatMul_output_0: 3e44483f
/model/vision_model/vision_model/encoder/layers.8/layer_norm1/LayerNormalization_output_0: 3dfd256c
onnx::MatMul_9121_output: 3a8a39d4
ONNXTRT_Broadcast_1496_output: 3a8a39d4
/model/vision_model/vision_model/encoder/layers.8/self_attn/q_proj/MatMul_output_0: 3d40db3b
backbone.model.vision_model.vision_model.encoder.layers.8.self_attn.q_proj.bias_output: 3d318020
ONNXTRT_Broadcast_1498_output: 3d318020
/model/vision_model/vision_model/encoder/layers.8/self_attn/q_proj/Add_output_0: 3d92f6b3
onnx::MatMul_9122_output: 3a76166d
ONNXTRT_Broadcast_1500_output: 3a76166d
/model/vision_model/vision_model/encoder/layers.8/self_attn/k_proj/MatMul_output_0: 3d417817
backbone.model.vision_model.vision_model.encoder.layers.8.self_attn.k_proj.bias_output: 3c489fd0
ONNXTRT_Broadcast_1502_output: 3c489fd0
/model/vision_model/vision_model/encoder/layers.8/self_attn/k_proj/Add_output_0: 3d50370d
onnx::MatMul_9123_output: 3a0e3ddc
ONNXTRT_Broadcast_1504_output: 3a0e3ddc
/model/vision_model/vision_model/encoder/layers.8/self_attn/v_proj/MatMul_output_0: 3cf703aa
backbone.model.vision_model.vision_model.encoder.layers.8.self_attn.v_proj.bias_output: 3b2d7a34
ONNXTRT_Broadcast_1506_output: 3b2d7a34
/model/vision_model/vision_model/encoder/layers.8/self_attn/v_proj/Add_output_0: 3cf5c865
/model/vision_model/vision_model/encoder/layers.8/self_attn/Reshape_output_0: 3d92f6b3
/model/vision_model/vision_model/encoder/layers.8/self_attn/Reshape_1_output_0: 3d50370d
/model/vision_model/vision_model/encoder/layers.8/self_attn/Reshape_2_output_0: 3cf5c865
/model/vision_model/vision_model/encoder/layers.8/self_attn/Transpose_output_0: 3cf5c865
/model/vision_model/vision_model/encoder/layers.8/self_attn/Transpose_1_output_0: 3d92f6b3
/model/vision_model/vision_model/encoder/layers.8/self_attn/Transpose_2_output_0: 3d50370d
/model/vision_model/vision_model/encoder/layers.8/self_attn/MatMul_output_0: 3face2e4
/model/vision_model/vision_model/encoder/layers.8/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1511_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.8/self_attn/Mul_output_0: 3e23026d
/model/vision_model/vision_model/encoder/layers.8/self_attn/Softmax_output: 3a9a8be8
/model/vision_model/vision_model/encoder/layers.8/self_attn/Softmax_output_0: 3a9a8be8
/model/vision_model/vision_model/encoder/layers.8/self_attn/Cast_output_0: 3a9a8be8
/model/vision_model/vision_model/encoder/layers.8/self_attn/Cast_1_output_0: 3a9a8be8
/model/vision_model/vision_model/encoder/layers.8/self_attn/MatMul_1_output_0: 3c8f5873
/model/vision_model/vision_model/encoder/layers.8/self_attn/Transpose_3_output_0: 3c8f5873
/model/vision_model/vision_model/encoder/layers.8/self_attn/Reshape_3_output_0: 3c8f5873
onnx::MatMul_9143_output: 3a1ec50a
ONNXTRT_Broadcast_1515_output: 3a1ec50a
/model/vision_model/vision_model/encoder/layers.8/self_attn/out_proj/MatMul_output_0: 3c92c246
backbone.model.vision_model.vision_model.encoder.layers.8.self_attn.out_proj.bias_output: 3b2a3163
ONNXTRT_Broadcast_1517_output: 3b2a3163
/model/vision_model/vision_model/encoder/layers.8/self_attn/out_proj/Add_output_0: 3cb9309a
/model/vision_model/vision_model/encoder/layers.8/Add_output_0: 3cacd6ce
ONNXTRT_Broadcast_7284_output: 3afb6851
onnx::MatMul_10131_output: 3afb6851
/model/vision_model/vision_model/encoder/layers.8/layer_norm2/LayerNormalization_output_0: 3d961efe
onnx::MatMul_9144_output: 3a794ad6
ONNXTRT_Broadcast_1525_output: 3a794ad6
/model/vision_model/vision_model/encoder/layers.8/mlp/fc1/MatMul_output_0: 3d098a97
backbone.model.vision_model.vision_model.encoder.layers.8.mlp.fc1.bias_output: 3d01164d
ONNXTRT_Broadcast_1527_output: 3d01164d
/model/vision_model/vision_model/encoder/layers.8/mlp/fc1/Add_output_0: 3d5b19c3
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Mul_output_0: 3e51ec55
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Mul_1_output_0: 3f8dfd76
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1529_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Mul_2_output_0: 3d4b23de
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Add_output_0: 3e1003ce
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1531_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Mul_3_output_0: 3de5ce12
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1533_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Mul_4_output_0: 3cab484c
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1535_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.8/mlp/activation_fn/Mul_5_output_0: 3c2b484c
onnx::MatMul_9145_output: 3a067b36
ONNXTRT_Broadcast_1537_output: 3a067b36
/model/vision_model/vision_model/encoder/layers.8/mlp/fc2/MatMul_output_0: 3cbbdd88
backbone.model.vision_model.vision_model.encoder.layers.8.mlp.fc2.bias_output: 3b5e1163
ONNXTRT_Broadcast_1539_output: 3b5e1163
/model/vision_model/vision_model/encoder/layers.8/mlp/fc2/Add_output_0: 3ca31b81
/model/vision_model/vision_model/encoder/layers.8/Add_1_output_0: 3ca62ac3
/model/language_model/model/layers.15/post_attention_layernorm/Mul_1_output_0: 3dac32ff
ONNXTRT_Broadcast_7282_output: 3c5ed7af
/model/vision_model/vision_model/encoder/layers.9/layer_norm1/LayerNormalization_output_0: 3dec61f7
onnx::MatMul_9146_output: 3a730c99
ONNXTRT_Broadcast_1547_output: 3a730c99
/model/vision_model/vision_model/encoder/layers.9/self_attn/q_proj/MatMul_output_0: 3d4f2f9f
backbone.model.vision_model.vision_model.encoder.layers.9.self_attn.q_proj.bias_output: 3d66dc08
ONNXTRT_Broadcast_1549_output: 3d66dc08
/model/vision_model/vision_model/encoder/layers.9/self_attn/q_proj/Add_output_0: 3da035d3
onnx::MatMul_9147_output: 3a2f8e5d
ONNXTRT_Broadcast_1551_output: 3a2f8e5d
/model/vision_model/vision_model/encoder/layers.9/self_attn/k_proj/MatMul_output_0: 3d3bd167
backbone.model.vision_model.vision_model.encoder.layers.9.self_attn.k_proj.bias_output: 3c347e9d
ONNXTRT_Broadcast_1553_output: 3c347e9d
/model/vision_model/vision_model/encoder/layers.9/self_attn/k_proj/Add_output_0: 3d48a385
onnx::MatMul_9148_output: 3a08374f
ONNXTRT_Broadcast_1555_output: 3a08374f
/model/vision_model/vision_model/encoder/layers.9/self_attn/v_proj/MatMul_output_0: 3cf26028
backbone.model.vision_model.vision_model.encoder.layers.9.self_attn.v_proj.bias_output: 3afb552a
ONNXTRT_Broadcast_1557_output: 3afb552a
/model/vision_model/vision_model/encoder/layers.9/self_attn/v_proj/Add_output_0: 3cec275b
/model/vision_model/vision_model/encoder/layers.9/self_attn/Reshape_output_0: 3da035d3
/model/vision_model/vision_model/encoder/layers.9/self_attn/Reshape_1_output_0: 3d48a385
/model/vision_model/vision_model/encoder/layers.9/self_attn/Reshape_2_output_0: 3cec275b
/model/vision_model/vision_model/encoder/layers.9/self_attn/Transpose_output_0: 3cec275b
/model/vision_model/vision_model/encoder/layers.9/self_attn/Transpose_1_output_0: 3da035d3
/model/vision_model/vision_model/encoder/layers.9/self_attn/Transpose_2_output_0: 3d48a385
/model/vision_model/vision_model/encoder/layers.9/self_attn/MatMul_output_0: 3f6bda9b
/model/vision_model/vision_model/encoder/layers.9/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1562_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.9/self_attn/Mul_output_0: 3dde613e
/model/vision_model/vision_model/encoder/layers.9/self_attn/Softmax_output: 3a9696b8
/model/vision_model/vision_model/encoder/layers.9/self_attn/Softmax_output_0: 3a9696b8
/model/vision_model/vision_model/encoder/layers.9/self_attn/Cast_output_0: 3a9696b8
/model/vision_model/vision_model/encoder/layers.9/self_attn/Cast_1_output_0: 3a9696b8
/model/vision_model/vision_model/encoder/layers.9/self_attn/MatMul_1_output_0: 3ca55942
/model/vision_model/vision_model/encoder/layers.9/self_attn/Transpose_3_output_0: 3ca55942
/model/vision_model/vision_model/encoder/layers.9/self_attn/Reshape_3_output_0: 3ca55942
onnx::MatMul_9168_output: 3a0938d2
ONNXTRT_Broadcast_1566_output: 3a0938d2
/model/vision_model/vision_model/encoder/layers.9/self_attn/out_proj/MatMul_output_0: 3c31419a
backbone.model.vision_model.vision_model.encoder.layers.9.self_attn.out_proj.bias_output: 3b4e4a95
ONNXTRT_Broadcast_1568_output: 3b4e4a95
/model/vision_model/vision_model/encoder/layers.9/self_attn/out_proj/Add_output_0: 3c7c8465
/model/vision_model/vision_model/encoder/layers.9/Add_output_0: 3cae7c87
backbone.model.language_model.model.layers.15.post_attention_layernorm.weight_output: 3c5ed7af
/model/language_model/model/layers.15/post_attention_layernorm/Cast_1_output_0: 3e0d3194
/model/vision_model/vision_model/encoder/layers.9/layer_norm2/LayerNormalization_output_0: 3d831cd7
onnx::MatMul_9169_output: 3b3175ec
ONNXTRT_Broadcast_1576_output: 3b3175ec
/model/vision_model/vision_model/encoder/layers.9/mlp/fc1/MatMul_output_0: 3e596d76
backbone.model.vision_model.vision_model.encoder.layers.9.mlp.fc1.bias_output: 3ce37af6
ONNXTRT_Broadcast_1578_output: 3ce37af6
/model/vision_model/vision_model/encoder/layers.9/mlp/fc1/Add_output_0: 3e53a0ff
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Mul_output_0: 421e11bc
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Mul_1_output_0: 45e0fa90
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1580_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Mul_2_output_0: 43a0ef3c
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Add_output_0: 43a10980
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1582_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Mul_3_output_0: 43807bd5
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1584_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Mul_4_output_0: 3ebd81e6
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1586_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.9/mlp/activation_fn/Mul_5_output_0: 3e3d81e6
onnx::MatMul_9170_output: 3a07ee5d
ONNXTRT_Broadcast_1588_output: 3a07ee5d
/model/vision_model/vision_model/encoder/layers.9/mlp/fc2/MatMul_output_0: 3fa697a5
backbone.model.vision_model.vision_model.encoder.layers.9.mlp.fc2.bias_output: 3b8c4871
ONNXTRT_Broadcast_1590_output: 3b8c4871
/model/vision_model/vision_model/encoder/layers.9/mlp/fc2/Add_output_0: 3fa6d567
/model/vision_model/vision_model/encoder/layers.9/Add_1_output_0: 3fa843bf
/model/language_model/model/layers.15/post_attention_layernorm/Mul_output_0: 3e0d3194
/model/language_model/model/layers.15/post_attention_layernorm/Div_output_0: 3b00c4b2
/model/vision_model/vision_model/encoder/layers.10/layer_norm1/LayerNormalization_output_0: 3ddacb76
onnx::MatMul_9171_output: 3aac76ee
ONNXTRT_Broadcast_1598_output: 3aac76ee
/model/vision_model/vision_model/encoder/layers.10/self_attn/q_proj/MatMul_output_0: 3d4ce4d4
backbone.model.vision_model.vision_model.encoder.layers.10.self_attn.q_proj.bias_output: 3d62f2e6
ONNXTRT_Broadcast_1600_output: 3d62f2e6
/model/vision_model/vision_model/encoder/layers.10/self_attn/q_proj/Add_output_0: 3dcbeda6
onnx::MatMul_9172_output: 3a6b0d5b
ONNXTRT_Broadcast_1602_output: 3a6b0d5b
/model/vision_model/vision_model/encoder/layers.10/self_attn/k_proj/MatMul_output_0: 3d50d242
backbone.model.vision_model.vision_model.encoder.layers.10.self_attn.k_proj.bias_output: 3c2872d6
ONNXTRT_Broadcast_1604_output: 3c2872d6
/model/vision_model/vision_model/encoder/layers.10/self_attn/k_proj/Add_output_0: 3d6b9e5c
onnx::MatMul_9173_output: 3a4dcb97
ONNXTRT_Broadcast_1606_output: 3a4dcb97
/model/vision_model/vision_model/encoder/layers.10/self_attn/v_proj/MatMul_output_0: 3d0aae6d
backbone.model.vision_model.vision_model.encoder.layers.10.self_attn.v_proj.bias_output: 3b2d84ca
ONNXTRT_Broadcast_1608_output: 3b2d84ca
/model/vision_model/vision_model/encoder/layers.10/self_attn/v_proj/Add_output_0: 3d0db38a
/model/vision_model/vision_model/encoder/layers.10/self_attn/Reshape_output_0: 3dcbeda6
/model/vision_model/vision_model/encoder/layers.10/self_attn/Reshape_1_output_0: 3d6b9e5c
/model/vision_model/vision_model/encoder/layers.10/self_attn/Reshape_2_output_0: 3d0db38a
/model/vision_model/vision_model/encoder/layers.10/self_attn/Transpose_output_0: 3d0db38a
/model/vision_model/vision_model/encoder/layers.10/self_attn/Transpose_1_output_0: 3dcbeda6
/model/vision_model/vision_model/encoder/layers.10/self_attn/Transpose_2_output_0: 3d6b9e5c
/model/vision_model/vision_model/encoder/layers.10/self_attn/MatMul_output_0: 3f855c1e
/model/vision_model/vision_model/encoder/layers.10/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1613_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.10/self_attn/Mul_output_0: 3dfb7b77
/model/vision_model/vision_model/encoder/layers.10/self_attn/Softmax_output: 3a944d9b
/model/vision_model/vision_model/encoder/layers.10/self_attn/Softmax_output_0: 3a944d9b
/model/vision_model/vision_model/encoder/layers.10/self_attn/Cast_output_0: 3a944d9b
/model/vision_model/vision_model/encoder/layers.10/self_attn/Cast_1_output_0: 3a944d9b
/model/vision_model/vision_model/encoder/layers.10/self_attn/MatMul_1_output_0: 3cb34451
/model/vision_model/vision_model/encoder/layers.10/self_attn/Transpose_3_output_0: 3cb34451
/model/vision_model/vision_model/encoder/layers.10/self_attn/Reshape_3_output_0: 3cb34451
onnx::MatMul_9193_output: 3a2b6e1c
ONNXTRT_Broadcast_1617_output: 3a2b6e1c
/model/vision_model/vision_model/encoder/layers.10/self_attn/out_proj/MatMul_output_0: 3c89bfce
backbone.model.vision_model.vision_model.encoder.layers.10.self_attn.out_proj.bias_output: 3b825f3e
ONNXTRT_Broadcast_1619_output: 3b825f3e
/model/vision_model/vision_model/encoder/layers.10/self_attn/out_proj/Add_output_0: 3c965f19
/model/vision_model/vision_model/encoder/layers.10/Add_output_0: 3fa70c33
ONNXTRT_Broadcast_7280_output: 3c010a14
/model/language_model/model/layers.15/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.10/layer_norm2/LayerNormalization_output_0: 3d69f233
onnx::MatMul_9194_output: 3a188a14
ONNXTRT_Broadcast_1627_output: 3a188a14
/model/vision_model/vision_model/encoder/layers.10/mlp/fc1/MatMul_output_0: 3d0a052f
backbone.model.vision_model.vision_model.encoder.layers.10.mlp.fc1.bias_output: 3cd9c963
ONNXTRT_Broadcast_1629_output: 3cd9c963
/model/vision_model/vision_model/encoder/layers.10/mlp/fc1/Add_output_0: 3d3e041c
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Mul_output_0: 3e3e88e4
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Mul_1_output_0: 3f752d8e
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1631_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Mul_2_output_0: 3d2f6236
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Add_output_0: 3dcae6c5
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1633_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Mul_3_output_0: 3da1e29e
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1635_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Mul_4_output_0: 3c9d0d2b
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1637_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.10/mlp/activation_fn/Mul_5_output_0: 3c1d0d2b
onnx::MatMul_9195_output: 3a0155ec
ONNXTRT_Broadcast_1639_output: 3a0155ec
/model/vision_model/vision_model/encoder/layers.10/mlp/fc2/MatMul_output_0: 3ce01d76
backbone.model.vision_model.vision_model.encoder.layers.10.mlp.fc2.bias_output: 3b630e9d
ONNXTRT_Broadcast_1641_output: 3b630e9d
/model/vision_model/vision_model/encoder/layers.10/mlp/fc2/Add_output_0: 3c8ce8f1
/model/vision_model/vision_model/encoder/layers.10/Add_1_output_0: 3fa5ce7a
/model/language_model/model/layers.15/post_attention_layernorm/Sqrt_output_0: 3efa19eb
/model/language_model/model/layers.15/post_attention_layernorm/Add_output_0: 44aed280
/model/vision_model/vision_model/encoder/layers.11/layer_norm1/LayerNormalization_output_0: 3dfd422e
onnx::MatMul_9196_output: 3a740cda
ONNXTRT_Broadcast_1649_output: 3a740cda
/model/vision_model/vision_model/encoder/layers.11/self_attn/q_proj/MatMul_output_0: 3d574be0
backbone.model.vision_model.vision_model.encoder.layers.11.self_attn.q_proj.bias_output: 3d53c1c4
ONNXTRT_Broadcast_1651_output: 3d53c1c4
/model/vision_model/vision_model/encoder/layers.11/self_attn/q_proj/Add_output_0: 3da729c6
onnx::MatMul_9197_output: 3a853a75
ONNXTRT_Broadcast_1653_output: 3a853a75
/model/vision_model/vision_model/encoder/layers.11/self_attn/k_proj/MatMul_output_0: 3d539567
backbone.model.vision_model.vision_model.encoder.layers.11.self_attn.k_proj.bias_output: 3c306eee
ONNXTRT_Broadcast_1655_output: 3c306eee
/model/vision_model/vision_model/encoder/layers.11/self_attn/k_proj/Add_output_0: 3d5be71c
onnx::MatMul_9198_output: 3a1e5b67
ONNXTRT_Broadcast_1657_output: 3a1e5b67
/model/vision_model/vision_model/encoder/layers.11/self_attn/v_proj/MatMul_output_0: 3d10e166
backbone.model.vision_model.vision_model.encoder.layers.11.self_attn.v_proj.bias_output: 3ae81dfc
ONNXTRT_Broadcast_1659_output: 3ae81dfc
/model/vision_model/vision_model/encoder/layers.11/self_attn/v_proj/Add_output_0: 3d0fd9f9
/model/vision_model/vision_model/encoder/layers.11/self_attn/Reshape_output_0: 3da729c6
/model/vision_model/vision_model/encoder/layers.11/self_attn/Reshape_1_output_0: 3d5be71c
/model/vision_model/vision_model/encoder/layers.11/self_attn/Reshape_2_output_0: 3d0fd9f9
/model/vision_model/vision_model/encoder/layers.11/self_attn/Transpose_output_0: 3d0fd9f9
/model/vision_model/vision_model/encoder/layers.11/self_attn/Transpose_1_output_0: 3da729c6
/model/vision_model/vision_model/encoder/layers.11/self_attn/Transpose_2_output_0: 3d5be71c
/model/vision_model/vision_model/encoder/layers.11/self_attn/MatMul_output_0: 3f8ee315
/model/vision_model/vision_model/encoder/layers.11/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1664_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.11/self_attn/Mul_output_0: 3e06b95c
/model/vision_model/vision_model/encoder/layers.11/self_attn/Softmax_output: 3a933acb
/model/vision_model/vision_model/encoder/layers.11/self_attn/Softmax_output_0: 3a933acb
/model/vision_model/vision_model/encoder/layers.11/self_attn/Cast_output_0: 3a933acb
/model/vision_model/vision_model/encoder/layers.11/self_attn/Cast_1_output_0: 3a933acb
/model/vision_model/vision_model/encoder/layers.11/self_attn/MatMul_1_output_0: 3ca478f5
/model/vision_model/vision_model/encoder/layers.11/self_attn/Transpose_3_output_0: 3ca478f5
/model/vision_model/vision_model/encoder/layers.11/self_attn/Reshape_3_output_0: 3ca478f5
onnx::MatMul_9218_output: 3a338438
ONNXTRT_Broadcast_1668_output: 3a338438
/model/vision_model/vision_model/encoder/layers.11/self_attn/out_proj/MatMul_output_0: 3c4a2e5f
backbone.model.vision_model.vision_model.encoder.layers.11.self_attn.out_proj.bias_output: 3b633b77
ONNXTRT_Broadcast_1670_output: 3b633b77
/model/vision_model/vision_model/encoder/layers.11/self_attn/out_proj/Add_output_0: 3c95cb82
/model/vision_model/vision_model/encoder/layers.11/Add_output_0: 3fa7091e
ONNXTRT_Broadcast_7278_output: 32074ebd
/model/language_model/model/layers.15/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/vision_model/vision_model/encoder/layers.11/layer_norm2/LayerNormalization_output_0: 3d87ab43
onnx::MatMul_9219_output: 3a1b9871
ONNXTRT_Broadcast_1678_output: 3a1b9871
/model/vision_model/vision_model/encoder/layers.11/mlp/fc1/MatMul_output_0: 3d1acae1
backbone.model.vision_model.vision_model.encoder.layers.11.mlp.fc1.bias_output: 3cd5c943
ONNXTRT_Broadcast_1680_output: 3cd5c943
/model/vision_model/vision_model/encoder/layers.11/mlp/fc1/Add_output_0: 3d3358fd
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Mul_output_0: 3e2c4798
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Mul_1_output_0: 3f532117
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1682_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Mul_2_output_0: 3d17070c
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Add_output_0: 3dbe7f9d
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1684_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Mul_3_output_0: 3d97fd52
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1686_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Add_1_output_0: 3c81109a
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Mul_4_output_0: 3c6b136b
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1688_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.11/mlp/activation_fn/Mul_5_output_0: 3beb136b
onnx::MatMul_9220_output: 3a73470e
ONNXTRT_Broadcast_1690_output: 3a73470e
/model/vision_model/vision_model/encoder/layers.11/mlp/fc2/MatMul_output_0: 3c80edf1
backbone.model.vision_model.vision_model.encoder.layers.11.mlp.fc2.bias_output: 3b9155ab
ONNXTRT_Broadcast_1692_output: 3b9155ab
/model/vision_model/vision_model/encoder/layers.11/mlp/fc2/Add_output_0: 3c9836bd
/model/vision_model/vision_model/encoder/layers.11/Add_1_output_0: 3fa5d219
/model/language_model/model/layers.15/post_attention_layernorm/ReduceMean_output_0: 44aed280
/model/language_model/model/layers.15/post_attention_layernorm/Pow_output_0: 49420ee6
/model/vision_model/vision_model/encoder/layers.12/layer_norm1/LayerNormalization_output_0: 3e006067
onnx::MatMul_9221_output: 3a58e7d0
ONNXTRT_Broadcast_1700_output: 3a58e7d0
/model/vision_model/vision_model/encoder/layers.12/self_attn/q_proj/MatMul_output_0: 3d6b0525
backbone.model.vision_model.vision_model.encoder.layers.12.self_attn.q_proj.bias_output: 3d73f70e
ONNXTRT_Broadcast_1702_output: 3d73f70e
/model/vision_model/vision_model/encoder/layers.12/self_attn/q_proj/Add_output_0: 3dc51717
onnx::MatMul_9222_output: 3a893275
ONNXTRT_Broadcast_1704_output: 3a893275
/model/vision_model/vision_model/encoder/layers.12/self_attn/k_proj/MatMul_output_0: 3d5f3d9e
backbone.model.vision_model.vision_model.encoder.layers.12.self_attn.k_proj.bias_output: 3c143b36
ONNXTRT_Broadcast_1706_output: 3c143b36
/model/vision_model/vision_model/encoder/layers.12/self_attn/k_proj/Add_output_0: 3d767578
onnx::MatMul_9223_output: 3a043469
ONNXTRT_Broadcast_1708_output: 3a043469
/model/vision_model/vision_model/encoder/layers.12/self_attn/v_proj/MatMul_output_0: 3d02b496
backbone.model.vision_model.vision_model.encoder.layers.12.self_attn.v_proj.bias_output: 3b0a4347
ONNXTRT_Broadcast_1710_output: 3b0a4347
/model/vision_model/vision_model/encoder/layers.12/self_attn/v_proj/Add_output_0: 3cfc9580
/model/vision_model/vision_model/encoder/layers.12/self_attn/Reshape_output_0: 3dc51717
/model/vision_model/vision_model/encoder/layers.12/self_attn/Reshape_1_output_0: 3d767578
/model/vision_model/vision_model/encoder/layers.12/self_attn/Reshape_2_output_0: 3cfc9580
/model/vision_model/vision_model/encoder/layers.12/self_attn/Transpose_output_0: 3cfc9580
/model/vision_model/vision_model/encoder/layers.12/self_attn/Transpose_1_output_0: 3dc51717
/model/vision_model/vision_model/encoder/layers.12/self_attn/Transpose_2_output_0: 3d767578
/model/vision_model/vision_model/encoder/layers.12/self_attn/MatMul_output_0: 3fc7aca9
/model/vision_model/vision_model/encoder/layers.12/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1715_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.12/self_attn/Mul_output_0: 3e3c446c
/model/vision_model/vision_model/encoder/layers.12/self_attn/Softmax_output: 3a84b816
/model/vision_model/vision_model/encoder/layers.12/self_attn/Softmax_output_0: 3a84b816
/model/vision_model/vision_model/encoder/layers.12/self_attn/Cast_output_0: 3a84b816
/model/vision_model/vision_model/encoder/layers.12/self_attn/Cast_1_output_0: 3a84b816
/model/vision_model/vision_model/encoder/layers.12/self_attn/MatMul_1_output_0: 3c9d12ef
/model/vision_model/vision_model/encoder/layers.12/self_attn/Transpose_3_output_0: 3c9d12ef
/model/vision_model/vision_model/encoder/layers.12/self_attn/Reshape_3_output_0: 3c9d12ef
onnx::MatMul_9243_output: 3a2a7d5b
ONNXTRT_Broadcast_1719_output: 3a2a7d5b
/model/vision_model/vision_model/encoder/layers.12/self_attn/out_proj/MatMul_output_0: 3c1b4b65
backbone.model.vision_model.vision_model.encoder.layers.12.self_attn.out_proj.bias_output: 3b8b89d4
ONNXTRT_Broadcast_1721_output: 3b8b89d4
/model/vision_model/vision_model/encoder/layers.12/self_attn/out_proj/Add_output_0: 3c82e733
/model/vision_model/vision_model/encoder/layers.12/Add_output_0: 3fa6fd6b
ONNXTRT_Broadcast_7276_output: 3c810a14
/model/language_model/model/layers.15/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/vision_model/vision_model/encoder/layers.12/layer_norm2/LayerNormalization_output_0: 3dc0b9eb
onnx::MatMul_9244_output: 3a5efe5d
ONNXTRT_Broadcast_1729_output: 3a5efe5d
/model/vision_model/vision_model/encoder/layers.12/mlp/fc1/MatMul_output_0: 3d1794ae
backbone.model.vision_model.vision_model.encoder.layers.12.mlp.fc1.bias_output: 3cb788e2
ONNXTRT_Broadcast_1731_output: 3cb788e2
/model/vision_model/vision_model/encoder/layers.12/mlp/fc1/Add_output_0: 3d3f9af4
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Mul_output_0: 3e41129d
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Mul_1_output_0: 3f2718f1
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1733_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Mul_2_output_0: 3cef0f6e
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Add_output_0: 3dbc3b9e
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1735_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Mul_3_output_0: 3d962e91
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1737_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Add_1_output_0: 3c811220
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Mul_4_output_0: 3cdbae85
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1739_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.12/mlp/activation_fn/Mul_5_output_0: 3c5bae85
onnx::MatMul_9245_output: 3a0a94a9
ONNXTRT_Broadcast_1741_output: 3a0a94a9
/model/vision_model/vision_model/encoder/layers.12/mlp/fc2/MatMul_output_0: 3c238a45
backbone.model.vision_model.vision_model.encoder.layers.12.mlp.fc2.bias_output: 3b8434ea
ONNXTRT_Broadcast_1743_output: 3b8434ea
/model/vision_model/vision_model/encoder/layers.12/mlp/fc2/Add_output_0: 3c815016
/model/vision_model/vision_model/encoder/layers.12/Add_1_output_0: 3fa5dd1d
/model/language_model/model/layers.15/post_attention_layernorm/Cast_output_0: 40ffabc1
/model/language_model/model/layers.15/Add_output_0: 40ffabc1
/model/vision_model/vision_model/encoder/layers.13/layer_norm1/LayerNormalization_output_0: 3df0b5fa
onnx::MatMul_9246_output: 3a2b6e1c
ONNXTRT_Broadcast_1751_output: 3a2b6e1c
/model/vision_model/vision_model/encoder/layers.13/self_attn/q_proj/MatMul_output_0: 3d6b7754
backbone.model.vision_model.vision_model.encoder.layers.13.self_attn.q_proj.bias_output: 3d54d973
ONNXTRT_Broadcast_1753_output: 3d54d973
/model/vision_model/vision_model/encoder/layers.13/self_attn/q_proj/Add_output_0: 3da6607a
onnx::MatMul_9247_output: 3a216810
ONNXTRT_Broadcast_1755_output: 3a216810
/model/vision_model/vision_model/encoder/layers.13/self_attn/k_proj/MatMul_output_0: 3d56d42d
backbone.model.vision_model.vision_model.encoder.layers.13.self_attn.k_proj.bias_output: 3c164861
ONNXTRT_Broadcast_1757_output: 3c164861
/model/vision_model/vision_model/encoder/layers.13/self_attn/k_proj/Add_output_0: 3d626c6a
onnx::MatMul_9248_output: 3a135bd8
ONNXTRT_Broadcast_1759_output: 3a135bd8
/model/vision_model/vision_model/encoder/layers.13/self_attn/v_proj/MatMul_output_0: 3d13ff13
backbone.model.vision_model.vision_model.encoder.layers.13.self_attn.v_proj.bias_output: 3b1f6489
ONNXTRT_Broadcast_1761_output: 3b1f6489
/model/vision_model/vision_model/encoder/layers.13/self_attn/v_proj/Add_output_0: 3d161c92
/model/vision_model/vision_model/encoder/layers.13/self_attn/Reshape_output_0: 3da6607a
/model/vision_model/vision_model/encoder/layers.13/self_attn/Reshape_1_output_0: 3d626c6a
/model/vision_model/vision_model/encoder/layers.13/self_attn/Reshape_2_output_0: 3d161c92
/model/vision_model/vision_model/encoder/layers.13/self_attn/Transpose_output_0: 3d161c92
/model/vision_model/vision_model/encoder/layers.13/self_attn/Transpose_1_output_0: 3da6607a
/model/vision_model/vision_model/encoder/layers.13/self_attn/Transpose_2_output_0: 3d626c6a
/model/vision_model/vision_model/encoder/layers.13/self_attn/MatMul_output_0: 3f6faea5
/model/vision_model/vision_model/encoder/layers.13/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1766_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.13/self_attn/Mul_output_0: 3de1fd4c
/model/vision_model/vision_model/encoder/layers.13/self_attn/Softmax_output: 3a766735
/model/vision_model/vision_model/encoder/layers.13/self_attn/Softmax_output_0: 3a766735
/model/vision_model/vision_model/encoder/layers.13/self_attn/Cast_output_0: 3a766735
/model/vision_model/vision_model/encoder/layers.13/self_attn/Cast_1_output_0: 3a766735
/model/vision_model/vision_model/encoder/layers.13/self_attn/MatMul_1_output_0: 3cad8d04
/model/vision_model/vision_model/encoder/layers.13/self_attn/Transpose_3_output_0: 3cad8d04
/model/vision_model/vision_model/encoder/layers.13/self_attn/Reshape_3_output_0: 3cad8d04
onnx::MatMul_9268_output: 39f76912
ONNXTRT_Broadcast_1770_output: 39f76912
/model/vision_model/vision_model/encoder/layers.13/self_attn/out_proj/MatMul_output_0: 3c70d7db
backbone.model.vision_model.vision_model.encoder.layers.13.self_attn.out_proj.bias_output: 3bb3aa95
ONNXTRT_Broadcast_1772_output: 3bb3aa95
/model/vision_model/vision_model/encoder/layers.13/self_attn/out_proj/Add_output_0: 3c97d865
/model/vision_model/vision_model/encoder/layers.13/Add_output_0: 3fa9766f
/model/language_model/model/layers.15/self_attn/o_proj/MatMul_output_0: 3f11cfaf
ONNXTRT_Broadcast_7274_output: 3ab8bfbf
/model/vision_model/vision_model/encoder/layers.13/layer_norm2/LayerNormalization_output_0: 3dc43307
onnx::MatMul_9269_output: 3a0f668d
ONNXTRT_Broadcast_1780_output: 3a0f668d
/model/vision_model/vision_model/encoder/layers.13/mlp/fc1/MatMul_output_0: 3d2ab7b2
backbone.model.vision_model.vision_model.encoder.layers.13.mlp.fc1.bias_output: 3cbfa418
ONNXTRT_Broadcast_1782_output: 3cbfa418
/model/vision_model/vision_model/encoder/layers.13/mlp/fc1/Add_output_0: 3d2ceb68
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Mul_output_0: 3e0d6573
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Mul_1_output_0: 3f1cfbd0
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1784_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Mul_2_output_0: 3ce09744
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Add_output_0: 3db4fd55
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1786_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Mul_3_output_0: 3d90671e
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1788_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Add_1_output_0: 3c821427
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Mul_4_output_0: 3c93c54c
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1790_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.13/mlp/activation_fn/Mul_5_output_0: 3c13c54c
onnx::MatMul_9270_output: 39f68e9d
ONNXTRT_Broadcast_1792_output: 39f68e9d
/model/vision_model/vision_model/encoder/layers.13/mlp/fc2/MatMul_output_0: 3c26e0f6
backbone.model.vision_model.vision_model.encoder.layers.13.mlp.fc2.bias_output: 3b9b7347
ONNXTRT_Broadcast_1794_output: 3b9b7347
/model/vision_model/vision_model/encoder/layers.13/mlp/fc2/Add_output_0: 3c93f088
/model/vision_model/vision_model/encoder/layers.13/Add_1_output_0: 3fa5eb98
onnx::MatMul_10130_output: 3ab8bfbf
/model/language_model/model/layers.15/self_attn/Reshape_7_output_0: 3e8b35bd
/model/vision_model/vision_model/encoder/layers.14/layer_norm1/LayerNormalization_output_0: 3de665ed
onnx::MatMul_9271_output: 3a9341f4
ONNXTRT_Broadcast_1802_output: 3a9341f4
/model/vision_model/vision_model/encoder/layers.14/self_attn/q_proj/MatMul_output_0: 3d5bd448
backbone.model.vision_model.vision_model.encoder.layers.14.self_attn.q_proj.bias_output: 3d67e4a9
ONNXTRT_Broadcast_1804_output: 3d67e4a9
/model/vision_model/vision_model/encoder/layers.14/self_attn/q_proj/Add_output_0: 3db31d65
onnx::MatMul_9272_output: 3a99470e
ONNXTRT_Broadcast_1806_output: 3a99470e
/model/vision_model/vision_model/encoder/layers.14/self_attn/k_proj/MatMul_output_0: 3d5e8936
backbone.model.vision_model.vision_model.encoder.layers.14.self_attn.k_proj.bias_output: 3c0f2c99
ONNXTRT_Broadcast_1808_output: 3c0f2c99
/model/vision_model/vision_model/encoder/layers.14/self_attn/k_proj/Add_output_0: 3d6223ea
onnx::MatMul_9273_output: 3a042f5f
ONNXTRT_Broadcast_1810_output: 3a042f5f
/model/vision_model/vision_model/encoder/layers.14/self_attn/v_proj/MatMul_output_0: 3cf44a16
backbone.model.vision_model.vision_model.encoder.layers.14.self_attn.v_proj.bias_output: 3b61d1a3
ONNXTRT_Broadcast_1812_output: 3b61d1a3
/model/vision_model/vision_model/encoder/layers.14/self_attn/v_proj/Add_output_0: 3cf0ba46
/model/vision_model/vision_model/encoder/layers.14/self_attn/Reshape_output_0: 3db31d65
/model/vision_model/vision_model/encoder/layers.14/self_attn/Reshape_1_output_0: 3d6223ea
/model/vision_model/vision_model/encoder/layers.14/self_attn/Reshape_2_output_0: 3cf0ba46
/model/vision_model/vision_model/encoder/layers.14/self_attn/Transpose_output_0: 3cf0ba46
/model/vision_model/vision_model/encoder/layers.14/self_attn/Transpose_1_output_0: 3db31d65
/model/vision_model/vision_model/encoder/layers.14/self_attn/Transpose_2_output_0: 3d6223ea
/model/vision_model/vision_model/encoder/layers.14/self_attn/MatMul_output_0: 3f86026b
/model/vision_model/vision_model/encoder/layers.14/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1817_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.14/self_attn/Mul_output_0: 3dfcb50e
/model/vision_model/vision_model/encoder/layers.14/self_attn/Softmax_output: 3a81a445
/model/vision_model/vision_model/encoder/layers.14/self_attn/Softmax_output_0: 3a81a445
/model/vision_model/vision_model/encoder/layers.14/self_attn/Cast_output_0: 3a81a445
/model/vision_model/vision_model/encoder/layers.14/self_attn/Cast_1_output_0: 3a81a445
/model/vision_model/vision_model/encoder/layers.14/self_attn/MatMul_1_output_0: 3c86d0fb
/model/vision_model/vision_model/encoder/layers.14/self_attn/Transpose_3_output_0: 3c86d0fb
/model/vision_model/vision_model/encoder/layers.14/self_attn/Reshape_3_output_0: 3c86d0fb
onnx::MatMul_9293_output: 3a043469
ONNXTRT_Broadcast_1821_output: 3a043469
/model/vision_model/vision_model/encoder/layers.14/self_attn/out_proj/MatMul_output_0: 3c244f9a
backbone.model.vision_model.vision_model.encoder.layers.14.self_attn.out_proj.bias_output: 3b51e449
ONNXTRT_Broadcast_1823_output: 3b51e449
/model/vision_model/vision_model/encoder/layers.14/self_attn/out_proj/Add_output_0: 3ca08d66
/model/vision_model/vision_model/encoder/layers.14/Add_output_0: 3fa98be5
ONNXTRT_Broadcast_5434_output: 32074ebd
/model/language_model/model/layers.8/self_attn/Slice_3_output_0: 3dc71f38
/model/vision_model/vision_model/encoder/layers.14/layer_norm2/LayerNormalization_output_0: 3daafb9b
onnx::MatMul_9294_output: 3a1a79f4
ONNXTRT_Broadcast_1831_output: 3a1a79f4
/model/vision_model/vision_model/encoder/layers.14/mlp/fc1/MatMul_output_0: 3d9c719d
backbone.model.vision_model.vision_model.encoder.layers.14.mlp.fc1.bias_output: 3ca05891
ONNXTRT_Broadcast_1833_output: 3ca05891
/model/vision_model/vision_model/encoder/layers.14/mlp/fc1/Add_output_0: 3d9a6e63
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Mul_output_0: 3f21323f
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Mul_1_output_0: 40801789
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1835_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Mul_2_output_0: 3e3741ac
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Add_output_0: 3e914c97
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1837_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Mul_3_output_0: 3e67dab8
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1839_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Add_1_output_0: 3c419326
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Mul_4_output_0: 3cf13841
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1841_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.14/mlp/activation_fn/Mul_5_output_0: 3c713841
onnx::MatMul_9295_output: 3a43f6ee
ONNXTRT_Broadcast_1843_output: 3a43f6ee
/model/vision_model/vision_model/encoder/layers.14/mlp/fc2/MatMul_output_0: 3c2721de
backbone.model.vision_model.vision_model.encoder.layers.14.mlp.fc2.bias_output: 3b648285
ONNXTRT_Broadcast_1845_output: 3b648285
/model/vision_model/vision_model/encoder/layers.14/mlp/fc2/Add_output_0: 3c8d6435
/model/vision_model/vision_model/encoder/layers.14/Add_1_output_0: 3fa60b55
/model/language_model/model/layers.14/self_attn/q_norm/Cast_1_output_0: 3d4e9853
/model/language_model/model/layers.7/self_attn/q_norm/Cast_output_0: 3da1b8fd
/model/vision_model/vision_model/encoder/layers.15/layer_norm1/LayerNormalization_output_0: 3dcd58d2
onnx::MatMul_9296_output: 3a194f5f
ONNXTRT_Broadcast_1853_output: 3a194f5f
/model/vision_model/vision_model/encoder/layers.15/self_attn/q_proj/MatMul_output_0: 3d4e9805
backbone.model.vision_model.vision_model.encoder.layers.15.self_attn.q_proj.bias_output: 3d3ea8d2
ONNXTRT_Broadcast_1855_output: 3d3ea8d2
/model/vision_model/vision_model/encoder/layers.15/self_attn/q_proj/Add_output_0: 3da980f7
onnx::MatMul_9297_output: 3a892b16
ONNXTRT_Broadcast_1857_output: 3a892b16
/model/vision_model/vision_model/encoder/layers.15/self_attn/k_proj/MatMul_output_0: 3d4ddcea
backbone.model.vision_model.vision_model.encoder.layers.15.self_attn.k_proj.bias_output: 3c195479
ONNXTRT_Broadcast_1859_output: 3c195479
/model/vision_model/vision_model/encoder/layers.15/self_attn/k_proj/Add_output_0: 3d564ff9
onnx::MatMul_9298_output: 3a1443e8
ONNXTRT_Broadcast_1861_output: 3a1443e8
/model/vision_model/vision_model/encoder/layers.15/self_attn/v_proj/MatMul_output_0: 3d0ba1fd
backbone.model.vision_model.vision_model.encoder.layers.15.self_attn.v_proj.bias_output: 3b1e760c
ONNXTRT_Broadcast_1863_output: 3b1e760c
/model/vision_model/vision_model/encoder/layers.15/self_attn/v_proj/Add_output_0: 3d130ee1
/model/vision_model/vision_model/encoder/layers.15/self_attn/Reshape_output_0: 3da980f7
/model/vision_model/vision_model/encoder/layers.15/self_attn/Reshape_1_output_0: 3d564ff9
/model/vision_model/vision_model/encoder/layers.15/self_attn/Reshape_2_output_0: 3d130ee1
/model/vision_model/vision_model/encoder/layers.15/self_attn/Transpose_output_0: 3d130ee1
/model/vision_model/vision_model/encoder/layers.15/self_attn/Transpose_1_output_0: 3da980f7
/model/vision_model/vision_model/encoder/layers.15/self_attn/Transpose_2_output_0: 3d564ff9
/model/vision_model/vision_model/encoder/layers.15/self_attn/MatMul_output_0: 3f552732
/model/vision_model/vision_model/encoder/layers.15/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1868_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.15/self_attn/Mul_output_0: 3dc8f9d6
/model/vision_model/vision_model/encoder/layers.15/self_attn/Softmax_output: 3a553397
/model/vision_model/vision_model/encoder/layers.15/self_attn/Softmax_output_0: 3a553397
/model/vision_model/vision_model/encoder/layers.15/self_attn/Cast_output_0: 3a553397
/model/vision_model/vision_model/encoder/layers.15/self_attn/Cast_1_output_0: 3a553397
/model/vision_model/vision_model/encoder/layers.15/self_attn/MatMul_1_output_0: 3c97a134
/model/vision_model/vision_model/encoder/layers.15/self_attn/Transpose_3_output_0: 3c97a134
/model/vision_model/vision_model/encoder/layers.15/self_attn/Reshape_3_output_0: 3c97a134
onnx::MatMul_9318_output: 39fb762c
ONNXTRT_Broadcast_1872_output: 39fb762c
/model/vision_model/vision_model/encoder/layers.15/self_attn/out_proj/MatMul_output_0: 3c925e8c
backbone.model.vision_model.vision_model.encoder.layers.15.self_attn.out_proj.bias_output: 3bb39ab5
ONNXTRT_Broadcast_1874_output: 3bb39ab5
/model/vision_model/vision_model/encoder/layers.15/self_attn/out_proj/Add_output_0: 3c1005cd
/model/vision_model/vision_model/encoder/layers.15/Add_output_0: 3fa89995
/model/language_model/model/layers.10/self_attn/Mul_8_output_0: 3e08866e
ONNXTRT_Broadcast_4902_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.15/layer_norm2/LayerNormalization_output_0: 3deb4187
onnx::MatMul_9319_output: 3a033cfa
ONNXTRT_Broadcast_1882_output: 3a033cfa
/model/vision_model/vision_model/encoder/layers.15/mlp/fc1/MatMul_output_0: 3d8676cd
backbone.model.vision_model.vision_model.encoder.layers.15.mlp.fc1.bias_output: 3cb993e8
ONNXTRT_Broadcast_1884_output: 3cb993e8
/model/vision_model/vision_model/encoder/layers.15/mlp/fc1/Add_output_0: 3d8f0ecd
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Mul_output_0: 3f0bbba9
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Mul_1_output_0: 4060f886
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1886_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Mul_2_output_0: 3e20edc7
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Add_output_0: 3e6dad1c
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1888_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Mul_3_output_0: 3e3da15e
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1890_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Mul_4_output_0: 3d207ddf
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1892_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.15/mlp/activation_fn/Mul_5_output_0: 3ca07ddf
onnx::MatMul_9320_output: 3a258041
ONNXTRT_Broadcast_1894_output: 3a258041
/model/vision_model/vision_model/encoder/layers.15/mlp/fc2/MatMul_output_0: 3c8dfeea
backbone.model.vision_model.vision_model.encoder.layers.15.mlp.fc2.bias_output: 3b719bb7
ONNXTRT_Broadcast_1896_output: 3b719bb7
/model/vision_model/vision_model/encoder/layers.15/mlp/fc2/Add_output_0: 3c627915
/model/vision_model/vision_model/encoder/layers.15/Add_1_output_0: 3fa8d4dc
/model/language_model/model/layers.15/self_attn/Transpose_4_output_0: 3e8b35bd
/model/language_model/model/layers.15/self_attn/MatMul_1_output_0: 3e8b35bd
/model/vision_model/vision_model/encoder/layers.16/layer_norm1/LayerNormalization_output_0: 3df0c0ef
onnx::MatMul_9321_output: 3a4edc18
ONNXTRT_Broadcast_1904_output: 3a4edc18
/model/vision_model/vision_model/encoder/layers.16/self_attn/q_proj/MatMul_output_0: 3d657219
backbone.model.vision_model.vision_model.encoder.layers.16.self_attn.q_proj.bias_output: 3d8f2810
ONNXTRT_Broadcast_1906_output: 3d8f2810
/model/vision_model/vision_model/encoder/layers.16/self_attn/q_proj/Add_output_0: 3dc276b0
onnx::MatMul_9322_output: 3a4dc469
ONNXTRT_Broadcast_1908_output: 3a4dc469
/model/vision_model/vision_model/encoder/layers.16/self_attn/k_proj/MatMul_output_0: 3d5f4b38
backbone.model.vision_model.vision_model.encoder.layers.16.self_attn.k_proj.bias_output: 3bec0cfa
ONNXTRT_Broadcast_1910_output: 3bec0cfa
/model/vision_model/vision_model/encoder/layers.16/self_attn/k_proj/Add_output_0: 3d5e96ec
onnx::MatMul_9323_output: 3a133a04
ONNXTRT_Broadcast_1912_output: 3a133a04
/model/vision_model/vision_model/encoder/layers.16/self_attn/v_proj/MatMul_output_0: 3cfcdf47
backbone.model.vision_model.vision_model.encoder.layers.16.self_attn.v_proj.bias_output: 3b1b5091
ONNXTRT_Broadcast_1914_output: 3b1b5091
/model/vision_model/vision_model/encoder/layers.16/self_attn/v_proj/Add_output_0: 3cee84ee
/model/vision_model/vision_model/encoder/layers.16/self_attn/Reshape_output_0: 3dc276b0
/model/vision_model/vision_model/encoder/layers.16/self_attn/Reshape_1_output_0: 3d5e96ec
/model/vision_model/vision_model/encoder/layers.16/self_attn/Reshape_2_output_0: 3cee84ee
/model/vision_model/vision_model/encoder/layers.16/self_attn/Transpose_output_0: 3cee84ee
/model/vision_model/vision_model/encoder/layers.16/self_attn/Transpose_1_output_0: 3dc276b0
/model/vision_model/vision_model/encoder/layers.16/self_attn/Transpose_2_output_0: 3d5e96ec
/model/vision_model/vision_model/encoder/layers.16/self_attn/MatMul_output_0: 3f5cb395
/model/vision_model/vision_model/encoder/layers.16/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1919_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.16/self_attn/Mul_output_0: 3dd017d3
/model/vision_model/vision_model/encoder/layers.16/self_attn/Softmax_output: 3a886212
/model/vision_model/vision_model/encoder/layers.16/self_attn/Softmax_output_0: 3a886212
/model/vision_model/vision_model/encoder/layers.16/self_attn/Cast_output_0: 3a886212
/model/vision_model/vision_model/encoder/layers.16/self_attn/Cast_1_output_0: 3a886212
/model/vision_model/vision_model/encoder/layers.16/self_attn/MatMul_1_output_0: 3c809eb2
/model/vision_model/vision_model/encoder/layers.16/self_attn/Transpose_3_output_0: 3c809eb2
/model/vision_model/vision_model/encoder/layers.16/self_attn/Reshape_3_output_0: 3c809eb2
onnx::MatMul_9343_output: 3a053bf8
ONNXTRT_Broadcast_1923_output: 3a053bf8
/model/vision_model/vision_model/encoder/layers.16/self_attn/out_proj/MatMul_output_0: 3c6425d6
backbone.model.vision_model.vision_model.encoder.layers.16.self_attn.out_proj.bias_output: 3ba069b3
ONNXTRT_Broadcast_1925_output: 3ba069b3
/model/vision_model/vision_model/encoder/layers.16/self_attn/out_proj/Add_output_0: 3c531213
/model/vision_model/vision_model/encoder/layers.16/Add_output_0: 3fa63187
/model/language_model/model/layers.15/self_attn/Cast_5_output_0: 3a80c183
/model/language_model/model/layers.15/self_attn/Cast_4_output_0: 3a80c183
/model/vision_model/vision_model/encoder/layers.16/layer_norm2/LayerNormalization_output_0: 3e03c788
onnx::MatMul_9344_output: 3a258f9f
ONNXTRT_Broadcast_1933_output: 3a258f9f
/model/vision_model/vision_model/encoder/layers.16/mlp/fc1/MatMul_output_0: 3dbc4b8e
backbone.model.vision_model.vision_model.encoder.layers.16.mlp.fc1.bias_output: 3cdfd65d
ONNXTRT_Broadcast_1935_output: 3cdfd65d
/model/vision_model/vision_model/encoder/layers.16/mlp/fc1/Add_output_0: 3dcdd754
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Mul_output_0: 3f97d1ea
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Mul_1_output_0: 41371800
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1937_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Mul_2_output_0: 3f02f90b
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Add_output_0: 3f1ac354
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1939_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Mul_3_output_0: 3ef6f4af
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1941_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Mul_4_output_0: 3d01b9d3
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1943_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.16/mlp/activation_fn/Mul_5_output_0: 3c81b9d3
onnx::MatMul_9345_output: 3a1358f2
ONNXTRT_Broadcast_1945_output: 3a1358f2
/model/vision_model/vision_model/encoder/layers.16/mlp/fc2/MatMul_output_0: 3bf7c160
backbone.model.vision_model.vision_model.encoder.layers.16.mlp.fc2.bias_output: 3b9440b1
ONNXTRT_Broadcast_1947_output: 3b9440b1
/model/vision_model/vision_model/encoder/layers.16/mlp/fc2/Add_output_0: 3c377ae3
/model/vision_model/vision_model/encoder/layers.16/Add_1_output_0: 3fa5070d
/model/language_model/model/layers.6/mlp/act_fn/Mul_output_0: 3c524260
/model/language_model/model/layers.3/self_attn/Unsqueeze_19_output_0: 3cbdf29d
/model/vision_model/vision_model/encoder/layers.17/layer_norm1/LayerNormalization_output_0: 3e112e7d
onnx::MatMul_9346_output: 3a2c91c4
ONNXTRT_Broadcast_1955_output: 3a2c91c4
/model/vision_model/vision_model/encoder/layers.17/self_attn/q_proj/MatMul_output_0: 3d62d1d7
backbone.model.vision_model.vision_model.encoder.layers.17.self_attn.q_proj.bias_output: 3d964367
ONNXTRT_Broadcast_1957_output: 3d964367
/model/vision_model/vision_model/encoder/layers.17/self_attn/q_proj/Add_output_0: 3ddceb9c
onnx::MatMul_9347_output: 3a3bb8f2
ONNXTRT_Broadcast_1959_output: 3a3bb8f2
/model/vision_model/vision_model/encoder/layers.17/self_attn/k_proj/MatMul_output_0: 3d4afdab
backbone.model.vision_model.vision_model.encoder.layers.17.self_attn.k_proj.bias_output: 3c0b3255
ONNXTRT_Broadcast_1961_output: 3c0b3255
/model/vision_model/vision_model/encoder/layers.17/self_attn/k_proj/Add_output_0: 3d5a7b4d
onnx::MatMul_9348_output: 3a091d4b
ONNXTRT_Broadcast_1963_output: 3a091d4b
/model/vision_model/vision_model/encoder/layers.17/self_attn/v_proj/MatMul_output_0: 3cfbfe90
backbone.model.vision_model.vision_model.encoder.layers.17.self_attn.v_proj.bias_output: 3afd2489
ONNXTRT_Broadcast_1965_output: 3afd2489
/model/vision_model/vision_model/encoder/layers.17/self_attn/v_proj/Add_output_0: 3cf89d0e
/model/vision_model/vision_model/encoder/layers.17/self_attn/Reshape_output_0: 3ddceb9c
/model/vision_model/vision_model/encoder/layers.17/self_attn/Reshape_1_output_0: 3d5a7b4d
/model/vision_model/vision_model/encoder/layers.17/self_attn/Reshape_2_output_0: 3cf89d0e
/model/vision_model/vision_model/encoder/layers.17/self_attn/Transpose_output_0: 3cf89d0e
/model/vision_model/vision_model/encoder/layers.17/self_attn/Transpose_1_output_0: 3ddceb9c
/model/vision_model/vision_model/encoder/layers.17/self_attn/Transpose_2_output_0: 3d5a7b4d
/model/vision_model/vision_model/encoder/layers.17/self_attn/MatMul_output_0: 3f62d490
/model/vision_model/vision_model/encoder/layers.17/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_1970_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.17/self_attn/Mul_output_0: 3dd5df2b
/model/vision_model/vision_model/encoder/layers.17/self_attn/Softmax_output: 3a530b6a
/model/vision_model/vision_model/encoder/layers.17/self_attn/Softmax_output_0: 3a530b6a
/model/vision_model/vision_model/encoder/layers.17/self_attn/Cast_output_0: 3a530b6a
/model/vision_model/vision_model/encoder/layers.17/self_attn/Cast_1_output_0: 3a530b6a
/model/vision_model/vision_model/encoder/layers.17/self_attn/MatMul_1_output_0: 3c80f1f3
/model/vision_model/vision_model/encoder/layers.17/self_attn/Transpose_3_output_0: 3c80f1f3
/model/vision_model/vision_model/encoder/layers.17/self_attn/Reshape_3_output_0: 3c80f1f3
onnx::MatMul_9368_output: 3a0e35bb
ONNXTRT_Broadcast_1974_output: 3a0e35bb
/model/vision_model/vision_model/encoder/layers.17/self_attn/out_proj/MatMul_output_0: 3c35014b
backbone.model.vision_model.vision_model.encoder.layers.17.self_attn.out_proj.bias_output: 3bbe9c38
ONNXTRT_Broadcast_1976_output: 3bbe9c38
/model/vision_model/vision_model/encoder/layers.17/self_attn/out_proj/Add_output_0: 3c70a1a6
/model/vision_model/vision_model/encoder/layers.17/Add_output_0: 3fa9dbd4
/model/language_model/model/layers.15/self_attn/Softmax_output_0: 3a80c183
/model/language_model/model/layers.15/self_attn/Softmax_output: 3a80c183
/model/vision_model/vision_model/encoder/layers.17/layer_norm2/LayerNormalization_output_0: 3e4352c5
onnx::MatMul_9369_output: 3a1f84ca
ONNXTRT_Broadcast_1984_output: 3a1f84ca
/model/vision_model/vision_model/encoder/layers.17/mlp/fc1/MatMul_output_0: 3e22a524
backbone.model.vision_model.vision_model.encoder.layers.17.mlp.fc1.bias_output: 3cb8a2c6
ONNXTRT_Broadcast_1986_output: 3cb8a2c6
/model/vision_model/vision_model/encoder/layers.17/mlp/fc1/Add_output_0: 3e22143a
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Mul_output_0: 4040710d
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Mul_1_output_0: 42268307
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_1988_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Mul_2_output_0: 3fee38f5
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Add_output_0: 40069dbf
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_1990_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Mul_3_output_0: 3fd6ceb7
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_1992_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Mul_4_output_0: 3dbec77d
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_1994_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.17/mlp/activation_fn/Mul_5_output_0: 3d3ec77d
onnx::MatMul_9370_output: 3a04b4ea
ONNXTRT_Broadcast_1996_output: 3a04b4ea
/model/vision_model/vision_model/encoder/layers.17/mlp/fc2/MatMul_output_0: 3cd05cd6
backbone.model.vision_model.vision_model.encoder.layers.17.mlp.fc2.bias_output: 3c0a2ece
ONNXTRT_Broadcast_1998_output: 3c0a2ece
/model/vision_model/vision_model/encoder/layers.17/mlp/fc2/Add_output_0: 3ce24283
/model/vision_model/vision_model/encoder/layers.17/Add_1_output_0: 3fa712a3
/model/language_model/model/layers.15/self_attn/Add_2_output_0: 4480ff80
/model/language_model/model/layers.15/self_attn/Slice_4_output_0: 4400f9f3
/model/vision_model/vision_model/encoder/layers.18/layer_norm1/LayerNormalization_output_0: 3e09ebeb
onnx::MatMul_9371_output: 3a63f204
ONNXTRT_Broadcast_2006_output: 3a63f204
/model/vision_model/vision_model/encoder/layers.18/self_attn/q_proj/MatMul_output_0: 3d60c016
backbone.model.vision_model.vision_model.encoder.layers.18.self_attn.q_proj.bias_output: 3d903f8f
ONNXTRT_Broadcast_2008_output: 3d903f8f
/model/vision_model/vision_model/encoder/layers.18/self_attn/q_proj/Add_output_0: 3dc666b1
onnx::MatMul_9372_output: 3a650cda
ONNXTRT_Broadcast_2010_output: 3a650cda
/model/vision_model/vision_model/encoder/layers.18/self_attn/k_proj/MatMul_output_0: 3d433af0
backbone.model.vision_model.vision_model.encoder.layers.18.self_attn.k_proj.bias_output: 3c051871
ONNXTRT_Broadcast_2012_output: 3c051871
/model/vision_model/vision_model/encoder/layers.18/self_attn/k_proj/Add_output_0: 3d5513cd
onnx::MatMul_9373_output: 3a1443e8
ONNXTRT_Broadcast_2014_output: 3a1443e8
/model/vision_model/vision_model/encoder/layers.18/self_attn/v_proj/MatMul_output_0: 3cff6620
backbone.model.vision_model.vision_model.encoder.layers.18.self_attn.v_proj.bias_output: 3b7711a3
ONNXTRT_Broadcast_2016_output: 3b7711a3
/model/vision_model/vision_model/encoder/layers.18/self_attn/v_proj/Add_output_0: 3d0bc275
/model/vision_model/vision_model/encoder/layers.18/self_attn/Reshape_output_0: 3dc666b1
/model/vision_model/vision_model/encoder/layers.18/self_attn/Reshape_1_output_0: 3d5513cd
/model/vision_model/vision_model/encoder/layers.18/self_attn/Reshape_2_output_0: 3d0bc275
/model/vision_model/vision_model/encoder/layers.18/self_attn/Transpose_output_0: 3d0bc275
/model/vision_model/vision_model/encoder/layers.18/self_attn/Transpose_1_output_0: 3dc666b1
/model/vision_model/vision_model/encoder/layers.18/self_attn/Transpose_2_output_0: 3d5513cd
/model/vision_model/vision_model/encoder/layers.18/self_attn/MatMul_output_0: 3f4bf1c6
/model/vision_model/vision_model/encoder/layers.18/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2021_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.18/self_attn/Mul_output_0: 3dc04b16
/model/vision_model/vision_model/encoder/layers.18/self_attn/Softmax_output: 3a7ed527
/model/vision_model/vision_model/encoder/layers.18/self_attn/Softmax_output_0: 3a7ed527
/model/vision_model/vision_model/encoder/layers.18/self_attn/Cast_output_0: 3a7ed527
/model/vision_model/vision_model/encoder/layers.18/self_attn/Cast_1_output_0: 3a7ed527
/model/vision_model/vision_model/encoder/layers.18/self_attn/MatMul_1_output_0: 3c866d55
/model/vision_model/vision_model/encoder/layers.18/self_attn/Transpose_3_output_0: 3c866d55
/model/vision_model/vision_model/encoder/layers.18/self_attn/Reshape_3_output_0: 3c866d55
onnx::MatMul_9393_output: 3a094122
ONNXTRT_Broadcast_2025_output: 3a094122
/model/vision_model/vision_model/encoder/layers.18/self_attn/out_proj/MatMul_output_0: 3c69056e
backbone.model.vision_model.vision_model.encoder.layers.18.self_attn.out_proj.bias_output: 3b915000
ONNXTRT_Broadcast_2027_output: 3b915000
/model/vision_model/vision_model/encoder/layers.18/self_attn/out_proj/Add_output_0: 3c2e656b
/model/vision_model/vision_model/encoder/layers.18/Add_output_0: 3fa85ff6
/model/language_model/model/layers.10/post_attention_layernorm/Cast_output_0: 40ffb039
/model/language_model/model/layers.15/self_attn/Concat_3_output_0: 3dc873a4
/model/vision_model/vision_model/encoder/layers.18/layer_norm2/LayerNormalization_output_0: 3e531e71
onnx::MatMul_9394_output: 3a155d1a
ONNXTRT_Broadcast_2035_output: 3a155d1a
/model/vision_model/vision_model/encoder/layers.18/mlp/fc1/MatMul_output_0: 3e1539e9
backbone.model.vision_model.vision_model.encoder.layers.18.mlp.fc1.bias_output: 3cceaa24
ONNXTRT_Broadcast_2037_output: 3cceaa24
/model/vision_model/vision_model/encoder/layers.18/mlp/fc1/Add_output_0: 3e236d0f
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Mul_output_0: 4050e36a
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Mul_1_output_0: 4248d112
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2039_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Mul_2_output_0: 400fa68e
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Add_output_0: 401483a1
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2041_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Mul_3_output_0: 3fecfc0a
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2043_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Mul_4_output_0: 3db1ec15
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2045_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.18/mlp/activation_fn/Mul_5_output_0: 3d31ec15
onnx::MatMul_9395_output: 3a0f7020
ONNXTRT_Broadcast_2047_output: 3a0f7020
/model/vision_model/vision_model/encoder/layers.18/mlp/fc2/MatMul_output_0: 3c2e11a2
backbone.model.vision_model.vision_model.encoder.layers.18.mlp.fc2.bias_output: 3b91452a
ONNXTRT_Broadcast_2049_output: 3b91452a
/model/vision_model/vision_model/encoder/layers.18/mlp/fc2/Add_output_0: 3c8cfab0
/model/vision_model/vision_model/encoder/layers.18/Add_1_output_0: 3fa4b7b2
/model/language_model/model/layers.14/self_attn/q_proj/MatMul_output_0: 3ea7afbb
/model/language_model/model/layers.14/self_attn/q_norm/Mul_1_output_0: 3e036a52
/model/vision_model/vision_model/encoder/layers.19/layer_norm1/LayerNormalization_output_0: 3e0ea72b
onnx::MatMul_9396_output: 3a5ee000
ONNXTRT_Broadcast_2057_output: 3a5ee000
/model/vision_model/vision_model/encoder/layers.19/self_attn/q_proj/MatMul_output_0: 3d6866e7
backbone.model.vision_model.vision_model.encoder.layers.19.self_attn.q_proj.bias_output: 3d9d50d2
ONNXTRT_Broadcast_2059_output: 3d9d50d2
/model/vision_model/vision_model/encoder/layers.19/self_attn/q_proj/Add_output_0: 3dd878cb
onnx::MatMul_9397_output: 3a165af6
ONNXTRT_Broadcast_2061_output: 3a165af6
/model/vision_model/vision_model/encoder/layers.19/self_attn/k_proj/MatMul_output_0: 3d4bfeea
backbone.model.vision_model.vision_model.encoder.layers.19.self_attn.k_proj.bias_output: 3bfa20c2
ONNXTRT_Broadcast_2063_output: 3bfa20c2
/model/vision_model/vision_model/encoder/layers.19/self_attn/k_proj/Add_output_0: 3d54e0a0
onnx::MatMul_9398_output: 3a1843f8
ONNXTRT_Broadcast_2065_output: 3a1843f8
/model/vision_model/vision_model/encoder/layers.19/self_attn/v_proj/MatMul_output_0: 3d10caa0
backbone.model.vision_model.vision_model.encoder.layers.19.self_attn.v_proj.bias_output: 3abdca14
ONNXTRT_Broadcast_2067_output: 3abdca14
/model/vision_model/vision_model/encoder/layers.19/self_attn/v_proj/Add_output_0: 3d0462da
/model/vision_model/vision_model/encoder/layers.19/self_attn/Reshape_output_0: 3dd878cb
/model/vision_model/vision_model/encoder/layers.19/self_attn/Reshape_1_output_0: 3d54e0a0
/model/vision_model/vision_model/encoder/layers.19/self_attn/Reshape_2_output_0: 3d0462da
/model/vision_model/vision_model/encoder/layers.19/self_attn/Transpose_output_0: 3d0462da
/model/vision_model/vision_model/encoder/layers.19/self_attn/Transpose_1_output_0: 3dd878cb
/model/vision_model/vision_model/encoder/layers.19/self_attn/Transpose_2_output_0: 3d54e0a0
/model/vision_model/vision_model/encoder/layers.19/self_attn/MatMul_output_0: 3f6ce8ff
/model/vision_model/vision_model/encoder/layers.19/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2072_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.19/self_attn/Mul_output_0: 3ddf602e
/model/vision_model/vision_model/encoder/layers.19/self_attn/Softmax_output: 3a4e8d72
/model/vision_model/vision_model/encoder/layers.19/self_attn/Softmax_output_0: 3a4e8d72
/model/vision_model/vision_model/encoder/layers.19/self_attn/Cast_output_0: 3a4e8d72
/model/vision_model/vision_model/encoder/layers.19/self_attn/Cast_1_output_0: 3a4e8d72
/model/vision_model/vision_model/encoder/layers.19/self_attn/MatMul_1_output_0: 3c872108
/model/vision_model/vision_model/encoder/layers.19/self_attn/Transpose_3_output_0: 3c872108
/model/vision_model/vision_model/encoder/layers.19/self_attn/Reshape_3_output_0: 3c872108
onnx::MatMul_9418_output: 3a0a3c18
ONNXTRT_Broadcast_2076_output: 3a0a3c18
/model/vision_model/vision_model/encoder/layers.19/self_attn/out_proj/MatMul_output_0: 3c6ef78f
backbone.model.vision_model.vision_model.encoder.layers.19.self_attn.out_proj.bias_output: 3bbed56b
ONNXTRT_Broadcast_2078_output: 3bbed56b
/model/vision_model/vision_model/encoder/layers.19/self_attn/out_proj/Add_output_0: 3c926553
/model/vision_model/vision_model/encoder/layers.19/Add_output_0: 3fa72186
/model/language_model/model/layers.10/self_attn/Neg_output_0: 3e052631
/model/language_model/model/layers.14/self_attn/MatMul_output_0: 3fcde925
/model/vision_model/vision_model/encoder/layers.19/layer_norm2/LayerNormalization_output_0: 3e7fcef7
onnx::MatMul_9419_output: 3a0e468d
ONNXTRT_Broadcast_2086_output: 3a0e468d
/model/vision_model/vision_model/encoder/layers.19/mlp/fc1/MatMul_output_0: 3e33b98c
backbone.model.vision_model.vision_model.encoder.layers.19.mlp.fc1.bias_output: 3cb07d6b
ONNXTRT_Broadcast_2088_output: 3cb07d6b
/model/vision_model/vision_model/encoder/layers.19/mlp/fc1/Add_output_0: 3e39fa1a
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Mul_output_0: 40852231
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Mul_1_output_0: 42a8992a
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2090_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Mul_2_output_0: 40713520
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Add_output_0: 4054d91c
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2092_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Mul_3_output_0: 4029d238
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2094_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Mul_4_output_0: 3df7eaee
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2096_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.19/mlp/activation_fn/Mul_5_output_0: 3d77eaee
onnx::MatMul_9420_output: 39eca143
ONNXTRT_Broadcast_2098_output: 39eca143
/model/vision_model/vision_model/encoder/layers.19/mlp/fc2/MatMul_output_0: 3c1b8282
backbone.model.vision_model.vision_model.encoder.layers.19.mlp.fc2.bias_output: 3bd615ec
ONNXTRT_Broadcast_2100_output: 3bd615ec
/model/vision_model/vision_model/encoder/layers.19/mlp/fc2/Add_output_0: 3cdc897a
/model/vision_model/vision_model/encoder/layers.19/Add_1_output_0: 3fa4bf10
/model/language_model/model/layers.2/self_attn/Slice_2_output_0: 3df56111
ONNXTRT_Broadcast_5180_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.20/layer_norm1/LayerNormalization_output_0: 3e0679db
onnx::MatMul_9421_output: 3a4eccb9
ONNXTRT_Broadcast_2108_output: 3a4eccb9
/model/vision_model/vision_model/encoder/layers.20/self_attn/q_proj/MatMul_output_0: 3d61b17d
backbone.model.vision_model.vision_model.encoder.layers.20.self_attn.q_proj.bias_output: 3d8f3000
ONNXTRT_Broadcast_2110_output: 3d8f3000
/model/vision_model/vision_model/encoder/layers.20/self_attn/q_proj/Add_output_0: 3dd3fa25
onnx::MatMul_9422_output: 3a3391a3
ONNXTRT_Broadcast_2112_output: 3a3391a3
/model/vision_model/vision_model/encoder/layers.20/self_attn/k_proj/MatMul_output_0: 3d6ee6a6
backbone.model.vision_model.vision_model.encoder.layers.20.self_attn.k_proj.bias_output: 3c082922
ONNXTRT_Broadcast_2114_output: 3c082922
/model/vision_model/vision_model/encoder/layers.20/self_attn/k_proj/Add_output_0: 3d7496b3
onnx::MatMul_9423_output: 3a2b7245
ONNXTRT_Broadcast_2116_output: 3a2b7245
/model/vision_model/vision_model/encoder/layers.20/self_attn/v_proj/MatMul_output_0: 3d12b2d9
backbone.model.vision_model.vision_model.encoder.layers.20.self_attn.v_proj.bias_output: 3b0f5d3a
ONNXTRT_Broadcast_2118_output: 3b0f5d3a
/model/vision_model/vision_model/encoder/layers.20/self_attn/v_proj/Add_output_0: 3d21f09d
/model/vision_model/vision_model/encoder/layers.20/self_attn/Reshape_output_0: 3dd3fa25
/model/vision_model/vision_model/encoder/layers.20/self_attn/Reshape_1_output_0: 3d7496b3
/model/vision_model/vision_model/encoder/layers.20/self_attn/Reshape_2_output_0: 3d21f09d
/model/vision_model/vision_model/encoder/layers.20/self_attn/Transpose_output_0: 3d21f09d
/model/vision_model/vision_model/encoder/layers.20/self_attn/Transpose_1_output_0: 3dd3fa25
/model/vision_model/vision_model/encoder/layers.20/self_attn/Transpose_2_output_0: 3d7496b3
/model/vision_model/vision_model/encoder/layers.20/self_attn/MatMul_output_0: 3f457268
/model/vision_model/vision_model/encoder/layers.20/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2123_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.20/self_attn/Mul_output_0: 3dba2abe
/model/vision_model/vision_model/encoder/layers.20/self_attn/Softmax_output: 3a57444a
/model/vision_model/vision_model/encoder/layers.20/self_attn/Softmax_output_0: 3a57444a
/model/vision_model/vision_model/encoder/layers.20/self_attn/Cast_output_0: 3a57444a
/model/vision_model/vision_model/encoder/layers.20/self_attn/Cast_1_output_0: 3a57444a
/model/vision_model/vision_model/encoder/layers.20/self_attn/MatMul_1_output_0: 3cc31a41
/model/vision_model/vision_model/encoder/layers.20/self_attn/Transpose_3_output_0: 3cc31a41
/model/vision_model/vision_model/encoder/layers.20/self_attn/Reshape_3_output_0: 3cc31a41
onnx::MatMul_9443_output: 3a185ab5
ONNXTRT_Broadcast_2127_output: 3a185ab5
/model/vision_model/vision_model/encoder/layers.20/self_attn/out_proj/MatMul_output_0: 3ca17d17
backbone.model.vision_model.vision_model.encoder.layers.20.self_attn.out_proj.bias_output: 3bff2993
ONNXTRT_Broadcast_2129_output: 3bff2993
/model/vision_model/vision_model/encoder/layers.20/self_attn/out_proj/Add_output_0: 3cd976b7
/model/vision_model/vision_model/encoder/layers.20/Add_output_0: 3fa6f73b
/model/language_model/model/layers.5/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.5/self_attn/Add_output_0: 3e13cb79
/model/vision_model/vision_model/encoder/layers.20/layer_norm2/LayerNormalization_output_0: 3eb69d2d
onnx::MatMul_9444_output: 3a248dbb
ONNXTRT_Broadcast_2137_output: 3a248dbb
/model/vision_model/vision_model/encoder/layers.20/mlp/fc1/MatMul_output_0: 3ed3174b
backbone.model.vision_model.vision_model.encoder.layers.20.mlp.fc1.bias_output: 3cae98b1
ONNXTRT_Broadcast_2139_output: 3cae98b1
/model/vision_model/vision_model/encoder/layers.20/mlp/fc1/Add_output_0: 3ed63761
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Mul_output_0: 4187a669
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Mul_1_output_0: 438fc71d
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2141_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Mul_2_output_0: 414db29e
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Add_output_0: 4151e357
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2143_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Mul_3_output_0: 412775a2
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2145_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Mul_4_output_0: 3e327776
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2147_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.20/mlp/activation_fn/Mul_5_output_0: 3db27776
onnx::MatMul_9445_output: 3a0a94a9
ONNXTRT_Broadcast_2149_output: 3a0a94a9
/model/vision_model/vision_model/encoder/layers.20/mlp/fc2/MatMul_output_0: 3cdb7c2d
backbone.model.vision_model.vision_model.encoder.layers.20.mlp.fc2.bias_output: 3c4cd2a5
ONNXTRT_Broadcast_2151_output: 3c4cd2a5
/model/vision_model/vision_model/encoder/layers.20/mlp/fc2/Add_output_0: 3cee85a4
/model/vision_model/vision_model/encoder/layers.20/Add_1_output_0: 3fa80573
/model/language_model/model/layers.13/self_attn/q_norm/Cast_1_output_0: 3d4c5302
/model/language_model/model/layers.8/mlp/gate_proj/MatMul_output_0: 3d4a7cab
/model/vision_model/vision_model/encoder/layers.21/layer_norm1/LayerNormalization_output_0: 3df12425
onnx::MatMul_9446_output: 3a53c5ec
ONNXTRT_Broadcast_2159_output: 3a53c5ec
/model/vision_model/vision_model/encoder/layers.21/self_attn/q_proj/MatMul_output_0: 3d73328d
backbone.model.vision_model.vision_model.encoder.layers.21.self_attn.q_proj.bias_output: 3d9545dc
ONNXTRT_Broadcast_2161_output: 3d9545dc
/model/vision_model/vision_model/encoder/layers.21/self_attn/q_proj/Add_output_0: 3dcd11aa
onnx::MatMul_9447_output: 3a45c9d4
ONNXTRT_Broadcast_2163_output: 3a45c9d4
/model/vision_model/vision_model/encoder/layers.21/self_attn/k_proj/MatMul_output_0: 3d5ea6e7
backbone.model.vision_model.vision_model.encoder.layers.21.self_attn.k_proj.bias_output: 3bc49983
ONNXTRT_Broadcast_2165_output: 3bc49983
/model/vision_model/vision_model/encoder/layers.21/self_attn/k_proj/Add_output_0: 3d75a2c7
onnx::MatMul_9448_output: 3a134993
ONNXTRT_Broadcast_2167_output: 3a134993
/model/vision_model/vision_model/encoder/layers.21/self_attn/v_proj/MatMul_output_0: 3d26f7e7
backbone.model.vision_model.vision_model.encoder.layers.21.self_attn.v_proj.bias_output: 3b670c59
ONNXTRT_Broadcast_2169_output: 3b670c59
/model/vision_model/vision_model/encoder/layers.21/self_attn/v_proj/Add_output_0: 3d345b3d
/model/vision_model/vision_model/encoder/layers.21/self_attn/Reshape_output_0: 3dcd11aa
/model/vision_model/vision_model/encoder/layers.21/self_attn/Reshape_1_output_0: 3d75a2c7
/model/vision_model/vision_model/encoder/layers.21/self_attn/Reshape_2_output_0: 3d345b3d
/model/vision_model/vision_model/encoder/layers.21/self_attn/Transpose_output_0: 3d345b3d
/model/vision_model/vision_model/encoder/layers.21/self_attn/Transpose_1_output_0: 3dcd11aa
/model/vision_model/vision_model/encoder/layers.21/self_attn/Transpose_2_output_0: 3d75a2c7
/model/vision_model/vision_model/encoder/layers.21/self_attn/MatMul_output_0: 3f4a8798
/model/vision_model/vision_model/encoder/layers.21/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2174_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.21/self_attn/Mul_output_0: 3dbef598
/model/vision_model/vision_model/encoder/layers.21/self_attn/Softmax_output: 3a6fbd08
/model/vision_model/vision_model/encoder/layers.21/self_attn/Softmax_output_0: 3a6fbd08
/model/vision_model/vision_model/encoder/layers.21/self_attn/Cast_output_0: 3a6fbd08
/model/vision_model/vision_model/encoder/layers.21/self_attn/Cast_1_output_0: 3a6fbd08
/model/vision_model/vision_model/encoder/layers.21/self_attn/MatMul_1_output_0: 3cdb57ef
/model/vision_model/vision_model/encoder/layers.21/self_attn/Transpose_3_output_0: 3cdb57ef
/model/vision_model/vision_model/encoder/layers.21/self_attn/Reshape_3_output_0: 3cdb57ef
onnx::MatMul_9468_output: 3a134bb7
ONNXTRT_Broadcast_2178_output: 3a134bb7
/model/vision_model/vision_model/encoder/layers.21/self_attn/out_proj/MatMul_output_0: 3cdffe27
backbone.model.vision_model.vision_model.encoder.layers.21.self_attn.out_proj.bias_output: 3bfe1912
ONNXTRT_Broadcast_2180_output: 3bfe1912
/model/vision_model/vision_model/encoder/layers.21/self_attn/out_proj/Add_output_0: 3d0de7e8
/model/vision_model/vision_model/encoder/layers.21/Add_output_0: 3fa91d1e
ONNXTRT_Broadcast_7031_output: 3b3c89e4
ONNXTRT_Broadcast_3849_output: 3ac3c245
/model/vision_model/vision_model/encoder/layers.21/layer_norm2/LayerNormalization_output_0: 3ebc43d5
onnx::MatMul_9469_output: 3a2c81a3
ONNXTRT_Broadcast_2188_output: 3a2c81a3
/model/vision_model/vision_model/encoder/layers.21/mlp/fc1/MatMul_output_0: 3e97185c
backbone.model.vision_model.vision_model.encoder.layers.21.mlp.fc1.bias_output: 3cae6e7d
ONNXTRT_Broadcast_2190_output: 3cae6e7d
/model/vision_model/vision_model/encoder/layers.21/mlp/fc1/Add_output_0: 3e981998
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Mul_output_0: 41222bc5
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Mul_1_output_0: 43b0775f
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2192_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Mul_2_output_0: 417c76c7
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Add_output_0: 417f48f7
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2194_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Mul_3_output_0: 414badf7
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2196_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Mul_4_output_0: 3e33d814
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2198_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.21/mlp/activation_fn/Mul_5_output_0: 3db3d814
onnx::MatMul_9470_output: 3a2a9489
ONNXTRT_Broadcast_2200_output: 3a2a9489
/model/vision_model/vision_model/encoder/layers.21/mlp/fc2/MatMul_output_0: 3bfdd298
backbone.model.vision_model.vision_model.encoder.layers.21.mlp.fc2.bias_output: 3c073f3e
ONNXTRT_Broadcast_2202_output: 3c073f3e
/model/vision_model/vision_model/encoder/layers.21/mlp/fc2/Add_output_0: 3d137ba3
/model/vision_model/vision_model/encoder/layers.21/Add_1_output_0: 3fa8311b
onnx::MatMul_9862_output: 3ad7e54b
onnx::MatMul_9863_output: 3ac4bbd8
/model/vision_model/vision_model/encoder/layers.22/layer_norm1/LayerNormalization_output_0: 3e1521c5
onnx::MatMul_9471_output: 3a43af1e
ONNXTRT_Broadcast_2210_output: 3a43af1e
/model/vision_model/vision_model/encoder/layers.22/self_attn/q_proj/MatMul_output_0: 3d6972e9
backbone.model.vision_model.vision_model.encoder.layers.22.self_attn.q_proj.bias_output: 3d82161c
ONNXTRT_Broadcast_2212_output: 3d82161c
/model/vision_model/vision_model/encoder/layers.22/self_attn/q_proj/Add_output_0: 3dbb0bab
onnx::MatMul_9472_output: 3a33a0e2
ONNXTRT_Broadcast_2214_output: 3a33a0e2
/model/vision_model/vision_model/encoder/layers.22/self_attn/k_proj/MatMul_output_0: 3d6ad889
backbone.model.vision_model.vision_model.encoder.layers.22.self_attn.k_proj.bias_output: 3c00890a
ONNXTRT_Broadcast_2216_output: 3c00890a
/model/vision_model/vision_model/encoder/layers.22/self_attn/k_proj/Add_output_0: 3d819ef5
onnx::MatMul_9473_output: 3a1853e8
ONNXTRT_Broadcast_2218_output: 3a1853e8
/model/vision_model/vision_model/encoder/layers.22/self_attn/v_proj/MatMul_output_0: 3d23dcb1
backbone.model.vision_model.vision_model.encoder.layers.22.self_attn.v_proj.bias_output: 3be8f245
ONNXTRT_Broadcast_2220_output: 3be8f245
/model/vision_model/vision_model/encoder/layers.22/self_attn/v_proj/Add_output_0: 3d2e02ea
/model/vision_model/vision_model/encoder/layers.22/self_attn/Reshape_output_0: 3dbb0bab
/model/vision_model/vision_model/encoder/layers.22/self_attn/Reshape_1_output_0: 3d819ef5
/model/vision_model/vision_model/encoder/layers.22/self_attn/Reshape_2_output_0: 3d2e02ea
/model/vision_model/vision_model/encoder/layers.22/self_attn/Transpose_output_0: 3d2e02ea
/model/vision_model/vision_model/encoder/layers.22/self_attn/Transpose_1_output_0: 3dbb0bab
/model/vision_model/vision_model/encoder/layers.22/self_attn/Transpose_2_output_0: 3d819ef5
/model/vision_model/vision_model/encoder/layers.22/self_attn/MatMul_output_0: 3f85f209
/model/vision_model/vision_model/encoder/layers.22/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2225_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.22/self_attn/Mul_output_0: 3dfc962a
/model/vision_model/vision_model/encoder/layers.22/self_attn/Softmax_output: 3a990fe3
/model/vision_model/vision_model/encoder/layers.22/self_attn/Softmax_output_0: 3a990fe3
/model/vision_model/vision_model/encoder/layers.22/self_attn/Cast_output_0: 3a990fe3
/model/vision_model/vision_model/encoder/layers.22/self_attn/Cast_1_output_0: 3a990fe3
/model/vision_model/vision_model/encoder/layers.22/self_attn/MatMul_1_output_0: 3d1e20f9
/model/vision_model/vision_model/encoder/layers.22/self_attn/Transpose_3_output_0: 3d1e20f9
/model/vision_model/vision_model/encoder/layers.22/self_attn/Reshape_3_output_0: 3d1e20f9
onnx::MatMul_9493_output: 3a32adbb
ONNXTRT_Broadcast_2229_output: 3a32adbb
/model/vision_model/vision_model/encoder/layers.22/self_attn/out_proj/MatMul_output_0: 3d5bb62d
backbone.model.vision_model.vision_model.encoder.layers.22.self_attn.out_proj.bias_output: 3bd9de1c
ONNXTRT_Broadcast_2231_output: 3bd9de1c
/model/vision_model/vision_model/encoder/layers.22/self_attn/out_proj/Add_output_0: 3d5b9777
/model/vision_model/vision_model/encoder/layers.22/Add_output_0: 3faa5d5c
/model/language_model/model/layers.4/input_layernorm/Mul_output_0: 3df7e714
/model/language_model/model/layers.15/self_attn/Mul_1_output_0: 3cf4dfaa
/model/vision_model/vision_model/encoder/layers.22/layer_norm2/LayerNormalization_output_0: 3ee541f5
onnx::MatMul_9494_output: 3a2f9102
ONNXTRT_Broadcast_2239_output: 3a2f9102
/model/vision_model/vision_model/encoder/layers.22/mlp/fc1/MatMul_output_0: 3ea0df02
backbone.model.vision_model.vision_model.encoder.layers.22.mlp.fc1.bias_output: 3cbb99f4
ONNXTRT_Broadcast_2241_output: 3cbb99f4
/model/vision_model/vision_model/encoder/layers.22/mlp/fc1/Add_output_0: 3eaa5deb
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Mul_output_0: 41512555
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Mul_1_output_0: 43f49f79
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2243_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Mul_2_output_0: 41aefc93
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Add_output_0: 41b0ee57
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2245_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Mul_3_output_0: 418d2a29
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2247_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Mul_4_output_0: 3e3a59fd
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2249_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.22/mlp/activation_fn/Mul_5_output_0: 3dba59fd
onnx::MatMul_9495_output: 3a2c6e9d
ONNXTRT_Broadcast_2251_output: 3a2c6e9d
/model/vision_model/vision_model/encoder/layers.22/mlp/fc2/MatMul_output_0: 3c1f007d
backbone.model.vision_model.vision_model.encoder.layers.22.mlp.fc2.bias_output: 3ca48b97
ONNXTRT_Broadcast_2253_output: 3ca48b97
/model/vision_model/vision_model/encoder/layers.22/mlp/fc2/Add_output_0: 3d4f1772
/model/vision_model/vision_model/encoder/layers.22/Add_1_output_0: 3fa96bdd
/model/language_model/model/layers.2/self_attn/Neg_1_output_0: 3f6cb711
backbone.model.language_model.model.layers.11.input_layernorm.weight_output: 3c9c8306
/model/vision_model/vision_model/encoder/layers.23/layer_norm1/LayerNormalization_output_0: 3e041b12
onnx::MatMul_9496_output: 3a3897d0
ONNXTRT_Broadcast_2261_output: 3a3897d0
/model/vision_model/vision_model/encoder/layers.23/self_attn/q_proj/MatMul_output_0: 3d7a982e
backbone.model.vision_model.vision_model.encoder.layers.23.self_attn.q_proj.bias_output: 3d731a55
ONNXTRT_Broadcast_2263_output: 3d731a55
/model/vision_model/vision_model/encoder/layers.23/self_attn/q_proj/Add_output_0: 3db74ce7
onnx::MatMul_9497_output: 3a216810
ONNXTRT_Broadcast_2265_output: 3a216810
/model/vision_model/vision_model/encoder/layers.23/self_attn/k_proj/MatMul_output_0: 3d5bb627
backbone.model.vision_model.vision_model.encoder.layers.23.self_attn.k_proj.bias_output: 3c0a1cca
ONNXTRT_Broadcast_2267_output: 3c0a1cca
/model/vision_model/vision_model/encoder/layers.23/self_attn/k_proj/Add_output_0: 3d59833f
onnx::MatMul_9498_output: 3a2473c8
ONNXTRT_Broadcast_2269_output: 3a2473c8
/model/vision_model/vision_model/encoder/layers.23/self_attn/v_proj/MatMul_output_0: 3d244151
backbone.model.vision_model.vision_model.encoder.layers.23.self_attn.v_proj.bias_output: 3bfc2993
ONNXTRT_Broadcast_2271_output: 3bfc2993
/model/vision_model/vision_model/encoder/layers.23/self_attn/v_proj/Add_output_0: 3d35aeb7
/model/vision_model/vision_model/encoder/layers.23/self_attn/Reshape_output_0: 3db74ce7
/model/vision_model/vision_model/encoder/layers.23/self_attn/Reshape_1_output_0: 3d59833f
/model/vision_model/vision_model/encoder/layers.23/self_attn/Reshape_2_output_0: 3d35aeb7
/model/vision_model/vision_model/encoder/layers.23/self_attn/Transpose_output_0: 3d35aeb7
/model/vision_model/vision_model/encoder/layers.23/self_attn/Transpose_1_output_0: 3db74ce7
/model/vision_model/vision_model/encoder/layers.23/self_attn/Transpose_2_output_0: 3d59833f
/model/vision_model/vision_model/encoder/layers.23/self_attn/MatMul_output_0: 3f84923b
/model/vision_model/vision_model/encoder/layers.23/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2276_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.23/self_attn/Mul_output_0: 3dfb64e5
/model/vision_model/vision_model/encoder/layers.23/self_attn/Softmax_output: 3a81efd5
/model/vision_model/vision_model/encoder/layers.23/self_attn/Softmax_output_0: 3a81efd5
/model/vision_model/vision_model/encoder/layers.23/self_attn/Cast_output_0: 3a81efd5
/model/vision_model/vision_model/encoder/layers.23/self_attn/Cast_1_output_0: 3a81efd5
/model/vision_model/vision_model/encoder/layers.23/self_attn/MatMul_1_output_0: 3ce5d146
/model/vision_model/vision_model/encoder/layers.23/self_attn/Transpose_3_output_0: 3ce5d146
/model/vision_model/vision_model/encoder/layers.23/self_attn/Reshape_3_output_0: 3ce5d146
onnx::MatMul_9518_output: 3a217dfc
ONNXTRT_Broadcast_2280_output: 3a217dfc
/model/vision_model/vision_model/encoder/layers.23/self_attn/out_proj/MatMul_output_0: 3d5699e7
backbone.model.vision_model.vision_model.encoder.layers.23.self_attn.out_proj.bias_output: 3c0f31a3
ONNXTRT_Broadcast_2282_output: 3c0f31a3
/model/vision_model/vision_model/encoder/layers.23/self_attn/out_proj/Add_output_0: 3d3024da
/model/vision_model/vision_model/encoder/layers.23/Add_output_0: 3faa605d
ONNXTRT_Broadcast_6517_output: 3d193bf8
/model/language_model/model/layers.10/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/vision_model/vision_model/encoder/layers.23/layer_norm2/LayerNormalization_output_0: 3efa6da5
onnx::MatMul_9519_output: 3a2586ce
ONNXTRT_Broadcast_2290_output: 3a2586ce
/model/vision_model/vision_model/encoder/layers.23/mlp/fc1/MatMul_output_0: 3eb78869
backbone.model.vision_model.vision_model.encoder.layers.23.mlp.fc1.bias_output: 3caf7ece
ONNXTRT_Broadcast_2292_output: 3caf7ece
/model/vision_model/vision_model/encoder/layers.23/mlp/fc1/Add_output_0: 3ebc8a38
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Mul_output_0: 418147c6
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Mul_1_output_0: 4428ecff
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2294_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Mul_2_output_0: 41f1ad0f
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Add_output_0: 41f39207
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2296_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Mul_3_output_0: 41c25542
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2298_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Mul_4_output_0: 3ec50499
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2300_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.23/mlp/activation_fn/Mul_5_output_0: 3e450499
onnx::MatMul_9520_output: 3a4eccb9
ONNXTRT_Broadcast_2302_output: 3a4eccb9
/model/vision_model/vision_model/encoder/layers.23/mlp/fc2/MatMul_output_0: 3c84813a
backbone.model.vision_model.vision_model.encoder.layers.23.mlp.fc2.bias_output: 3c3c0d5b
ONNXTRT_Broadcast_2304_output: 3c3c0d5b
/model/vision_model/vision_model/encoder/layers.23/mlp/fc2/Add_output_0: 3d61d486
/model/vision_model/vision_model/encoder/layers.23/Add_1_output_0: 3fa84b86
/model/language_model/model/layers.15/self_attn/Expand_1_output_0: 3e974f2f
ONNXTRT_Broadcast_5184_output: 3aab7b67
/model/vision_model/vision_model/encoder/layers.24/layer_norm1/LayerNormalization_output_0: 3e08384b
onnx::MatMul_9521_output: 3a3388f2
ONNXTRT_Broadcast_2312_output: 3a3388f2
/model/vision_model/vision_model/encoder/layers.24/self_attn/q_proj/MatMul_output_0: 3d5d15e3
backbone.model.vision_model.vision_model.encoder.layers.24.self_attn.q_proj.bias_output: 3d57d66d
ONNXTRT_Broadcast_2314_output: 3d57d66d
/model/vision_model/vision_model/encoder/layers.24/self_attn/q_proj/Add_output_0: 3da1324f
onnx::MatMul_9522_output: 3a194f5f
ONNXTRT_Broadcast_2316_output: 3a194f5f
/model/vision_model/vision_model/encoder/layers.24/self_attn/k_proj/MatMul_output_0: 3d6319ee
backbone.model.vision_model.vision_model.encoder.layers.24.self_attn.k_proj.bias_output: 3bd9c58b
ONNXTRT_Broadcast_2318_output: 3bd9c58b
/model/vision_model/vision_model/encoder/layers.24/self_attn/k_proj/Add_output_0: 3d5e55bf
onnx::MatMul_9523_output: 3a3b92e6
ONNXTRT_Broadcast_2320_output: 3a3b92e6
/model/vision_model/vision_model/encoder/layers.24/self_attn/v_proj/MatMul_output_0: 3d454236
backbone.model.vision_model.vision_model.encoder.layers.24.self_attn.v_proj.bias_output: 3bd5dddc
ONNXTRT_Broadcast_2322_output: 3bd5dddc
/model/vision_model/vision_model/encoder/layers.24/self_attn/v_proj/Add_output_0: 3d4425a1
/model/vision_model/vision_model/encoder/layers.24/self_attn/Reshape_output_0: 3da1324f
/model/vision_model/vision_model/encoder/layers.24/self_attn/Reshape_1_output_0: 3d5e55bf
/model/vision_model/vision_model/encoder/layers.24/self_attn/Reshape_2_output_0: 3d4425a1
/model/vision_model/vision_model/encoder/layers.24/self_attn/Transpose_output_0: 3d4425a1
/model/vision_model/vision_model/encoder/layers.24/self_attn/Transpose_1_output_0: 3da1324f
/model/vision_model/vision_model/encoder/layers.24/self_attn/Transpose_2_output_0: 3d5e55bf
/model/vision_model/vision_model/encoder/layers.24/self_attn/MatMul_output_0: 3f4490a2
/model/vision_model/vision_model/encoder/layers.24/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2327_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.24/self_attn/Mul_output_0: 3db955df
/model/vision_model/vision_model/encoder/layers.24/self_attn/Softmax_output: 3a7e68f3
/model/vision_model/vision_model/encoder/layers.24/self_attn/Softmax_output_0: 3a7e68f3
/model/vision_model/vision_model/encoder/layers.24/self_attn/Cast_output_0: 3a7e68f3
/model/vision_model/vision_model/encoder/layers.24/self_attn/Cast_1_output_0: 3a7e68f3
/model/vision_model/vision_model/encoder/layers.24/self_attn/MatMul_1_output_0: 3cf87053
/model/vision_model/vision_model/encoder/layers.24/self_attn/Transpose_3_output_0: 3cf87053
/model/vision_model/vision_model/encoder/layers.24/self_attn/Reshape_3_output_0: 3cf87053
onnx::MatMul_9543_output: 3a2b98b1
ONNXTRT_Broadcast_2331_output: 3a2b98b1
/model/vision_model/vision_model/encoder/layers.24/self_attn/out_proj/MatMul_output_0: 3d87c2cb
backbone.model.vision_model.vision_model.encoder.layers.24.self_attn.out_proj.bias_output: 3c3394a9
ONNXTRT_Broadcast_2333_output: 3c3394a9
/model/vision_model/vision_model/encoder/layers.24/self_attn/out_proj/Add_output_0: 3d351301
/model/vision_model/vision_model/encoder/layers.24/Add_output_0: 3fa9292e
ONNXTRT_Broadcast_5949_output: 3b003dbb
/model/language_model/model/layers.13/post_attention_layernorm/Mul_1_output_0: 3cdb5b0f
/model/vision_model/vision_model/encoder/layers.24/layer_norm2/LayerNormalization_output_0: 3f1b62e8
onnx::MatMul_9544_output: 3a23a9d4
ONNXTRT_Broadcast_2341_output: 3a23a9d4
/model/vision_model/vision_model/encoder/layers.24/mlp/fc1/MatMul_output_0: 3eb4301d
backbone.model.vision_model.vision_model.encoder.layers.24.mlp.fc1.bias_output: 3cbc89e4
ONNXTRT_Broadcast_2343_output: 3cbc89e4
/model/vision_model/vision_model/encoder/layers.24/mlp/fc1/Add_output_0: 3eb5800f
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Mul_output_0: 41713059
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Mul_1_output_0: 44182474
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2345_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Mul_2_output_0: 41d9aa26
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Add_output_0: 41da45ab
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2347_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Mul_3_output_0: 41ae2616
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2349_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Mul_4_output_0: 3eb5bae5
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2351_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.24/mlp/activation_fn/Mul_5_output_0: 3e35bae5
onnx::MatMul_9545_output: 3a2a7d5b
ONNXTRT_Broadcast_2353_output: 3a2a7d5b
/model/vision_model/vision_model/encoder/layers.24/mlp/fc2/MatMul_output_0: 3d28ba21
backbone.model.vision_model.vision_model.encoder.layers.24.mlp.fc2.bias_output: 3c8f4489
ONNXTRT_Broadcast_2355_output: 3c8f4489
/model/vision_model/vision_model/encoder/layers.24/mlp/fc2/Add_output_0: 3d57116a
/model/vision_model/vision_model/encoder/layers.24/Add_1_output_0: 3fa824ff
ONNXTRT_Broadcast_6771_output: 3c010a14
ONNXTRT_Broadcast_4108_output: 3c810a14
/model/vision_model/vision_model/encoder/layers.25/layer_norm1/LayerNormalization_output_0: 3e0cff21
onnx::MatMul_9546_output: 3a48b9f4
ONNXTRT_Broadcast_2363_output: 3a48b9f4
/model/vision_model/vision_model/encoder/layers.25/self_attn/q_proj/MatMul_output_0: 3d3612b9
backbone.model.vision_model.vision_model.encoder.layers.25.self_attn.q_proj.bias_output: 3d5ad275
ONNXTRT_Broadcast_2365_output: 3d5ad275
/model/vision_model/vision_model/encoder/layers.25/self_attn/q_proj/Add_output_0: 3d9a3f48
onnx::MatMul_9547_output: 3a4ebbb7
ONNXTRT_Broadcast_2367_output: 3a4ebbb7
/model/vision_model/vision_model/encoder/layers.25/self_attn/k_proj/MatMul_output_0: 3d4bb9fe
backbone.model.vision_model.vision_model.encoder.layers.25.self_attn.k_proj.bias_output: 3bf1052a
ONNXTRT_Broadcast_2369_output: 3bf1052a
/model/vision_model/vision_model/encoder/layers.25/self_attn/k_proj/Add_output_0: 3d4d6b06
onnx::MatMul_9548_output: 3a3cacda
ONNXTRT_Broadcast_2371_output: 3a3cacda
/model/vision_model/vision_model/encoder/layers.25/self_attn/v_proj/MatMul_output_0: 3d5ce72f
backbone.model.vision_model.vision_model.encoder.layers.25.self_attn.v_proj.bias_output: 3c193bf8
ONNXTRT_Broadcast_2373_output: 3c193bf8
/model/vision_model/vision_model/encoder/layers.25/self_attn/v_proj/Add_output_0: 3d5c2ef4
/model/vision_model/vision_model/encoder/layers.25/self_attn/Reshape_output_0: 3d9a3f48
/model/vision_model/vision_model/encoder/layers.25/self_attn/Reshape_1_output_0: 3d4d6b06
/model/vision_model/vision_model/encoder/layers.25/self_attn/Reshape_2_output_0: 3d5c2ef4
/model/vision_model/vision_model/encoder/layers.25/self_attn/Transpose_output_0: 3d5c2ef4
/model/vision_model/vision_model/encoder/layers.25/self_attn/Transpose_1_output_0: 3d9a3f48
/model/vision_model/vision_model/encoder/layers.25/self_attn/Transpose_2_output_0: 3d4d6b06
/model/vision_model/vision_model/encoder/layers.25/self_attn/MatMul_output_0: 3f89fb3f
/model/vision_model/vision_model/encoder/layers.25/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2378_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.25/self_attn/Mul_output_0: 3e021945
/model/vision_model/vision_model/encoder/layers.25/self_attn/Softmax_output: 3a86cbae
/model/vision_model/vision_model/encoder/layers.25/self_attn/Softmax_output_0: 3a86cbae
/model/vision_model/vision_model/encoder/layers.25/self_attn/Cast_output_0: 3a86cbae
/model/vision_model/vision_model/encoder/layers.25/self_attn/Cast_1_output_0: 3a86cbae
/model/vision_model/vision_model/encoder/layers.25/self_attn/MatMul_1_output_0: 3cefc881
/model/vision_model/vision_model/encoder/layers.25/self_attn/Transpose_3_output_0: 3cefc881
/model/vision_model/vision_model/encoder/layers.25/self_attn/Reshape_3_output_0: 3cefc881
onnx::MatMul_9568_output: 3a3c95cc
ONNXTRT_Broadcast_2382_output: 3a3c95cc
/model/vision_model/vision_model/encoder/layers.25/self_attn/out_proj/MatMul_output_0: 3d7e5eb8
backbone.model.vision_model.vision_model.encoder.layers.25.self_attn.out_proj.bias_output: 3caa75dc
ONNXTRT_Broadcast_2384_output: 3caa75dc
/model/vision_model/vision_model/encoder/layers.25/self_attn/out_proj/Add_output_0: 3d062129
/model/vision_model/vision_model/encoder/layers.25/Add_output_0: 3fae0b20
/model/language_model/model/layers.15/self_attn/Unsqueeze_10_output_0: 3ecddb11
/model/language_model/model/layers.3/self_attn/q_norm/Cast_output_0: 3d72cb6c
/model/vision_model/vision_model/encoder/layers.25/layer_norm2/LayerNormalization_output_0: 3f1a5444
onnx::MatMul_9569_output: 3a1593e8
ONNXTRT_Broadcast_2392_output: 3a1593e8
/model/vision_model/vision_model/encoder/layers.25/mlp/fc1/MatMul_output_0: 3efced32
backbone.model.vision_model.vision_model.encoder.layers.25.mlp.fc1.bias_output: 3cb07347
ONNXTRT_Broadcast_2394_output: 3cb07347
/model/vision_model/vision_model/encoder/layers.25/mlp/fc1/Add_output_0: 3efae8e4
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Mul_output_0: 41a83562
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Mul_1_output_0: 440228ab
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2396_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Mul_2_output_0: 41ba36af
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Add_output_0: 41bee01c
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2398_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Mul_3_output_0: 41984a4f
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2400_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Mul_4_output_0: 3ec8ec99
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2402_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.25/mlp/activation_fn/Mul_5_output_0: 3e48ec99
onnx::MatMul_9570_output: 3a38bfbf
ONNXTRT_Broadcast_2404_output: 3a38bfbf
/model/vision_model/vision_model/encoder/layers.25/mlp/fc2/MatMul_output_0: 3d8f38a2
backbone.model.vision_model.vision_model.encoder.layers.25.mlp.fc2.bias_output: 3c8d3e5d
ONNXTRT_Broadcast_2406_output: 3c8d3e5d
/model/vision_model/vision_model/encoder/layers.25/mlp/fc2/Add_output_0: 3d7ac703
/model/vision_model/vision_model/encoder/layers.25/Add_1_output_0: 3fa77256
onnx::MatMul_9916_output: 3a887020
/model/language_model/model/layers.3/self_attn/Reshape_6_output_0: 3cbdf29d
/model/vision_model/vision_model/encoder/layers.26/layer_norm1/LayerNormalization_output_0: 3e1d7332
onnx::MatMul_9571_output: 3a246e9d
ONNXTRT_Broadcast_2414_output: 3a246e9d
/model/vision_model/vision_model/encoder/layers.26/self_attn/q_proj/MatMul_output_0: 3d3751d2
backbone.model.vision_model.vision_model.encoder.layers.26.self_attn.q_proj.bias_output: 3d3b87f0
ONNXTRT_Broadcast_2416_output: 3d3b87f0
/model/vision_model/vision_model/encoder/layers.26/self_attn/q_proj/Add_output_0: 3d7fc18d
onnx::MatMul_9572_output: 3a256fe0
ONNXTRT_Broadcast_2418_output: 3a256fe0
/model/vision_model/vision_model/encoder/layers.26/self_attn/k_proj/MatMul_output_0: 3d6096fa
backbone.model.vision_model.vision_model.encoder.layers.26.self_attn.k_proj.bias_output: 3be4eede
ONNXTRT_Broadcast_2420_output: 3be4eede
/model/vision_model/vision_model/encoder/layers.26/self_attn/k_proj/Add_output_0: 3d5e9e10
onnx::MatMul_9573_output: 3a793993
ONNXTRT_Broadcast_2422_output: 3a793993
/model/vision_model/vision_model/encoder/layers.26/self_attn/v_proj/MatMul_output_0: 3d841ffd
backbone.model.vision_model.vision_model.encoder.layers.26.self_attn.v_proj.bias_output: 3bdcd081
ONNXTRT_Broadcast_2424_output: 3bdcd081
/model/vision_model/vision_model/encoder/layers.26/self_attn/v_proj/Add_output_0: 3d7e4706
/model/vision_model/vision_model/encoder/layers.26/self_attn/Reshape_output_0: 3d7fc18d
/model/vision_model/vision_model/encoder/layers.26/self_attn/Reshape_1_output_0: 3d5e9e10
/model/vision_model/vision_model/encoder/layers.26/self_attn/Reshape_2_output_0: 3d7e4706
/model/vision_model/vision_model/encoder/layers.26/self_attn/Transpose_output_0: 3d7e4706
/model/vision_model/vision_model/encoder/layers.26/self_attn/Transpose_1_output_0: 3d7fc18d
/model/vision_model/vision_model/encoder/layers.26/self_attn/Transpose_2_output_0: 3d5e9e10
/model/vision_model/vision_model/encoder/layers.26/self_attn/MatMul_output_0: 3f3fa5f4
/model/vision_model/vision_model/encoder/layers.26/self_attn/Constant_3_output_0_output: 3a7355c2
ONNXTRT_Broadcast_2429_output: 3a7355c2
/model/vision_model/vision_model/encoder/layers.26/self_attn/Mul_output_0: 3db4b319
/model/vision_model/vision_model/encoder/layers.26/self_attn/Softmax_output: 3a855895
/model/vision_model/vision_model/encoder/layers.26/self_attn/Softmax_output_0: 3a855895
/model/vision_model/vision_model/encoder/layers.26/self_attn/Cast_output_0: 3a855895
/model/vision_model/vision_model/encoder/layers.26/self_attn/Cast_1_output_0: 3a855895
/model/vision_model/vision_model/encoder/layers.26/self_attn/MatMul_1_output_0: 3d41597a
/model/vision_model/vision_model/encoder/layers.26/self_attn/Transpose_3_output_0: 3d41597a
/model/vision_model/vision_model/encoder/layers.26/self_attn/Reshape_3_output_0: 3d41597a
onnx::MatMul_9593_output: 3a44cf1e
ONNXTRT_Broadcast_2433_output: 3a44cf1e
/model/vision_model/vision_model/encoder/layers.26/self_attn/out_proj/MatMul_output_0: 3de491c6
backbone.model.vision_model.vision_model.encoder.layers.26.self_attn.out_proj.bias_output: 3ca08e3c
ONNXTRT_Broadcast_2435_output: 3ca08e3c
/model/vision_model/vision_model/encoder/layers.26/self_attn/out_proj/Add_output_0: 3da2ce27
/model/vision_model/vision_model/encoder/layers.26/Add_output_0: 3fa6ede4
/model/language_model/model/layers.8/self_attn/k_norm/Mul_output_0: 3d4f20ca
/model/language_model/model/layers.14/self_attn/Cast_4_output_0: 3a7f7efe
/model/vision_model/vision_model/encoder/layers.26/layer_norm2/LayerNormalization_output_0: 3f2bae45
onnx::MatMul_9594_output: 3a1ec50a
ONNXTRT_Broadcast_2443_output: 3a1ec50a
/model/vision_model/vision_model/encoder/layers.26/mlp/fc1/MatMul_output_0: 3f191298
backbone.model.vision_model.vision_model.encoder.layers.26.mlp.fc1.bias_output: 3cdfe62c
ONNXTRT_Broadcast_2445_output: 3cdfe62c
/model/vision_model/vision_model/encoder/layers.26/mlp/fc1/Add_output_0: 3f1726f3
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Mul_output_0: 42066582
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Mul_1_output_0: 46257944
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Constant_output_0_output: 39b89cab
ONNXTRT_Broadcast_2447_output: 39b89cab
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Mul_2_output_0: 43ecbcbd
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Add_output_0: 43ece8f3
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Constant_1_output_0_output: 3bcde895
ONNXTRT_Broadcast_2449_output: 3bcde895
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Mul_3_output_0: 43bd04dc
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Tanh_output_0: 3c010a14
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Constant_2_output_0_output: 3c010a14
ONNXTRT_Broadcast_2451_output: 3c010a14
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Add_1_output_0: 3c810a14
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Mul_4_output_0: 3f9a9963
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Constant_3_output_0_output: 3b810a14
ONNXTRT_Broadcast_2453_output: 3b810a14
/model/vision_model/vision_model/encoder/layers.26/mlp/activation_fn/Mul_5_output_0: 3f1a9963
onnx::MatMul_9595_output: 3a32a993
ONNXTRT_Broadcast_2455_output: 3a32a993
/model/vision_model/vision_model/encoder/layers.26/mlp/fc2/MatMul_output_0: 3f3c7b89
backbone.model.vision_model.vision_model.encoder.layers.26.mlp.fc2.bias_output: 3c5f65cc
ONNXTRT_Broadcast_2457_output: 3c5f65cc
/model/vision_model/vision_model/encoder/layers.26/mlp/fc2/Add_output_0: 3f2fc687
/model/vision_model/vision_model/encoder/layers.26/Add_1_output_0: 3fbee0e0
/model/language_model/model/layers.15/self_attn/Mul_8_output_0: 3e2f9271
ONNXTRT_Broadcast_7232_output: 3a367841
/model/vision_model/vision_model/Gather_output_0: 3e579e8b
/model/Reshape_output_0: 3e579e8b
/model/Split_output_0: 3e564e2c
/model/Split_output_1: 3e5751df
/model/Split_output_2: 3e56e555
/model/Split_output_3: 3e579e8b
/model/Transpose_output_0: 3e564e2c
/model/Reshape_1_output_0: 3e564e2c
/model/Transpose_1_output_0: 3e5751df
/model/Reshape_2_output_0: 3e5751df
/model/Transpose_2_output_0: 3e56e555
/model/Reshape_3_output_0: 3e56e555
/model/Transpose_3_output_0: 3e579e8b
/model/Reshape_4_output_0: 3e579e8b
ONNXTRT_Broadcast_4622_output: 32074ebd
/model/Unsqueeze_output_0: 3e564e2c
/model/language_model/model/layers.11/self_attn/Unsqueeze_19_output_0: 3dc1336e
/model/Unsqueeze_1_output_0: 3e5751df
/model/language_model/model/layers.6/input_layernorm/Pow_output_0: 49face38
/model/Unsqueeze_2_output_0: 3e56e555
/model/language_model/model/layers.6/input_layernorm/Constant_output_0_output: 3c810a14
/model/Unsqueeze_3_output_0: 3e579e8b
/model/Concat_output_0: 3e579e8b
/model/Reshape_5_output_0: 3e579e8b
/model/Transpose_4_output_0: 3e579e8b
/model/Reshape_6_output_0: 3e579e8b
/model/language_model/model/layers.7/mlp/Mul_output_0: 3d1acf20
/model/language_model/model/layers.2/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.9/self_attn/q_norm/Mul_output_0: 3d68f3cb
onnx::MatMul_9823_output: 3ac7c5cc
/model/language_model/model/layers.5/post_attention_layernorm/Mul_1_output_0: 3d0232e1
/model/language_model/model/layers.14/self_attn/Reshape_2_output_0: 3e681d68
/model/language_model/model/layers.5/mlp/Mul_output_0: 3c62dd7d
/model/language_model/model/layers.2/self_attn/k_norm/Mul_1_output_0: 3f6cb711
/model/language_model/model/layers.3/Add_1_output_0: 40ff518d
ONNXTRT_Broadcast_4616_output: 3abeea55
/model/language_model/model/layers.6/input_layernorm/Cast_output_0: 40ff58fe
/model/language_model/model/layers.3/self_attn/q_norm/Mul_1_output_0: 3dfbc01a
/model/language_model/model/layers.5/mlp/act_fn/Mul_output_0: 3c73eae5
/model/language_model/model/layers.5/Add_1_output_0: 40ff58fe
/model/language_model/model/layers.5/mlp/gate_proj/MatMul_output_0: 3d2a97d9
/model/language_model/model/layers.3/input_layernorm/ReduceMean_output_0: 44aed0d3
/model/language_model/model/layers.5/post_attention_layernorm/Mul_output_0: 3dfd5a5b
/model/language_model/model/layers.5/post_attention_layernorm/Div_output_0: 3c56aa9e
ONNXTRT_Broadcast_4612_output: 3bfa0387
/model/language_model/model/layers.5/post_attention_layernorm/Add_output_0: 44aed4e2
/model/language_model/model/layers.5/post_attention_layernorm/ReduceMean_output_0: 44aed4e2
/model/language_model/model/layers.5/post_attention_layernorm/Pow_output_0: 49face55
/model/language_model/model/layers.11/post_attention_layernorm/Add_output_0: 44aecf3e
/model/language_model/model/layers.5/post_attention_layernorm/Cast_output_0: 40ff590c
/model/language_model/model/layers.5/Add_output_0: 40ff590c
/model/language_model/model/layers.10/self_attn/Slice_4_output_0: 4400f9f3
ONNXTRT_Broadcast_4614_output: 3af76953
/model/language_model/model/layers.5/self_attn/o_proj/MatMul_output_0: 3d0b3f68
ONNXTRT_Broadcast_4604_output: 3b24756b
onnx::MatMul_9738_output: 3ab3d4ea
/model/language_model/model/layers.13/self_attn/q_norm/Mul_output_0: 3d4c5302
/model/Reshape_7_output_0: 3e579e8b
/model/Transpose_5_output_0: 3e579e8b
/model/Split_1_output_0: 3e564e2c
/model/Split_1_output_1: 3e5751df
/model/Split_1_output_2: 3e56e555
/model/Split_1_output_3: 3e579e8b
onnx::MatMul_9820_output: 3b24756b
/model/Squeeze_output_0: 3e564e2c
ONNXTRT_Broadcast_3809_output: 3c010a14
/model/Squeeze_1_output_0: 3e5751df
/model/language_model/model/layers.5/self_attn/Reshape_7_output_0: 3c24678b
/model/Squeeze_2_output_0: 3e56e555
/model/language_model/model/layers.8/self_attn/Expand_1_output_0: 3d8cc845
/model/Squeeze_3_output_0: 3e579e8b
/model/Concat_2_output_0: 3e579e8b
ONNXTRT_Broadcast_7036_output: 32074ebd
/model/Unsqueeze_4_output_0: 3e579e8b
/model/language_model/model/layers.15/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.15/self_attn/MatMul_output_0: 3ff852a8
/model/mlp1/mlp1.0/LayerNormalization_output_0: 3e16e2c7
onnx::MatMul_9615_output: 3a2e83e8
ONNXTRT_Broadcast_2527_output: 3a2e83e8
/model/mlp1/mlp1.1/MatMul_output_0: 3d91c28b
backbone.model.mlp1.1.bias_output: 39b59f7f
ONNXTRT_Broadcast_2529_output: 39b59f7f
/model/mlp1/mlp1.1/Add_output_0: 3d92cad9
/model/mlp1/mlp1.2/Constant_output_0_output: 3c367841
ONNXTRT_Broadcast_2531_output: 3c367841
/model/mlp1/mlp1.2/Div_output_0: 3d4f9e30
/model/mlp1/mlp1.2/Erf_output_0: 3c010a14
/model/mlp1/mlp1.2/Constant_1_output_0_output: 3c010a14
ONNXTRT_Broadcast_2533_output: 3c010a14
/model/mlp1/mlp1.2/Add_output_0: 3c810a14
/model/mlp1/mlp1.2/Mul_output_0: 3d8c9827
/model/mlp1/mlp1.2/Constant_2_output_0_output: 3b810a14
ONNXTRT_Broadcast_2535_output: 3b810a14
/model/mlp1/mlp1.2/Mul_1_output_0: 3d0c9827
onnx::MatMul_9616_output: 3a1e4b47
ONNXTRT_Broadcast_2537_output: 3a1e4b47
/model/mlp1/mlp1.3/MatMul_output_0: 3dd015a8
backbone.model.mlp1.3.bias_output: 39760183
ONNXTRT_Broadcast_2539_output: 39760183
/model/mlp1/mlp1.3/Add_output_0: 3dcf9b36
/model/Reshape_8_output_0: 3dcf9b36
/model/language_model/model/layers.7/input_layernorm/Div_output_0: 3c174942
onnx::MatMul_9769_output: 3b0938d2
onnx::MatMul_9822_output: 3abeea55
/model/language_model/model/layers.11/input_layernorm/Cast_output_0: 40ffafeb
ONNXTRT_Broadcast_5405_output: 3acdfbf8
ONNXTRT_Broadcast_6216_output: 3b0938d2
/model/language_model/model/layers.13/input_layernorm/Cast_output_0: 40ff840f
ONNXTRT_Broadcast_5165_output: 3c810a14
ONNXTRT_Broadcast_4070_output: 3aed2830
/model/language_model/model/layers.4/self_attn/q_norm/ReduceMean_output_0: 3c4f68a3
/model/language_model/model/layers.6/self_attn/q_norm/Add_output_0: 3cbed024
/model/language_model/model/layers.15/self_attn/k_norm/Add_output_0: 400e7ea4
/model/language_model/model/layers.5/self_attn/Unsqueeze_10_output_0: 3f443dee
/model/language_model/model/layers.12/self_attn/Reshape_4_output_0: 3e9b2d41
/model/language_model/model/layers.14/post_attention_layernorm/ReduceMean_output_0: 44aecc41
/model/language_model/model/layers.10/self_attn/q_norm/Div_output_0: 3cbadc5b
/model/language_model/model/layers.11/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.2/mlp/Mul_output_0: 43188643
/model/Reshape_9_output_0: 3a3e96ce
/model/language_model/model/layers.14/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.11/post_attention_layernorm/Div_output_0: 3ba0994c
ONNXTRT_Broadcast_5959_output: 3c010a14
/model/language_model/model/layers.9/self_attn/q_norm/ReduceMean_output_0: 3da4278e
/model/GatherND_output_0: 39ad7922
/model/Constant_26_output_0_output: 0
ONNXTRT_Broadcast_2547_output: 0
/model/Mul_1_output_0: 0
/model/Add_output_0: 3dcf9b36
/model/language_model/model/layers.14/self_attn/o_proj/MatMul_output_0: 3e6e6ef8
onnx::MatMul_9977_output: 3ab4a489
/model/language_model/model/layers.13/input_layernorm/Pow_output_0: 49fb22db
ONNXTRT_Broadcast_7021_output: 3ad65ebd
/model/language_model/model/layers.5/self_attn/Reshape_2_output_0: 3cb925a3
/model/language_model/model/layers.7/self_attn/Mul_1_output_0: 3daa80ba
/model/language_model/model/layers.9/self_attn/q_norm/Cast_1_output_0: 3d68f3cb
/model/language_model/model/layers.8/input_layernorm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_6500_output: 3c810a14
/model/language_model/model/layers.11/Add_output_0: 429e0ded
/model/language_model/model/layers.13/post_attention_layernorm/Sqrt_output_0: 40546234
/model/language_model/model/layers.14/self_attn/Reshape_4_output_0: 3e4fac74
ONNXTRT_Broadcast_6228_output: 3cd3cd1a
/model/language_model/model/layers.13/self_attn/Constant_54_output_0_output: 3a367841
ONNXTRT_Broadcast_5699_output: 3c810a14
/model/Reshape_11_output_0: 3dcf9b36
ONNXTRT_Broadcast_6752_output: 3b194f5f
ONNXTRT_Broadcast_3544_output: 3c1e9326
ONNXTRT_Broadcast_3823_output: 3c010a14
/model/language_model/model/layers.5/self_attn/Softmax_output_0: 3a776ede
/model/language_model/model/layers.12/self_attn/q_norm/Mul_1_output_0: 3d95d327
ONNXTRT_Broadcast_5897_output: 3a367841
/model/language_model/model/layers.9/post_attention_layernorm/Mul_output_0: 3df8803b
/model/language_model/model/layers.5/self_attn/Mul_1_output_0: 3d95719d
/model/language_model/model/layers.5/self_attn/Softmax_output: 3a776ede
/model/language_model/model/layers.11/self_attn/k_norm/Mul_output_0: 3d55ed78
ONNXTRT_Broadcast_3803_output: 3b12372e
/model/language_model/model/layers.15/self_attn/k_norm/Sqrt_output_0: 3e078dc1
backbone.model.language_model.model.layers.1.post_attention_layernorm.weight_output: 3c1e9326
ONNXTRT_Broadcast_6491_output: 32074ebd
/model/language_model/model/layers.5/self_attn/Transpose_4_output_0: 3c24678b
/model/language_model/model/layers.14/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.5/self_attn/k_norm/Div_output_0: 3cb668bb
/model/language_model/model/layers.5/self_attn/Cast_5_output_0: 3a776ede
/model/language_model/model/layers.5/self_attn/Cast_4_output_0: 3a776ede
/model/language_model/model/layers.7/self_attn/k_proj/MatMul_output_0: 3d3e9feb
ONNXTRT_Broadcast_6250_output: 3cdead5b
/model/language_model/model/layers.5/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.3/post_attention_layernorm/Sqrt_output_0: 40546825
ONNXTRT_Broadcast_4074_output: 32074ebd
/model/language_model/model/layers.1/mlp/act_fn/Mul_output_0: 3c69cd5d
/model/language_model/model/layers.14/self_attn/q_norm/Cast_output_0: 3ea7afbb
ONNXTRT_Broadcast_3550_output: 3aa9a9d4
/model/language_model/model/layers.2/self_attn/Cast_5_output_0: 3a814285
/model/language_model/model/layers.4/self_attn/k_norm/Cast_output_0: 3d01c692
/model/language_model/model/layers.15/self_attn/Transpose_output_0: 3dc873a4
/model/language_model/model/layers.4/self_attn/Unsqueeze_10_output_0: 3f641313
/model/Slice_1_output_0: 3dcf9b36
/model/ScatterND_output_0: 3d4e6605
/model/language_model/model/layers.1/self_attn/Neg_1_output_0: 3e2a6b8b
/model/language_model/model/layers.1/self_attn/Add_2_output_0: 4480ff8c
/model/language_model/model/layers.3/self_attn/Neg_1_output_0: 3f3dbb6c
onnx::MatMul_9699_output: 3aa9a9d4
ONNXTRT_Broadcast_5445_output: 32074ebd
/model/language_model/model/layers.2/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.12/self_attn/k_norm/Sqrt_output_0: 3e3c88fa
/model/Reshape_12_output_0: 3d4e6605
/model/language_model/model/layers.9/post_attention_layernorm/ReduceMean_output_0: 44aed0a7
/model/language_model/model/layers.2/post_attention_layernorm/Div_output_0: 3cb203eb
/model/language_model/model/layers.5/self_attn/Reshape_6_output_0: 3cb925a3
/model/language_model/model/layers.3/self_attn/Mul_8_output_0: 3e24725e
ONNXTRT_Broadcast_4618_output: 3ac7c5cc
ONNXTRT_Broadcast_4562_output: 3a367841
/model/language_model/model/layers.5/self_attn/Transpose_3_output_0: 3f443dee
ONNXTRT_Broadcast_3817_output: 3a8269d4
/model/language_model/model/layers.11/self_attn/Reshape_4_output_0: 3e1ad653
/model/language_model/model/layers.15/input_layernorm/Mul_1_output_0: 3e55dda3
/model/language_model/model/layers.12/self_attn/Cast_4_output_0: 3a400000
ONNXTRT_Broadcast_4084_output: 3a876cda
/model/language_model/model/layers.15/self_attn/q_norm/ReduceMean_output_0: 4012d946
/model/language_model/model/layers.9/self_attn/Slice_1_output_0: 3dfa3d78
/model/language_model/model/layers.8/self_attn/Constant_54_output_0_output: 3a367841
onnx::MatMul_9925_output: 3aab8e1c
/model/language_model/model/layers.5/self_attn/MatMul_output_0: 4004a02f
ONNXTRT_Broadcast_5714_output: 3c010a14
ONNXTRT_Broadcast_5436_output: 3c010a14
backbone.model.language_model.model.layers.4.self_attn.q_norm.weight_output: 3cae8204
/model/language_model/model/layers.8/self_attn/Slice_1_output_0: 3e1de798
ONNXTRT_Broadcast_7015_output: 3c46a0d2
/model/language_model/model/layers.12/post_attention_layernorm/Mul_output_0: 3d24e6cd
/model/language_model/model/layers.12/self_attn/Mul_8_output_0: 3e15c418
onnx::MatMul_9707_output: 3ae5e8d2
/model/language_model/model/layers.1/self_attn/Reshape_4_output_0: 3f784da5
/model/language_model/model/layers.8/self_attn/Add_output_0: 3e1bb76e
/model/language_model/model/layers.6/self_attn/Unsqueeze_10_output_0: 3f246ce7
/model/language_model/model/layers.11/self_attn/Transpose_output_0: 3dadf90e
/model/language_model/model/layers.3/self_attn/Mul_output_0: 3df3b4ed
/model/language_model/model/layers.10/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.14/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.7/post_attention_layernorm/Pow_output_0: 49fb01b8
/model/language_model/model/layers.2/input_layernorm/Add_output_0: 3db67e48
/model/language_model/model/layers.13/self_attn/q_norm/Constant_output_0_output: 3c810a14
tmp_refittable_weight_0_output: 4400f9f3
ONNXTRT_ShapeShuffle_2611_output: 4400f9f3
/model/language_model/model/ConstantOfShape_output_0: 4400f9f3
ONNXTRT_Broadcast_3832_output: 32074ebd
/model/language_model/model/layers.1/self_attn/Reshape_7_output_0: 3bc8cfb1
onnx::MatMul_10007_output: 3b0938d2
/model/language_model/model/layers.4/self_attn/Reshape_7_output_0: 3c036402
/model/language_model/model/layers.15/self_attn/Add_1_output_0: 3ecddb11
/model/language_model/model/layers.3/post_attention_layernorm/Mul_output_0: 3dce8f79
/model/language_model/model/layers.12/input_layernorm/Pow_output_0: 49fba44d
/model/language_model/model/layers.1/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.12/self_attn/q_norm/Sqrt_output_0: 3dab2c37
onnx::MatMul_9727_output: 3b12372e
/model/language_model/model/layers.11/self_attn/Reshape_7_output_0: 3d10e158
onnx::MatMul_9739_output: 3ac3c245
ONNXTRT_Broadcast_4646_output: 3c010a14
/model/language_model/model/layers.13/self_attn/k_norm/Pow_output_0: 408587da
/model/language_model/model/layers.8/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/self_attn/k_norm/Add_output_0: 3c0d4f02
/model/language_model/model/layers.3/self_attn/Reshape_2_output_0: 3cbdf29d
onnx::Mul_3838: 3c010a14
/model/language_model/model/Mul_output_0: 4400f9f3
/model/language_model/model/layers.3/self_attn/Transpose_3_output_0: 3f3dba3d
/model/language_model/model/Unsqueeze_3_output_0: 4400f9f3
/model/language_model/model/layers.14/input_layernorm/Mul_1_output_0: 3e103b73
/model/language_model/model/Unsqueeze_4_output_0: 4400f9f3
/model/language_model/model/layers.11/self_attn/Add_2_output_0: 44810252
/model/language_model/model/layers.5/self_attn/k_norm/Mul_1_output_0: 3f3d78e5
/model/language_model/model/layers.12/self_attn/Reshape_1_output_0: 3ef4d723
/model/language_model/model/layers.14/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.10/self_attn/Mul_output_0: 3de86b7d
/model/language_model/model/layers.6/self_attn/k_norm/Mul_1_output_0: 3f2c1c7f
/model/language_model/model/layers.3/self_attn/Mul_2_output_0: 3f3dba60
/model/language_model/model/layers.2/input_layernorm/Div_output_0: 3ccb9130
/model/language_model/model/layers.3/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.8/Add_1_output_0: 40ff7f7d
/model/language_model/model/layers.13/self_attn/Expand_1_output_0: 3e407804
/model/language_model/model/layers.12/self_attn/q_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3841_output: 3c810a14
/model/language_model/model/layers.8/self_attn/Add_1_output_0: 3e6be427
/model/language_model/model/layers.3/self_attn/MatMul_output_0: 3fe89671
/model/language_model/model/layers.13/post_attention_layernorm/Pow_output_0: 49fb29e2
/model/language_model/model/layers.11/mlp/Mul_output_0: 3cd44011
/model/language_model/model/layers.8/self_attn/Unsqueeze_19_output_0: 3d8cc845
/model/language_model/model/layers.8/self_attn/Transpose_2_output_0: 3d8cc845
backbone.model.language_model.model.layers.13.self_attn.q_norm.weight_output: 3d328800
ONNXTRT_Broadcast_4624_output: 3c010a14
/model/language_model/model/layers.14/self_attn/k_norm/Mul_output_0: 3d413962
ONNXTRT_Broadcast_4086_output: 3c810a14
/model/language_model/model/layers.6/self_attn/Reshape_6_output_0: 3ca09e10
/model/language_model/model/layers.8/self_attn/q_norm/Sqrt_output_0: 3c9025c5
/model/language_model/model/layers.3/input_layernorm/Mul_1_output_0: 3d207bbd
/model/language_model/model/layers.14/self_attn/Transpose_3_output_0: 3e4fac74
/model/language_model/model/layers.5/self_attn/Reshape_4_output_0: 3f443dee
/model/language_model/model/Expand_output_0: 4400f9f3
ONNXTRT_Broadcast_5672_output: 3b2f7c99
ONNXTRT_Broadcast_5970_output: 3c010a14
/model/language_model/model/layers.7/self_attn/q_norm/Sqrt_output_0: 3c971aa2
/model/language_model/model/layers.11/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.9/self_attn/k_norm/Div_output_0: 3c895894
onnx::MatMul_9947_output: 3a7bc993
ONNXTRT_Broadcast_7023_output: 3c810a14
/model/language_model/model/layers.4/input_layernorm/ReduceMean_output_0: 44aed124
/model/language_model/model/layers.2/self_attn/q_norm/Mul_output_0: 3d66f170
/model/language_model/model/layers.5/self_attn/Concat_4_output_0: 3f3d78e5
ONNXTRT_Broadcast_6495_output: 3cd3fefe
ONNXTRT_Broadcast_5443_output: 3c810a14
/model/language_model/model/layers.5/self_attn/Neg_1_output_0: 3f3d78e5
/model/language_model/model/layers.5/self_attn/Slice_3_output_0: 3f3d78e5
/model/language_model/model/layers.2/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.5/self_attn/Add_1_output_0: 3f443dee
/model/language_model/model/layers.13/self_attn/Add_2_output_0: 4480ffe6
/model/language_model/model/layers.7/input_layernorm/Pow_output_0: 49fae6c8
/model/language_model/model/layers.2/self_attn/q_norm/Pow_output_0: 3d0cb10d
/model/language_model/model/layers.2/self_attn/q_norm/ReduceMean_output_0: 3b560011
ONNXTRT_Broadcast_3563_output: 3c810a14
/model/language_model/model/layers.13/self_attn/Mul_output_0: 3dbd10db
/model/language_model/model/layers.4/post_attention_layernorm/Add_output_0: 44aed121
ONNXTRT_Broadcast_3565_output: 32074ebd
/model/language_model/model/layers.8/post_attention_layernorm/Cast_output_0: 40ff7f95
/model/language_model/model/layers.2/self_attn/q_norm/Sqrt_output_0: 3bb7a69d
/model/language_model/model/layers.2/self_attn/q_norm/Cast_1_output_0: 3d66f170
/model/language_model/model/layers.10/mlp/down_proj/MatMul_output_0: 3d8a077f
/model/language_model/model/layers.10/mlp/gate_proj/MatMul_output_0: 3d580dc1
/model/language_model/model/layers.10/self_attn/k_norm/Sqrt_output_0: 3c921917
/model/language_model/model/Slice_output_0: 4400f9f3
/model/language_model/model/layers.10/self_attn/k_norm/Pow_output_0: 408b6fb3
/model/language_model/model/layers.12/post_attention_layernorm/Sqrt_output_0: 405465c8
/model/language_model/model/Cast_3_output_0: 3c010a14
/model/language_model/model/Add_output_0: 4480f972
/model/language_model/model/layers.7/post_attention_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_5138_output: 3b0938d2
/model/language_model/model/layers.9/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.2/self_attn/Reshape_1_output_0: 3cccd046
/model/language_model/model/layers.1/mlp/up_proj/MatMul_output_0: 3d8d1068
onnx::MatMul_9698_output: 3b053bf8
/model/language_model/model/layers.1/Add_1_output_0: 3e56e37e
/model/language_model/model/layers.2/self_attn/q_norm/Div_output_0: 3d5f7644
/model/language_model/model/layers.4/self_attn/q_norm/Cast_output_0: 3d33d716
/model/language_model/model/layers.1/mlp/gate_proj/MatMul_output_0: 3dbe3a8b
/model/language_model/model/layers.14/self_attn/q_norm/Add_output_0: 3f3163a1
onnx::MatMul_9697_output: 3ad9f52a
/model/language_model/model/layers.13/self_attn/Reshape_2_output_0: 3e407804
/model/language_model/model/layers.3/self_attn/k_norm/Sqrt_output_0: 3c12445d
/model/language_model/model/layers.2/self_attn/Transpose_output_0: 3e14fbb5
backbone.model.language_model.model.layers.2.self_attn.q_norm.weight_output: 3d204a85
onnx::MatMul_9979_output: 3b053bf8
onnx::MatMul_9886_output: 3b2c76ee
/model/language_model/model/layers.13/self_attn/Softmax_output: 3a776ede
ONNXTRT_Broadcast_5146_output: 3c14379f
/model/language_model/model/layers.9/self_attn/Reshape_6_output_0: 3d323dd6
/model/language_model/model/layers.4/self_attn/Softmax_output_0: 3a7f7efe
/model/language_model/model/layers.2/Add_output_0: 3dcc265b
/model/language_model/model/layers.14/self_attn/MatMul_1_output_0: 3dccc1ae
ONNXTRT_Broadcast_7053_output: 3b337912
/model/language_model/model/layers.9/self_attn/Softmax_output: 3a19b367
/model/language_model/model/layers.3/input_layernorm/Cast_output_0: 40ff4d44
/model/language_model/model/layers.14/self_attn/Concat_3_output_0: 3e036a52
/model/language_model/model/layers.2/self_attn/k_norm/Cast_output_0: 3cccd046
/model/language_model/model/layers.10/self_attn/Slice_3_output_0: 3e59e06d
/model/language_model/model/Slice_1_output_0: 4400f9f3
/model/language_model/model/Where_1_output_0: 4400f9f3
/model/language_model/model/layers.7/Add_output_0: 40ff7334
/model/language_model/model/layers.2/self_attn/Slice_1_output_0: 3e14fbb5
/model/language_model/model/layers.10/self_attn/Neg_1_output_0: 3e59e06d
backbone.model.language_model.model.layers.9.self_attn.q_norm.weight_output: 3d5ac316
/model/language_model/model/layers.10/self_attn/q_norm/Cast_output_0: 3de37b2e
onnx::MatMul_10048_output: 3af306ce
ONNXTRT_Broadcast_6506_output: 3d328800
/model/language_model/model/layers.8/input_layernorm/Div_output_0: 3c156b25
/model/language_model/model/layers.2/self_attn/k_proj/MatMul_output_0: 3cccd046
/model/language_model/model/layers.5/self_attn/Slice_2_output_0: 3f1e4bd4
/model/language_model/model/layers.7/self_attn/Neg_output_0: 3e001f9a
/model/language_model/model/layers.15/self_attn/k_norm/ReduceMean_output_0: 400e7ea4
/model/language_model/model/layers.9/self_attn/Cast_4_output_0: 3a19b367
/model/language_model/model/layers.4/self_attn/Reshape_output_0: 3d33d716
backbone.model.language_model.model.layers.7.post_attention_layernorm.weight_output: 3c14379f
/model/language_model/model/layers.13/post_attention_layernorm/Cast_1_output_0: 3cfdfd11
/model/language_model/model/layers.8/post_attention_layernorm/Div_output_0: 3c0854df
backbone.model.language_model.model.layers.12.self_attn.k_norm.weight_output: 3cdead5b
/model/language_model/model/layers.10/self_attn/Slice_output_0: 3e0ca13b
onnx::MatMul_10101_output: 3aef3f3e
/model/language_model/model/layers.10/self_attn/q_norm/Cast_1_output_0: 3d8283a6
/model/language_model/model/layers.13/self_attn/Concat_4_output_0: 3db3f66a
/model/language_model/model/layers.3/self_attn/Transpose_output_0: 3dfbc01a
ONNXTRT_Broadcast_4094_output: 3af33d7b
/model/language_model/model/layers.3/self_attn/q_proj/MatMul_output_0: 3d72cb6c
ONNXTRT_Broadcast_3813_output: 3b0e3000
ONNXTRT_Broadcast_5957_output: 32074ebd
/model/language_model/model/layers.1/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.1/self_attn/Constant_54_output_0_output: 3a367841
ONNXTRT_Broadcast_5981_output: 3c010a14
ONNXTRT_Broadcast_4917_output: 3ac4bbd8
/model/language_model/model/layers.13/self_attn/q_norm/Add_output_0: 3eda7444
ONNXTRT_Broadcast_6224_output: 32074ebd
/model/language_model/model/layers.15/self_attn/q_norm/Cast_1_output_0: 3d8924d4
ONNXTRT_Broadcast_4359_output: 3be81163
/model/language_model/model/layers.5/input_layernorm/Cast_1_output_0: 3e01fd36
/model/language_model/model/layers.5/input_layernorm/Div_output_0: 3c5f2469
ONNXTRT_Broadcast_4357_output: 3c010a14
/model/language_model/model/layers.9/self_attn/Softmax_output_0: 3a19b367
/model/language_model/model/layers.4/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.6/self_attn/Reshape_4_output_0: 3f246ce7
/model/language_model/model/layers.3/post_attention_layernorm/Add_output_0: 44aed143
ONNXTRT_Broadcast_6750_output: 3af76912
/model/language_model/model/layers.9/self_attn/k_norm/Pow_output_0: 3e860322
/model/language_model/model/Expand_1_output_0: 4400f9f3
/model/language_model/model/layers.8/input_layernorm/Pow_output_0: 49fb01ed
/model/language_model/model/layers.7/mlp/down_proj/MatMul_output_0: 3d5efb64
/model/language_model/model/layers.13/self_attn/k_norm/Cast_1_output_0: 3d420a80
/model/language_model/model/layers.13/self_attn/k_proj/MatMul_output_0: 3eb41665
/model/language_model/model/layers.12/Add_1_output_0: 40ff840f
/model/language_model/model/layers.12/mlp/gate_proj/MatMul_output_0: 3d3d2921
/model/language_model/model/layers.14/mlp/act_fn/Mul_output_0: 3d4a1e42
ONNXTRT_Broadcast_4337_output: 3a8f668d
/model/language_model/model/layers.8/self_attn/Reshape_output_0: 3dadc3be
/model/language_model/model/layers.8/input_layernorm/Sqrt_output_0: 40546a42
/model/language_model/model/layers.2/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3576_output: 32074ebd
/model/language_model/model/layers.6/self_attn/q_norm/Cast_output_0: 3d680110
/model/language_model/model/layers.13/self_attn/Softmax_output_0: 3a776ede
/model/language_model/model/layers.12/self_attn/Reshape_2_output_0: 3e54e1d5
/model/language_model/model/layers.1/post_attention_layernorm/Mul_output_0: 3e134197
backbone.model.language_model.model.layers.4.self_attn.k_norm.weight_output: 3d8d4204
/model/language_model/model/layers.4/self_attn/k_norm/ReduceMean_output_0: 3c542ed8
/model/language_model/model/layers.12/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.14/post_attention_layernorm/Pow_output_0: 49fb1ad4
/model/language_model/model/layers.5/self_attn/Mul_2_output_0: 3f226b6d
ONNXTRT_Broadcast_5943_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Transpose_output_0: 3ddfdb1f
/model/language_model/model/layers.15/self_attn/Slice_3_output_0: 3ecddd3b
/model/language_model/model/layers.4/self_attn/q_norm/Mul_1_output_0: 3e050bfe
/model/language_model/model/layers.2/self_attn/k_norm/Sqrt_output_0: 3bcdb218
/model/language_model/model/layers.2/self_attn/k_norm/Div_output_0: 3d7a130c
/model/language_model/model/layers.5/self_attn/Concat_3_output_0: 3e18b0ed
/model/language_model/model/layers.5/self_attn/Slice_1_output_0: 3e189a2a
/model/language_model/model/layers.2/self_attn/k_norm/Add_output_0: 3b2a399d
onnx::MatMul_10079_output: 3adf172e
ONNXTRT_Broadcast_3580_output: 3d657dfc
/model/language_model/model/layers.2/self_attn/Transpose_1_output_0: 3f6cb711
ONNXTRT_Broadcast_4620_output: 3c810a14
/model/language_model/model/layers.14/self_attn/Unsqueeze_19_output_0: 3e681d68
/model/language_model/model/layers.11/self_attn/Concat_4_output_0: 3e1ad653
/model/language_model/model/layers.2/self_attn/Transpose_2_output_0: 3c334541
/model/language_model/model/layers.13/self_attn/Mul_2_output_0: 3db3f66a
/model/language_model/model/layers.2/self_attn/Mul_output_0: 3dce41de
ONNXTRT_Broadcast_3582_output: 3aa4756b
/model/language_model/model/layers.10/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.11/self_attn/k_norm/Cast_1_output_0: 3d55ed78
/model/language_model/model/layers.2/self_attn/v_proj/MatMul_output_0: 3c334541
/model/language_model/model/layers.3/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.2/post_attention_layernorm/Cast_output_0: 3dcc265b
/model/language_model/model/layers.7/post_attention_layernorm/Cast_1_output_0: 3e0089e5
/model/language_model/model/layers.13/self_attn/k_norm/Sqrt_output_0: 3dda402d
/model/language_model/model/layers.3/self_attn/Add_output_0: 3e016ee7
/model/language_model/model/layers.5/self_attn/Expand_1_output_0: 3cb925a3
/model/language_model/model/layers.9/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.8/self_attn/q_norm/Add_output_0: 3d24e343
/model/language_model/model/layers.4/self_attn/Slice_3_output_0: 3f66a344
ONNXTRT_Broadcast_5684_output: 3aafac38
/model/language_model/model/layers.6/self_attn/Softmax_output_0: 3a7c78f2
/model/language_model/model/layers.14/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.3/post_attention_layernorm/Mul_1_output_0: 3de2a049
/model/language_model/model/layers.3/input_layernorm/Sqrt_output_0: 405467e2
ONNXTRT_Broadcast_5417_output: 3aa58f9f
backbone.model.language_model.model.layers.8.self_attn.q_norm.weight_output: 3c9142a5
/model/language_model/model/layers.7/input_layernorm/Cast_output_0: 40ff657e
/model/language_model/model/layers.12/self_attn/k_norm/ReduceMean_output_0: 3eb85d4b
/model/language_model/model/layers.3/input_layernorm/Pow_output_0: 49fab72f
/model/language_model/model/layers.15/self_attn/Neg_1_output_0: 3ecddd3b
/model/language_model/model/layers.10/post_attention_layernorm/Pow_output_0: 49fb79b2
/model/language_model/model/layers.12/self_attn/Add_1_output_0: 3e9b2d41
/model/language_model/model/layers.7/self_attn/o_proj/MatMul_output_0: 3d204c0e
/model/language_model/model/layers.4/mlp/act_fn/Mul_output_0: 3c31a7ad
/model/language_model/model/layers.10/input_layernorm/Cast_1_output_0: 3df74aa8
/model/language_model/model/layers.5/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.4/mlp/act_fn/Sigmoid_output_0: 3bf1d2d6
/model/language_model/model/layers.5/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.5/input_layernorm/Sqrt_output_0: 40546815
/model/language_model/model/layers.14/self_attn/Unsqueeze_10_output_0: 3e4fac74
/model/language_model/model/layers.5/input_layernorm/Add_output_0: 44aed128
/model/language_model/model/layers.5/input_layernorm/Pow_output_0: 49fac206
/model/language_model/model/layers.5/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.5/input_layernorm/ReduceMean_output_0: 44aed128
/model/language_model/model/layers.10/input_layernorm/Div_output_0: 3be3f4de
/model/language_model/model/layers.5/input_layernorm/Cast_output_0: 40ff52c9
/model/language_model/model/layers.4/Add_1_output_0: 40ff52c9
ONNXTRT_Broadcast_4355_output: 32074ebd
/model/language_model/model/layers.4/mlp/down_proj/MatMul_output_0: 3cef0092
onnx::MatMul_9792_output: 3a788102
/model/language_model/model/layers.4/post_attention_layernorm/Mul_1_output_0: 3db60072
ONNXTRT_Broadcast_4345_output: 3c021e5d
onnx::MatMul_9790_output: 3ad7e7d0
/model/language_model/model/layers.4/post_attention_layernorm/Cast_1_output_0: 3dfed947
/model/language_model/model/layers.1/post_attention_layernorm/Mul_1_output_0: 3dd5fde5
/model/language_model/model/layers.10/self_attn/Reshape_6_output_0: 3d9d216c
onnx::MatMul_9791_output: 3a8c6f1e
/model/language_model/model/layers.11/self_attn/Reshape_1_output_0: 3e341aac
/model/language_model/model/layers.4/post_attention_layernorm/Mul_output_0: 3dfed947
/model/language_model/model/layers.4/post_attention_layernorm/Div_output_0: 3c3faa4c
/model/language_model/model/layers.4/mlp/up_proj/MatMul_output_0: 3d5c545a
ONNXTRT_Broadcast_4343_output: 3c010a14
/model/language_model/model/layers.15/self_attn/Reshape_6_output_0: 3e974f2f
/model/language_model/model/layers.12/input_layernorm/Cast_1_output_0: 3de80632
/model/language_model/model/layers.6/self_attn/q_norm/Cast_1_output_0: 3d789504
/model/language_model/model/layers.6/self_attn/k_proj/MatMul_output_0: 3d07b641
/model/language_model/model/layers.9/self_attn/Unsqueeze_19_output_0: 3d323dd6
/model/language_model/model/layers.15/self_attn/Transpose_3_output_0: 3ecddb11
ONNXTRT_Broadcast_3847_output: 3d30d428
/model/language_model/model/layers.2/self_attn/q_norm/Add_output_0: 3b560019
ONNXTRT_Broadcast_4341_output: 32074ebd
/model/language_model/model/layers.4/post_attention_layernorm/ReduceMean_output_0: 44aed121
/model/language_model/model/layers.2/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_6508_output: 3af306ce
/model/language_model/model/layers.15/self_attn/Mul_3_output_0: 3dd4e0f2
/model/language_model/model/layers.4/self_attn/Transpose_4_output_0: 3c036402
ONNXTRT_Broadcast_4877_output: 3c010a14
ONNXTRT_Broadcast_3838_output: 3ab3d4ea
/model/language_model/model/layers.15/self_attn/Slice_1_output_0: 3da0592a
backbone.model.language_model.model.layers.4.input_layernorm.weight_output: 3bc9c8b1
/model/language_model/model/layers.5/self_attn/Neg_output_0: 3e189a2a
/model/language_model/model/layers.11/self_attn/Neg_1_output_0: 3e1ac842
/model/language_model/model/layers.11/self_attn/Cast_5_output_0: 3a80c183
/model/language_model/model/layers.5/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
onnx::MatMul_9789_output: 3a8f668d
/model/language_model/model/layers.3/self_attn/o_proj/MatMul_output_0: 3c2bc01c
/model/language_model/model/layers.13/self_attn/Slice_3_output_0: 3da454da
/model/language_model/model/layers.13/mlp/up_proj/MatMul_output_0: 3d4f08e8
/model/language_model/model/layers.9/self_attn/Mul_output_0: 3e01f693
/model/language_model/model/layers.4/self_attn/v_proj/MatMul_output_0: 3cbadcd9
ONNXTRT_Broadcast_6775_output: 3adf172e
onnx::MatMul_9924_output: 3b4cbcda
/model/language_model/model/layers.9/self_attn/k_norm/Add_output_0: 3d251124
/model/language_model/model/layers.2/self_attn/k_norm/Cast_1_output_0: 3d551c47
/model/language_model/model/layers.15/input_layernorm/ReduceMean_output_0: 44aecd3c
/model/language_model/model/layers.10/input_layernorm/Pow_output_0: 49fb5827
/model/language_model/model/layers.7/self_attn/Add_1_output_0: 3ef3d49c
ONNXTRT_Broadcast_3494_output: 3a367841
/model/language_model/model/layers.13/Add_1_output_0: 429e669d
/model/language_model/model/layers.4/self_attn/Cast_5_output_0: 3a7f7efe
/model/language_model/model/layers.14/self_attn/Add_output_0: 3e0d8255
/model/language_model/model/layers.3/post_attention_layernorm/Cast_output_0: 40ff51a6
/model/language_model/model/layers.10/input_layernorm/Sqrt_output_0: 405467dd
ONNXTRT_Broadcast_5630_output: 3a367841
/model/language_model/model/layers.3/self_attn/Neg_output_0: 3e03708e
/model/language_model/model/layers.11/self_attn/Transpose_4_output_0: 3d10e158
/model/language_model/model/layers.14/post_attention_layernorm/Cast_output_0: 429e81c3
/model/language_model/model/layers.12/self_attn/Slice_output_0: 3d956ed1
/model/language_model/model/layers.1/post_attention_layernorm/Cast_1_output_0: 3e134197
/model/language_model/model/layers.2/Add_1_output_0: 40ff4d44
ONNXTRT_Broadcast_5158_output: 3c010a14
ONNXTRT_Broadcast_5939_output: 3b1158b1
/model/language_model/model/layers.3/self_attn/k_norm/Mul_output_0: 3d5df1d5
/model/language_model/model/layers.8/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.7/self_attn/Slice_output_0: 3de86eef
/model/language_model/model/layers.14/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.5/mlp/act_fn/Sigmoid_output_0: 3c0079a1
/model/language_model/model/layers.3/self_attn/k_norm/ReduceMean_output_0: 3c0d4efa
/model/language_model/model/layers.13/self_attn/Transpose_4_output_0: 3d40349a
onnx::MatMul_10039_output: 3aeafcda
/model/language_model/model/layers.15/self_attn/k_norm/Mul_1_output_0: 3ecddd3b
/model/language_model/model/layers.12/self_attn/Add_output_0: 3da3fec8
/model/language_model/model/layers.9/self_attn/v_proj/MatMul_output_0: 3d323dd6
/model/language_model/model/layers.3/self_attn/Slice_2_output_0: 3e26ddd9
ONNXTRT_Broadcast_6965_output: 3a367841
/model/language_model/model/layers.6/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
onnx::MatMul_9955_output: 3ad9d8d2
/model/language_model/model/layers.4/self_attn/Unsqueeze_19_output_0: 3cbadcd9
onnx::MatMul_9855_output: 3b092c69
/model/language_model/model/layers.5/input_layernorm/Mul_1_output_0: 3d32e87f
/model/language_model/model/layers.14/self_attn/Transpose_1_output_0: 3e4fd4ad
backbone.model.language_model.model.layers.2.input_layernorm.weight_output: 3b41b1e4
/model/language_model/model/layers.10/self_attn/Reshape_1_output_0: 3dfee05a
/model/language_model/model/layers.7/self_attn/k_norm/Add_output_0: 3c9b4167
/model/language_model/model/layers.7/self_attn/MatMul_output_0: 3fd821a2
/model/language_model/model/layers.15/self_attn/k_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_5718_output: 3aab6c49
ONNXTRT_Broadcast_5674_output: 3c810a14
/model/language_model/model/layers.11/mlp/act_fn/Sigmoid_output_0: 3c00f9f4
/model/language_model/model/layers.4/self_attn/Cast_4_output_0: 3a7f7efe
ONNXTRT_Broadcast_4895_output: 3b092c69
/model/language_model/model/layers.14/self_attn/k_norm/Mul_1_output_0: 3e4fd4ad
/model/language_model/model/layers.10/self_attn/Add_2_output_0: 4480ff53
/model/language_model/model/layers.10/post_attention_layernorm/Mul_output_0: 3df31eb9
/model/language_model/model/layers.12/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.8/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.2/post_attention_layernorm/Mul_output_0: 3d91954b
/model/language_model/model/layers.4/input_layernorm/Div_output_0: 3c3fafa4
/model/language_model/model/layers.12/self_attn/Slice_2_output_0: 3e9b2fdf
/model/language_model/model/layers.4/post_attention_layernorm/Pow_output_0: 49fac250
/model/language_model/model/layers.4/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.4/post_attention_layernorm/Cast_output_0: 40ff52ee
ONNXTRT_Broadcast_5425_output: 3c010a14
/model/language_model/model/layers.2/self_attn/Add_output_0: 3e159451
/model/language_model/model/layers.10/self_attn/Concat_3_output_0: 3e0ca13b
ONNXTRT_Broadcast_6504_output: 3c010a14
/model/language_model/model/layers.15/self_attn/k_norm/Mul_output_0: 3d5c84ff
/model/language_model/model/layers.3/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.9/self_attn/k_norm/Cast_output_0: 3d924f89
/model/language_model/model/layers.11/self_attn/k_norm/Sqrt_output_0: 3cd59980
onnx::MatMul_9854_output: 3a84a1c4
/model/language_model/model/layers.13/self_attn/v_proj/MatMul_output_0: 3e407804
/model/language_model/model/layers.9/post_attention_layernorm/Cast_1_output_0: 3df8803b
ONNXTRT_Broadcast_6502_output: 32074ebd
/model/language_model/model/layers.9/input_layernorm/Pow_output_0: 49fb19dd
/model/language_model/model/layers.11/self_attn/q_norm/Constant_output_0_output: 3c810a14
onnx::MatMul_9852_output: 3aec1c38
/model/language_model/model/layers.5/self_attn/Expand_output_0: 3f443dee
/model/language_model/model/layers.3/Add_output_0: 40ff51a6
/model/language_model/model/layers.11/self_attn/k_proj/MatMul_output_0: 3e341aac
/model/language_model/model/layers.12/self_attn/Neg_1_output_0: 3d8cb086
/model/language_model/model/layers.2/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.3/mlp/down_proj/MatMul_output_0: 3cc204d5
onnx::MatMul_9884_output: 3ab2b367
/model/language_model/model/layers.2/self_attn/q_proj/MatMul_output_0: 3cd3da30
/model/language_model/model/layers.2/self_attn/q_norm/Cast_output_0: 3cd3da30
onnx::MatMul_9760_output: 3ac7cb36
ONNXTRT_Broadcast_4082_output: 3ac7cb36
/model/language_model/model/layers.9/self_attn/Mul_1_output_0: 3d8f78df
/model/language_model/model/layers.11/mlp/gate_proj/MatMul_output_0: 3d44c1f6
/model/language_model/model/layers.13/self_attn/Transpose_output_0: 3dc473ae
/model/language_model/model/layers.9/mlp/act_fn/Mul_output_0: 3c898c80
/model/language_model/model/layers.4/self_attn/k_norm/Pow_output_0: 3d72ebf3
/model/language_model/model/layers.8/input_layernorm/Add_output_0: 44aed4bb
/model/language_model/model/layers.8/self_attn/q_proj/MatMul_output_0: 3dadc3be
/model/language_model/model/layers.13/self_attn/Unsqueeze_10_output_0: 3db3f66a
ONNXTRT_Broadcast_4088_output: 32074ebd
/model/language_model/model/layers.6/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.14/self_attn/Concat_4_output_0: 3e4fd4ad
onnx::MatMul_10102_output: 3ad65ebd
ONNXTRT_Broadcast_6744_output: 32074ebd
/model/language_model/model/layers.9/self_attn/k_proj/MatMul_output_0: 3d924f89
/model/language_model/model/layers.4/self_attn/MatMul_1_output_0: 3c036402
/model/language_model/model/Reshape_2_output_0: 4400f9f3
/model/language_model/model/ScatterND_output_0: 4400f9f3
/model/language_model/model/layers.7/self_attn/Cast_4_output_0: 3a7f7efe
/model/language_model/model/layers.9/self_attn/k_norm/ReduceMean_output_0: 3d251122
/model/language_model/model/layers.9/self_attn/Unsqueeze_10_output_0: 3e992ea2
/model/language_model/model/layers.6/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/post_attention_layernorm/ReduceMean_output_0: 44aed143
/model/language_model/model/layers.11/mlp/act_fn/Mul_output_0: 3cdf9b41
ONNXTRT_Broadcast_5680_output: 3bfd2c59
/model/language_model/model/layers.9/self_attn/q_norm/Sqrt_output_0: 3ce0cfa7
backbone.model.language_model.model.layers.3.self_attn.q_norm.weight_output: 3d184a95
/model/language_model/model/layers.10/self_attn/k_norm/Cast_1_output_0: 3d5a83ca
/model/language_model/model/layers.13/self_attn/o_proj/MatMul_output_0: 3e035714
ONNXTRT_Broadcast_6208_output: 3c810a14
backbone.model.language_model.model.layers.14.self_attn.q_norm.weight_output: 3d4fac38
ONNXTRT_Broadcast_5678_output: 3c010a14
/model/language_model/model/layers.1/self_attn/Mul_3_output_0: 3d5220e9
/model/language_model/model/layers.12/self_attn/Concat_3_output_0: 3d95d327
/model/language_model/model/layers.4/self_attn/Add_1_output_0: 3f641313
/model/language_model/model/layers.10/self_attn/k_norm/Mul_output_0: 3d5a83ca
/model/language_model/model/layers.3/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
onnx::Expand_3996_output: 3c010a14
ONNXTRT_Broadcast_3827_output: 3b3c968d
/model/language_model/model/layers.13/self_attn/Add_1_output_0: 3db3f66a
ONNXTRT_Broadcast_4351_output: 3a788102
/model/language_model/model/layers.8/self_attn/k_norm/Pow_output_0: 3ffcee7b
/model/language_model/model/layers.2/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.9/self_attn/Mul_2_output_0: 3e992dc9
/model/language_model/model/rotary_emb/Expand_output_0: 3c010a14
/model/language_model/model/rotary_emb/Cast_output_0: 3c010a14
ONNXTRT_Broadcast_5941_output: 3c810a14
/model/language_model/model/rotary_emb/Cast_1_output_0: 404eaa24
/model/language_model/model/rotary_emb/Cast_2_output_0: 3c010a14
/model/language_model/model/rotary_emb/Cast_3_output_0: 404eaa24
/model/language_model/model/rotary_emb/MatMul_output_0: 4027eca9
/model/language_model/model/rotary_emb/Transpose_output_0: 4027eca9
/model/language_model/model/rotary_emb/Concat_1_output_0: 4027eca9
/model/language_model/model/rotary_emb/Cos_output_0: 3c010a14
/model/language_model/model/rotary_emb/Constant_7_output_0_output: 3c010a14
ONNXTRT_Broadcast_3014_output: 3c010a14
/model/language_model/model/rotary_emb/Mul_1_output_0: 3c010a14
/model/language_model/model/rotary_emb/Sin_output_0: 3c010a13
/model/language_model/model/rotary_emb/Constant_8_output_0_output: 3c010a14
ONNXTRT_Broadcast_3016_output: 3c010a14
/model/language_model/model/rotary_emb/Mul_2_output_0: 3c010a13
/model/language_model/model/rotary_emb/Cast_4_output_0: 3c010a14
/model/language_model/model/rotary_emb/Cast_5_output_0: 3c010a13
/model/language_model/model/layers.0/input_layernorm/Cast_output_0: 3d4e6605
/model/language_model/model/layers.0/input_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3018_output: 3c810a14
/model/language_model/model/layers.0/input_layernorm/Pow_output_0: 3f22f688
/model/language_model/model/layers.0/input_layernorm/ReduceMean_output_0: 3d426d4a
/model/language_model/model/layers.0/input_layernorm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3020_output: 32074ebd
/model/language_model/model/layers.0/input_layernorm/Add_output_0: 3d426d4d
/model/language_model/model/layers.0/input_layernorm/Sqrt_output_0: 3ce6f01e
/model/language_model/model/layers.0/input_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3022_output: 3c010a14
/model/language_model/model/layers.0/input_layernorm/Div_output_0: 3e886234
/model/language_model/model/layers.0/input_layernorm/Mul_output_0: 3db5148f
/model/language_model/model/layers.0/input_layernorm/Cast_1_output_0: 3db5148f
backbone.model.language_model.model.layers.0.input_layernorm.weight_output: 3b6f24ca
ONNXTRT_Broadcast_3024_output: 3b6f24ca
/model/language_model/model/layers.0/input_layernorm/Mul_1_output_0: 3c56bb4f
/model/language_model/model/layers.6/self_attn/Concat_3_output_0: 3ddfdb1f
/model/language_model/model/layers.8/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.14/self_attn/k_norm/Div_output_0: 3ba482d8
ONNXTRT_Broadcast_4370_output: 3d2f6e0c
/model/language_model/model/layers.8/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.2/self_attn/Add_2_output_0: 448101dd
/model/language_model/model/layers.13/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.7/self_attn/k_norm/Mul_output_0: 3d5b4687
onnx::MatMul_9638_output: 3b05276f
ONNXTRT_Broadcast_3026_output: 3b05276f
/model/language_model/model/layers.0/self_attn/q_proj/MatMul_output_0: 3cfcfa71
ONNXTRT_Broadcast_3825_output: 3beaf102
/model/language_model/model/layers.13/self_attn/q_norm/Div_output_0: 3bb0339c
/model/language_model/model/layers.12/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.15/self_attn/Transpose_2_output_0: 3e974f2f
/model/language_model/model/layers.10/self_attn/Slice_2_output_0: 3f1a30c6
/model/language_model/model/layers.4/input_layernorm/Constant_output_0_output: 3c810a14
onnx::MatMul_9948_output: 3b1e55bb
/model/language_model/model/layers.7/mlp/act_fn/Sigmoid_output_0: 3c010a14
/model/language_model/model/layers.15/self_attn/k_norm/Cast_1_output_0: 3d5c84ff
/model/language_model/model/layers.6/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.6/Add_1_output_0: 40ff657e
/model/language_model/model/layers.2/self_attn/Slice_output_0: 3de0801d
/model/language_model/model/layers.14/input_layernorm/Sqrt_output_0: 40546269
/model/language_model/model/layers.2/self_attn/Reshape_4_output_0: 3f6cb2f2
/model/language_model/model/layers.3/self_attn/k_norm/Div_output_0: 3d30554e
/model/language_model/model/layers.12/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.11/self_attn/q_norm/Div_output_0: 3c178753
/model/language_model/model/layers.11/self_attn/Reshape_2_output_0: 3dc1336e
onnx::MatMul_9758_output: 3aed2830
onnx::MatMul_9893_output: 3ac3f6ee
/model/language_model/model/layers.9/self_attn/Add_1_output_0: 3e992ea2
/model/language_model/model/layers.0/self_attn/Reshape_output_0: 3cfcfa71
/model/language_model/model/layers.0/self_attn/q_norm/Cast_output_0: 3cfcfa71
/model/language_model/model/layers.0/self_attn/q_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3029_output: 3c810a14
/model/language_model/model/layers.0/self_attn/q_norm/Pow_output_0: 3db4470c
/model/language_model/model/layers.0/self_attn/q_norm/ReduceMean_output_0: 3baf8783
/model/language_model/model/layers.0/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3031_output: 32074ebd
/model/language_model/model/layers.0/self_attn/q_norm/Add_output_0: 3baf8787
/model/language_model/model/layers.0/self_attn/q_norm/Sqrt_output_0: 3c294d88
/model/language_model/model/layers.0/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3033_output: 3c010a14
/model/language_model/model/layers.0/self_attn/q_norm/Div_output_0: 3d5bcddf
/model/language_model/model/layers.0/self_attn/q_norm/Mul_output_0: 3d64b453
/model/language_model/model/layers.0/self_attn/q_norm/Cast_1_output_0: 3d64b453
backbone.model.language_model.model.layers.0.self_attn.q_norm.weight_output: 3cff27af
ONNXTRT_Broadcast_3035_output: 3cff27af
/model/language_model/model/layers.0/self_attn/q_norm/Mul_1_output_0: 3e2ce4ee
/model/language_model/model/layers.0/self_attn/Transpose_output_0: 3e2ce4ee
onnx::MatMul_9645_output: 3ad31224
ONNXTRT_Broadcast_3037_output: 3ad31224
/model/language_model/model/layers.0/self_attn/k_proj/MatMul_output_0: 3d11a65f
/model/language_model/model/layers.0/self_attn/Reshape_1_output_0: 3d11a65f
/model/language_model/model/layers.0/self_attn/k_norm/Cast_output_0: 3d11a65f
/model/language_model/model/layers.0/self_attn/k_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3040_output: 3c810a14
/model/language_model/model/layers.0/self_attn/k_norm/Pow_output_0: 3cc75c57
/model/language_model/model/layers.0/self_attn/k_norm/ReduceMean_output_0: 3c154de0
/model/language_model/model/layers.0/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3042_output: 32074ebd
/model/language_model/model/layers.0/self_attn/k_norm/Add_output_0: 3c154de3
/model/language_model/model/layers.0/self_attn/k_norm/Sqrt_output_0: 3c3ffcb0
/model/language_model/model/layers.0/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3044_output: 3c010a14
/model/language_model/model/layers.0/self_attn/k_norm/Div_output_0: 3d43cc59
/model/language_model/model/layers.0/self_attn/k_norm/Mul_output_0: 3d751ca9
/model/language_model/model/layers.0/self_attn/k_norm/Cast_1_output_0: 3d751ca9
backbone.model.language_model.model.layers.0.self_attn.k_norm.weight_output: 3d0aad5b
ONNXTRT_Broadcast_3046_output: 3d0aad5b
/model/language_model/model/layers.0/self_attn/k_norm/Mul_1_output_0: 3f1480aa
/model/language_model/model/layers.0/self_attn/Transpose_1_output_0: 3f1480aa
onnx::MatMul_9646_output: 3aab7245
ONNXTRT_Broadcast_3048_output: 3aab7245
/model/language_model/model/layers.0/self_attn/v_proj/MatMul_output_0: 3c4c6a97
/model/language_model/model/layers.0/self_attn/Reshape_2_output_0: 3c4c6a97
/model/language_model/model/layers.0/self_attn/Transpose_2_output_0: 3c4c6a97
/model/language_model/model/layers.8/self_attn/k_norm/ReduceMean_output_0: 3d85b2f3
/model/language_model/model/layers.0/self_attn/Unsqueeze_6_output_0: 3c010a14
/model/language_model/model/layers.13/input_layernorm/Mul_output_0: 3d008495
/model/language_model/model/layers.0/self_attn/Unsqueeze_7_output_0: 3c010a13
/model/language_model/model/layers.0/self_attn/Mul_output_0: 3e04c49c
/model/language_model/model/layers.8/mlp/down_proj/MatMul_output_0: 3cc6001a
/model/language_model/model/layers.1/Add_output_0: 3e0be544
/model/language_model/model/layers.9/self_attn/Transpose_2_output_0: 3d323dd6
/model/language_model/model/layers.5/self_attn/Mul_output_0: 3e13c82e
/model/language_model/model/layers.9/self_attn/Reshape_1_output_0: 3d924f89
/model/language_model/model/layers.11/self_attn/q_norm/Cast_1_output_0: 3d793a38
/model/language_model/model/layers.12/self_attn/k_norm/Div_output_0: 3c23cafc
ONNXTRT_Broadcast_7011_output: 32074ebd
/model/language_model/model/layers.5/self_attn/Transpose_2_output_0: 3cb925a3
/model/language_model/model/layers.7/input_layernorm/Sqrt_output_0: 40546c16
/model/language_model/model/layers.3/self_attn/Transpose_4_output_0: 3c068415
/model/language_model/model/layers.7/self_attn/k_norm/Pow_output_0: 3dbd2294
onnx::MatMul_9801_output: 3ad9e9d4
/model/language_model/model/layers.7/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.2/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.3/input_layernorm/Cast_1_output_0: 3dcf26ad
ONNXTRT_Broadcast_4072_output: 3c810a14
ONNXTRT_Broadcast_7049_output: 3c010a14
/model/language_model/model/layers.8/self_attn/k_norm/Add_output_0: 3d85b2f3
/model/language_model/model/layers.15/self_attn/v_proj/MatMul_output_0: 3e974f2f
/model/language_model/model/layers.1/self_attn/Expand_1_output_0: 3c0d858a
/model/language_model/model/layers.2/post_attention_layernorm/Sqrt_output_0: 3ca3ad50
ONNXTRT_Broadcast_3815_output: 3a68664d
/model/language_model/model/layers.10/mlp/Mul_output_0: 3daf2aa0
/model/language_model/model/layers.13/self_attn/k_norm/Add_output_0: 3ebe90f5
onnx::MatMul_10072_output: 3b18553a
ONNXTRT_Broadcast_6762_output: 3d165c38
/model/language_model/model/layers.7/post_attention_layernorm/Div_output_0: 3c2e5b2d
/model/language_model/model/layers.5/self_attn/Transpose_1_output_0: 3f3d78e5
/model/language_model/model/layers.2/self_attn/MatMul_output_0: 4013d4f5
/model/language_model/model/layers.11/post_attention_layernorm/Sqrt_output_0: 405466ed
/model/language_model/model/layers.12/mlp/Mul_output_0: 3d5259e7
/model/language_model/model/layers.12/self_attn/k_norm/Pow_output_0: 40af5281
/model/language_model/model/layers.11/input_layernorm/Add_output_0: 44aed32a
/model/language_model/model/layers.12/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.0/self_attn/Slice_output_0: 3e2ce4ee
/model/language_model/model/layers.15/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.6/input_layernorm/Add_output_0: 44aed4ea
/model/language_model/model/layers.9/self_attn/Reshape_2_output_0: 3d323dd6
ONNXTRT_Broadcast_5985_output: 3ac4bf1e
/model/language_model/model/layers.5/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.5/self_attn/k_norm/Cast_1_output_0: 3d5a827e
/model/language_model/model/layers.10/self_attn/Reshape_4_output_0: 3f0feba7
ONNXTRT_Broadcast_4381_output: 3d1f8bd8
/model/language_model/model/layers.5/self_attn/k_norm/Mul_output_0: 3d5a827e
/model/language_model/model/layers.11/input_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_4379_output: 3c010a14
/model/language_model/model/layers.12/self_attn/Expand_output_0: 3e9b2d41
ONNXTRT_Broadcast_6493_output: 3c010a14
/model/language_model/model/layers.5/self_attn/k_norm/Sqrt_output_0: 3c3e0ddd
/model/language_model/model/layers.2/self_attn/Softmax_output_0: 3a814285
/model/language_model/model/layers.5/self_attn/k_norm/ReduceMean_output_0: 3c52ef95
/model/language_model/model/layers.5/self_attn/k_norm/Pow_output_0: 3da3dcde
/model/language_model/model/layers.13/self_attn/Mul_3_output_0: 3d26deef
ONNXTRT_Broadcast_4375_output: 3c810a14
/model/language_model/model/layers.14/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.5/self_attn/k_norm/Cast_output_0: 3d26f3f3
ONNXTRT_Broadcast_4377_output: 32074ebd
/model/language_model/model/layers.5/self_attn/Reshape_1_output_0: 3d26f3f3
/model/language_model/model/layers.5/self_attn/k_proj/MatMul_output_0: 3d26f3f3
ONNXTRT_Broadcast_4372_output: 3aae98b1
/model/language_model/model/layers.5/self_attn/k_norm/Add_output_0: 3c52ef9a
/model/language_model/model/layers.5/self_attn/Transpose_output_0: 3e18b0ed
/model/language_model/model/layers.0/self_attn/Slice_1_output_0: 3dba8ec3
/model/language_model/model/layers.0/self_attn/Neg_output_0: 3dba8ec3
/model/language_model/model/layers.0/self_attn/Concat_3_output_0: 3e2ce4ee
/model/language_model/model/layers.0/self_attn/Mul_1_output_0: 3d67fc8a
/model/language_model/model/layers.0/self_attn/Add_output_0: 3e1e60a2
/model/language_model/model/layers.0/self_attn/Mul_2_output_0: 3f427b29
ONNXTRT_Broadcast_3538_output: 3c810a14
/model/language_model/model/layers.3/self_attn/k_norm/Pow_output_0: 3daff035
/model/language_model/model/layers.5/self_attn/q_norm/Pow_output_0: 3e2dbec8
/model/language_model/model/layers.7/mlp/up_proj/MatMul_output_0: 3d9b80c7
/model/language_model/model/layers.5/self_attn/q_norm/ReduceMean_output_0: 3c920e76
/model/language_model/model/layers.9/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.4/self_attn/Reshape_6_output_0: 3cbadcd9
ONNXTRT_Broadcast_4364_output: 3c810a14
/model/language_model/model/layers.3/self_attn/Reshape_4_output_0: 3f3dba3d
/model/language_model/model/layers.9/input_layernorm/Cast_output_0: 40ff7f7d
/model/language_model/model/layers.8/self_attn/Reshape_4_output_0: 3e6be427
/model/language_model/model/layers.8/mlp/act_fn/Sigmoid_output_0: 3bff8bb9
/model/language_model/model/layers.14/self_attn/k_norm/Cast_output_0: 3ed3dc33
/model/language_model/model/layers.10/self_attn/v_proj/MatMul_output_0: 3d9d216c
/model/language_model/model/layers.5/self_attn/q_norm/Mul_output_0: 3d773e89
/model/language_model/model/layers.5/self_attn/q_norm/Cast_1_output_0: 3d773e89
/model/language_model/model/layers.5/self_attn/q_norm/Div_output_0: 3d2018d2
/model/language_model/model/layers.8/post_attention_layernorm/Mul_output_0: 3dff0383
ONNXTRT_Broadcast_4368_output: 3c010a14
/model/language_model/model/layers.5/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.5/self_attn/q_norm/Mul_1_output_0: 3e18b0ed
/model/language_model/model/layers.5/self_attn/q_norm/Sqrt_output_0: 3c45b899
/model/language_model/model/layers.5/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.5/self_attn/q_norm/Cast_output_0: 3d62407f
/model/language_model/model/layers.5/self_attn/Reshape_output_0: 3d62407f
/model/language_model/model/layers.5/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.13/self_attn/Cast_5_output_0: 3a776ede
backbone.model.language_model.model.layers.14.post_attention_layernorm.weight_output: 3c46a0d2
/model/language_model/model/layers.8/self_attn/q_norm/Cast_1_output_0: 3d737355
ONNXTRT_Broadcast_6497_output: 3b3b9234
/model/language_model/model/layers.3/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.12/self_attn/Reshape_output_0: 3eb0fd1b
/model/language_model/model/layers.3/self_attn/Expand_1_output_0: 3cbdf29d
ONNXTRT_Broadcast_6479_output: 3c010a14
ONNXTRT_Broadcast_3542_output: 3c010a14
/model/language_model/model/layers.0/self_attn/Slice_2_output_0: 3e84a78d
/model/language_model/model/layers.9/self_attn/q_proj/MatMul_output_0: 3de848b0
onnx::MatMul_9986_output: 3b000d5b
/model/language_model/model/layers.8/self_attn/Transpose_3_output_0: 3e6be427
backbone.model.language_model.model.layers.5.self_attn.k_norm.weight_output: 3d1f8bd8
/model/language_model/model/layers.12/self_attn/Slice_1_output_0: 3d95b941
ONNXTRT_Broadcast_5438_output: 3d5ac316
/model/language_model/model/layers.14/self_attn/Reshape_output_0: 3ea7afbb
/model/language_model/model/layers.9/self_attn/q_norm/Add_output_0: 3da4278e
/model/language_model/model/layers.2/self_attn/Concat_3_output_0: 3e14fbb5
onnx::MatMul_10037_output: 3b56d0e2
/model/language_model/model/layers.2/self_attn/Neg_output_0: 3e14fbb5
/model/language_model/model/layers.3/self_attn/q_norm/Mul_output_0: 3d7d0422
/model/language_model/model/layers.1/mlp/act_fn/Sigmoid_output_0: 3be1e12b
/model/language_model/model/layers.9/post_attention_layernorm/Sqrt_output_0: 405467c8
/model/language_model/model/layers.8/self_attn/MatMul_output_0: 400e09be
/model/language_model/model/layers.12/input_layernorm/Add_output_0: 44aecf48
onnx::MatMul_10006_output: 3b3db0e2
/model/language_model/model/layers.11/Add_1_output_0: 429e0de4
/model/language_model/model/layers.13/mlp/act_fn/Sigmoid_output_0: 3c00a884
/model/language_model/model/layers.5/self_attn/q_proj/MatMul_output_0: 3d62407f
ONNXTRT_Broadcast_4361_output: 3aeb0d5b
/model/language_model/model/layers.7/self_attn/Slice_3_output_0: 3efc8893
onnx::MatMul_9793_output: 3aeb0d5b
ONNXTRT_Broadcast_3558_output: 3b41b1e4
/model/language_model/model/layers.8/self_attn/k_norm/Cast_1_output_0: 3d4f20ca
/model/language_model/model/layers.1/self_attn/Concat_4_output_0: 3f54d9a0
/model/language_model/model/layers.7/post_attention_layernorm/Mul_1_output_0: 3d57649b
/model/language_model/model/layers.0/self_attn/Slice_3_output_0: 3f3c29d2
/model/language_model/model/layers.0/self_attn/Neg_1_output_0: 3f3c29d2
/model/language_model/model/layers.0/self_attn/Concat_4_output_0: 3f1480aa
/model/language_model/model/layers.0/self_attn/Mul_3_output_0: 3dbc181e
/model/language_model/model/layers.0/self_attn/Add_1_output_0: 3f38e556
/model/language_model/model/layers.4/self_attn/Mul_3_output_0: 3de4723a
/model/language_model/model/layers.4/self_attn/Transpose_3_output_0: 3f641313
ONNXTRT_Broadcast_5696_output: 3b1e55bb
ONNXTRT_Broadcast_4610_output: 3c010a14
ONNXTRT_Broadcast_5167_output: 32074ebd
/model/language_model/model/layers.2/self_attn/Reshape_7_output_0: 3c190a1e
ONNXTRT_Broadcast_5182_output: 3cf10953
/model/language_model/model/layers.4/input_layernorm/Add_output_0: 44aed124
ONNXTRT_Broadcast_7051_output: 3e306bc8
/model/language_model/model/layers.7/self_attn/Reshape_6_output_0: 3d04058d
/model/language_model/model/layers.10/self_attn/Concat_4_output_0: 3f0fea9f
/model/language_model/model/layers.4/mlp/Mul_output_0: 3c25c9a1
/model/language_model/model/layers.7/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.9/input_layernorm/Add_output_0: 44aed46d
/model/language_model/model/layers.3/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3805_output: 3c810a14
/model/language_model/model/layers.4/post_attention_layernorm/Sqrt_output_0: 40546811
/model/language_model/model/layers.0/self_attn/Unsqueeze_12_output_0: 3f38e556
/model/language_model/model/layers.4/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.12/self_attn/Concat_4_output_0: 3e9b2fdf
/model/language_model/model/layers.11/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.2/self_attn/Reshape_6_output_0: 3c334541
ONNXTRT_Broadcast_5169_output: 3c010a14
/model/language_model/model/layers.10/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.4/self_attn/o_proj/MatMul_output_0: 3ca14fa3
/model/language_model/model/layers.13/input_layernorm/Sqrt_output_0: 40546623
/model/language_model/model/layers.4/self_attn/MatMul_output_0: 3fda1392
/model/language_model/model/layers.8/self_attn/Neg_output_0: 3e1de798
/model/language_model/model/layers.9/self_attn/Slice_3_output_0: 3e992e04
/model/language_model/model/layers.8/self_attn/Slice_2_output_0: 3e744b01
/model/language_model/model/layers.4/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.3/self_attn/q_norm/Sqrt_output_0: 3c57d258
backbone.model.language_model.model.layers.8.post_attention_layernorm.weight_output: 3bf51993
/model/language_model/model/layers.4/self_attn/Expand_1_output_0: 3cbadcd9
/model/language_model/model/layers.7/self_attn/Softmax_output_0: 3a7f7efe
/model/language_model/model/layers.11/self_attn/Mul_8_output_0: 3e9aee91
/model/language_model/model/layers.11/self_attn/Expand_output_0: 3e1ad653
/model/language_model/model/layers.8/self_attn/v_proj/MatMul_output_0: 3d8cc845
ONNXTRT_Broadcast_5150_output: 3ab2b367
/model/language_model/model/layers.12/self_attn/q_norm/Cast_1_output_0: 3d46b0ad
backbone.model.language_model.model.layers.10.self_attn.k_norm.weight_output: 3d258285
/model/language_model/model/layers.4/self_attn/Mul_8_output_0: 3e1a2fd7
/model/language_model/model/layers.2/self_attn/Cast_4_output_0: 3a814285
/model/language_model/model/layers.11/self_attn/k_norm/Mul_1_output_0: 3e1ad653
/model/language_model/model/layers.8/post_attention_layernorm/Pow_output_0: 49fb1a0d
/model/language_model/model/layers.11/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.4/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.12/self_attn/Softmax_output: 3a400000
/model/language_model/model/layers.13/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.12/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.0/self_attn/Expand_output_0: 3f38e556
/model/language_model/model/layers.14/post_attention_layernorm/Mul_1_output_0: 3d1e744b
/model/language_model/model/layers.8/self_attn/Concat_4_output_0: 3e6bdfa5
/model/language_model/model/layers.4/self_attn/Reshape_4_output_0: 3f641313
/model/language_model/model/layers.14/post_attention_layernorm/Sqrt_output_0: 4054651b
/model/language_model/model/layers.6/self_attn/Mul_8_output_0: 3e87d6f8
/model/language_model/model/layers.1/self_attn/Cast_4_output_0: 3a7f7efe
/model/language_model/model/layers.4/Add_output_0: 40ff52ee
/model/language_model/model/layers.7/self_attn/q_norm/Div_output_0: 3d0a68f3
/model/language_model/model/layers.11/self_attn/Slice_output_0: 3dacbd08
/model/language_model/model/layers.2/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.3/self_attn/q_norm/Pow_output_0: 3e01aec8
/model/language_model/model/layers.0/self_attn/Reshape_4_output_0: 3f38e556
ONNXTRT_Broadcast_7017_output: 3ab2c4ca
ONNXTRT_Broadcast_4080_output: 3ad7e9d4
/model/language_model/model/layers.10/self_attn/q_norm/Add_output_0: 3d605bcb
/model/language_model/model/layers.11/input_layernorm/Sqrt_output_0: 4054694e
/model/language_model/model/layers.15/self_attn/Slice_output_0: 3dc873a4
ONNXTRT_Broadcast_4911_output: 32074ebd
/model/language_model/model/layers.10/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.11/input_layernorm/Mul_1_output_0: 3dbebda3
/model/language_model/model/layers.12/mlp/down_proj/MatMul_output_0: 3e97b3d3
/model/language_model/model/layers.7/self_attn/Reshape_output_0: 3da1b8fd
/model/language_model/model/layers.9/input_layernorm/Div_output_0: 3c0c5b0e
/model/language_model/model/layers.13/mlp/act_fn/Mul_output_0: 3cc16dc7
/model/language_model/model/layers.4/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.14/self_attn/Softmax_output_0: 3a7f7efe
/model/language_model/model/layers.9/self_attn/Transpose_3_output_0: 3e992ea2
/model/language_model/model/layers.12/self_attn/Reshape_6_output_0: 3e54e1d5
/model/language_model/model/layers.14/self_attn/Slice_1_output_0: 3de41e48
/model/language_model/model/layers.0/self_attn/Unsqueeze_21_output_0: 3c4c6a97
ONNXTRT_Broadcast_4339_output: 3c810a14
/model/language_model/model/layers.12/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.10/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.5/post_attention_layernorm/Sqrt_output_0: 40546a59
backbone.model.language_model.model.layers.3.post_attention_layernorm.weight_output: 3c1c68d2
/model/language_model/model/layers.2/self_attn/Transpose_3_output_0: 3f6cb2f2
/model/language_model/model/layers.10/self_attn/Slice_1_output_0: 3e052631
/model/language_model/model/layers.15/self_attn/Reshape_output_0: 3f0973f4
ONNXTRT_Broadcast_5413_output: 3bf51993
backbone.model.language_model.model.layers.4.post_attention_layernorm.weight_output: 3c021e5d
/model/language_model/model/layers.8/self_attn/q_norm/ReduceMean_output_0: 3d24e343
onnx::MatMul_9731_output: 3b3c968d
backbone.model.language_model.model.layers.5.self_attn.q_norm.weight_output: 3d2f6e0c
/model/language_model/model/layers.4/self_attn/k_norm/Add_output_0: 3c542edf
/model/language_model/model/layers.2/post_attention_layernorm/Mul_1_output_0: 3dd9c822
/model/language_model/model/layers.12/input_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_4915_output: 3d7c5f3e
/model/language_model/model/layers.10/self_attn/Softmax_output_0: 3a7468d2
/model/language_model/model/layers.5/input_layernorm/Mul_output_0: 3e01fd36
/model/language_model/model/layers.8/self_attn/k_proj/MatMul_output_0: 3de64e9d
/model/language_model/model/layers.8/self_attn/Add_2_output_0: 448100bb
/model/language_model/model/layers.13/post_attention_layernorm/Div_output_0: 3b105e83
/model/language_model/model/layers.5/self_attn/Mul_8_output_0: 3e3b8a83
/model/language_model/model/layers.15/self_attn/Concat_4_output_0: 3ecddd3b
ONNXTRT_Broadcast_5429_output: 3b265dfc
/model/language_model/model/layers.14/self_attn/Transpose_output_0: 3e036a52
/model/language_model/model/layers.12/self_attn/Neg_output_0: 3d95b941
ONNXTRT_Broadcast_6784_output: 3d094a95
/model/language_model/model/layers.7/self_attn/Softmax_output: 3a7f7efe
/model/language_model/model/layers.10/self_attn/o_proj/MatMul_output_0: 3d159fef
ONNXTRT_Broadcast_5140_output: 3c810a14
/model/language_model/model/layers.2/mlp/act_fn/Mul_output_0: 3d8419f1
/model/language_model/model/layers.0/self_attn/Expand_1_output_0: 3c4c6a97
ONNXTRT_Broadcast_6756_output: 3c810a14
/model/language_model/model/layers.3/self_attn/q_norm/ReduceMean_output_0: 3cb46abb
/model/language_model/model/layers.15/self_attn/Expand_output_0: 3ecddb11
ONNXTRT_Broadcast_3821_output: 32074ebd
ONNXTRT_Broadcast_4028_output: 3a367841
/model/language_model/model/layers.10/self_attn/Reshape_2_output_0: 3d9d216c
/model/language_model/model/layers.5/post_attention_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.11/self_attn/q_norm/Mul_1_output_0: 3dadf90e
/model/language_model/model/layers.7/self_attn/Add_2_output_0: 44810044
/model/language_model/model/layers.15/input_layernorm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.15/self_attn/k_norm/Div_output_0: 3b3960f2
/model/language_model/model/layers.0/self_attn/Reshape_6_output_0: 3c4c6a97
/model/language_model/model/layers.0/self_attn/Transpose_3_output_0: 3f38e556
/model/language_model/model/layers.0/self_attn/MatMul_output_0: 4023de30
/model/language_model/model/layers.0/self_attn/Constant_56_output_0_output: 3a367841
ONNXTRT_Broadcast_3227_output: 3a367841
/model/language_model/model/layers.0/self_attn/Mul_8_output_0: 3e67b830
/model/language_model/model/layers.7/self_attn/k_norm/ReduceMean_output_0: 3c9b4164
/model/language_model/model/layers.14/post_attention_layernorm/Add_output_0: 44aecc41
/model/language_model/model/layers.10/self_attn/Transpose_2_output_0: 3d9d216c
/model/language_model/model/layers.3/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.8/post_attention_layernorm/ReduceMean_output_0: 44aed455
ONNXTRT_Broadcast_5411_output: 3c010a14
/model/language_model/model/layers.10/self_attn/q_norm/Pow_output_0: 3f500415
/model/language_model/model/layers.9/post_attention_layernorm/Div_output_0: 3c1d9873
/model/language_model/model/layers.7/mlp/act_fn/Mul_output_0: 3c92e14f
/model/language_model/model/layers.10/self_attn/Reshape_output_0: 3de37b2e
ONNXTRT_Broadcast_5710_output: 3c810a14
ONNXTRT_Broadcast_6767_output: 3c810a14
/model/language_model/model/layers.8/self_attn/Expand_output_0: 3e6be427
/model/language_model/model/layers.7/self_attn/Mul_8_output_0: 3e18cfc8
/model/language_model/model/layers.2/self_attn/Add_1_output_0: 3f6cb2f2
/model/language_model/model/layers.2/mlp/up_proj/MatMul_output_0: 3d9bf54c
/model/language_model/model/layers.4/self_attn/Expand_output_0: 3f641313
onnx::MatMul_10068_output: 3a998c99
/model/language_model/model/layers.13/self_attn/k_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.4/self_attn/Slice_2_output_0: 3ef55cd7
onnx::MatMul_9946_output: 3aafac38
/model/language_model/model/layers.6/input_layernorm/Div_output_0: 3c3e05ac
/model/language_model/model/layers.15/input_layernorm/Pow_output_0: 4942c704
/model/language_model/model/layers.15/self_attn/q_norm/Div_output_0: 3badef72
/model/language_model/model/layers.6/post_attention_layernorm/Add_output_0: 44aed7b3
/model/language_model/model/layers.13/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.14/input_layernorm/Mul_output_0: 3e1766e9
/model/language_model/model/layers.9/input_layernorm/Cast_1_output_0: 3e015180
/model/language_model/model/layers.13/self_attn/q_proj/MatMul_output_0: 3e71b327
/model/language_model/model/layers.5/self_attn/Mul_3_output_0: 3d62c5e8
/model/language_model/model/layers.3/mlp/gate_proj/MatMul_output_0: 3d9297dc
/model/language_model/model/layers.2/self_attn/Unsqueeze_10_output_0: 3f6cb2f2
/model/language_model/model/layers.14/post_attention_layernorm/Div_output_0: 3aea0184
ONNXTRT_Broadcast_5142_output: 32074ebd
/model/language_model/model/layers.0/self_attn/Slice_4_output_0: 4400f9f3
/model/language_model/model/layers.0/self_attn/Add_2_output_0: 4480fedc
/model/language_model/model/layers.0/self_attn/Softmax_output: 3a7c78f2
/model/language_model/model/layers.0/self_attn/Softmax_output_0: 3a7c78f2
ONNXTRT_Broadcast_6473_output: 3b56d0e2
/model/language_model/model/layers.14/input_layernorm/Pow_output_0: 49fb29a0
/model/language_model/model/layers.0/self_attn/Cast_4_output_0: 3a7c78f2
/model/language_model/model/layers.0/self_attn/Cast_5_output_0: 3a7c78f2
/model/language_model/model/layers.0/self_attn/MatMul_1_output_0: 3c13597d
/model/language_model/model/layers.0/self_attn/Transpose_4_output_0: 3c13597d
ONNXTRT_Broadcast_3843_output: 32074ebd
ONNXTRT_Broadcast_6782_output: 3c010a14
/model/language_model/model/layers.11/post_attention_layernorm/Mul_output_0: 3deabecc
/model/language_model/model/layers.10/self_attn/Mul_2_output_0: 3f0fe92c
ONNXTRT_Broadcast_7038_output: 3c010a14
/model/language_model/model/layers.11/input_layernorm/Div_output_0: 3b9d58e0
/model/language_model/model/layers.0/self_attn/Reshape_7_output_0: 3c13597d
onnx::MatMul_9665_output: 3b317b57
ONNXTRT_Broadcast_3269_output: 3b317b57
/model/language_model/model/layers.0/self_attn/o_proj/MatMul_output_0: 3ca7b3a3
/model/language_model/model/layers.0/Add_output_0: 3db351cb
/model/language_model/model/layers.0/post_attention_layernorm/Cast_output_0: 3db351cb
/model/language_model/model/layers.0/post_attention_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3271_output: 3c810a14
/model/language_model/model/layers.0/post_attention_layernorm/Pow_output_0: 3f1c29be
/model/language_model/model/layers.0/post_attention_layernorm/ReduceMean_output_0: 3d57419d
/model/language_model/model/layers.0/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3273_output: 32074ebd
/model/language_model/model/layers.0/post_attention_layernorm/Add_output_0: 3d5741a0
/model/language_model/model/layers.0/post_attention_layernorm/Sqrt_output_0: 3cc7c4c3
/model/language_model/model/layers.0/post_attention_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3275_output: 3c010a14
/model/language_model/model/layers.0/post_attention_layernorm/Div_output_0: 3d3114a3
/model/language_model/model/layers.0/post_attention_layernorm/Mul_output_0: 3dd02500
/model/language_model/model/layers.0/post_attention_layernorm/Cast_1_output_0: 3dd02500
backbone.model.language_model.model.layers.0.post_attention_layernorm.weight_output: 3b809c69
ONNXTRT_Broadcast_3277_output: 3b809c69
/model/language_model/model/layers.0/post_attention_layernorm/Mul_1_output_0: 3cb3a420
onnx::MatMul_9666_output: 3a9267d0
ONNXTRT_Broadcast_3279_output: 3a9267d0
/model/language_model/model/layers.0/mlp/gate_proj/MatMul_output_0: 3d089c7b
/model/language_model/model/layers.0/mlp/act_fn/Sigmoid_output_0: 3bfe7b58
/model/language_model/model/layers.0/mlp/act_fn/Mul_output_0: 3ca41154
onnx::MatMul_9667_output: 3a96764d
ONNXTRT_Broadcast_3281_output: 3a96764d
/model/language_model/model/layers.0/mlp/up_proj/MatMul_output_0: 3cbbe09f
/model/language_model/model/layers.0/mlp/Mul_output_0: 3c18a59b
onnx::MatMul_9668_output: 3a998c99
ONNXTRT_Broadcast_3283_output: 3a998c99
/model/language_model/model/layers.0/mlp/down_proj/MatMul_output_0: 3d824444
/model/language_model/model/layers.0/Add_1_output_0: 3e0275e1
/model/language_model/model/layers.1/input_layernorm/Cast_output_0: 3e0275e1
/model/language_model/model/layers.1/input_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3285_output: 3c810a14
/model/language_model/model/layers.1/input_layernorm/Pow_output_0: 3ec218a6
/model/language_model/model/layers.1/input_layernorm/ReduceMean_output_0: 3d5329cf
/model/language_model/model/layers.1/input_layernorm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3287_output: 32074ebd
/model/language_model/model/layers.1/input_layernorm/Add_output_0: 3d5329d3
/model/language_model/model/layers.1/input_layernorm/Sqrt_output_0: 3cac1198
/model/language_model/model/layers.1/input_layernorm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3289_output: 3c010a14
/model/language_model/model/layers.1/input_layernorm/Div_output_0: 3d17ccd0
/model/language_model/model/layers.1/input_layernorm/Mul_output_0: 3e01f1e9
/model/language_model/model/layers.1/input_layernorm/Cast_1_output_0: 3e01f1e9
backbone.model.language_model.model.layers.1.input_layernorm.weight_output: 3b1f60c2
ONNXTRT_Broadcast_3291_output: 3b1f60c2
/model/language_model/model/layers.1/input_layernorm/Mul_1_output_0: 3c9005ad
/model/language_model/model/layers.1/self_attn/Reshape_6_output_0: 3c0d858a
/model/language_model/model/layers.3/self_attn/q_norm/Add_output_0: 3cb46abe
/model/language_model/model/layers.12/self_attn/Transpose_2_output_0: 3e54e1d5
/model/language_model/model/layers.8/self_attn/Transpose_1_output_0: 3e6bdfa5
/model/language_model/model/layers.9/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.9/input_layernorm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3761_output: 3a367841
ONNXTRT_Broadcast_4099_output: 32074ebd
onnx::MatMul_9669_output: 3acbe9d4
ONNXTRT_Broadcast_3293_output: 3acbe9d4
/model/language_model/model/layers.1/self_attn/q_proj/MatMul_output_0: 3c984401
onnx::MatMul_10099_output: 3ab3d4ea
/model/language_model/model/layers.7/post_attention_layernorm/Cast_output_0: 40ff7334
/model/language_model/model/layers.2/post_attention_layernorm/Pow_output_0: 3fa6f58d
/model/language_model/model/layers.2/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/self_attn/k_norm/Constant_output_0_output: 3c810a14
onnx::MatMul_9729_output: 3a68664d
ONNXTRT_Broadcast_3819_output: 3c810a14
onnx::MatMul_9708_output: 3aa4756b
/model/language_model/model/layers.11/self_attn/Transpose_1_output_0: 3e1ad653
/model/language_model/model/layers.14/self_attn/Softmax_output: 3a7f7efe
/model/language_model/model/layers.12/self_attn/q_norm/Mul_output_0: 3d46b0ad
/model/language_model/model/layers.13/self_attn/k_norm/Mul_output_0: 3d420a80
ONNXTRT_Broadcast_4633_output: 32074ebd
backbone.model.language_model.model.layers.7.self_attn.q_norm.weight_output: 3d52b275
/model/language_model/model/layers.12/self_attn/Mul_1_output_0: 3d2fa717
ONNXTRT_Broadcast_4092_output: 3bc9c8b1
/model/language_model/model/layers.3/self_attn/k_norm/Mul_1_output_0: 3f3dbb6c
/model/language_model/model/layers.3/self_attn/Concat_3_output_0: 3dfbc01a
/model/language_model/model/layers.10/self_attn/q_proj/MatMul_output_0: 3de37b2e
/model/language_model/model/layers.2/self_attn/k_norm/Mul_output_0: 3d551c47
ONNXTRT_Broadcast_4608_output: 32074ebd
/model/language_model/model/layers.1/self_attn/Reshape_output_0: 3c984401
/model/language_model/model/layers.1/self_attn/q_norm/Cast_output_0: 3c984401
/model/language_model/model/layers.1/self_attn/q_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3296_output: 3c810a14
/model/language_model/model/layers.1/self_attn/q_norm/Pow_output_0: 3c853cd2
/model/language_model/model/layers.1/self_attn/q_norm/ReduceMean_output_0: 3b7e3770
/model/language_model/model/layers.1/self_attn/q_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3298_output: 32074ebd
/model/language_model/model/layers.1/self_attn/q_norm/Add_output_0: 3b7e3792
/model/language_model/model/layers.1/self_attn/q_norm/Sqrt_output_0: 3ba5fff0
/model/language_model/model/layers.1/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3300_output: 3c010a14
/model/language_model/model/layers.1/self_attn/q_norm/Div_output_0: 3d9d38ef
/model/language_model/model/layers.1/self_attn/q_norm/Mul_output_0: 3d69534d
/model/language_model/model/layers.1/self_attn/q_norm/Cast_1_output_0: 3d69534d
backbone.model.language_model.model.layers.1.self_attn.q_norm.weight_output: 3ccfb204
ONNXTRT_Broadcast_3302_output: 3ccfb204
/model/language_model/model/layers.1/self_attn/q_norm/Mul_1_output_0: 3dc17808
/model/language_model/model/layers.1/self_attn/Transpose_output_0: 3dc17808
onnx::MatMul_9676_output: 3b0e44a9
ONNXTRT_Broadcast_3304_output: 3b0e44a9
/model/language_model/model/layers.1/self_attn/k_proj/MatMul_output_0: 3c904176
/model/language_model/model/layers.1/self_attn/Reshape_1_output_0: 3c904176
/model/language_model/model/layers.1/self_attn/k_norm/Cast_output_0: 3c904176
/model/language_model/model/layers.1/self_attn/k_norm/Constant_output_0_output: 3c810a14
ONNXTRT_Broadcast_3307_output: 3c810a14
/model/language_model/model/layers.1/self_attn/k_norm/Pow_output_0: 3c609630
/model/language_model/model/layers.1/self_attn/k_norm/ReduceMean_output_0: 3b207b8f
/model/language_model/model/layers.1/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_3309_output: 32074ebd
/model/language_model/model/layers.1/self_attn/k_norm/Add_output_0: 3b207bac
/model/language_model/model/layers.1/self_attn/k_norm/Sqrt_output_0: 3b9510d3
/model/language_model/model/layers.1/self_attn/k_norm/Constant_3_output_0_output: 3c010a14
ONNXTRT_Broadcast_3311_output: 3c010a14
/model/language_model/model/layers.1/self_attn/k_norm/Div_output_0: 3d55795e
/model/language_model/model/layers.1/self_attn/k_norm/Mul_output_0: 3d41e968
/model/language_model/model/layers.1/self_attn/k_norm/Cast_1_output_0: 3d41e968
backbone.model.language_model.model.layers.1.self_attn.k_norm.weight_output: 3d52ffbf
ONNXTRT_Broadcast_3313_output: 3d52ffbf
/model/language_model/model/layers.1/self_attn/k_norm/Mul_1_output_0: 3f54d9a0
/model/language_model/model/layers.1/self_attn/Transpose_1_output_0: 3f54d9a0
onnx::MatMul_9677_output: 3aab6e5d
ONNXTRT_Broadcast_3315_output: 3aab6e5d
/model/language_model/model/layers.1/self_attn/v_proj/MatMul_output_0: 3c0d858a
/model/language_model/model/layers.1/self_attn/Reshape_2_output_0: 3c0d858a
/model/language_model/model/layers.1/self_attn/Transpose_2_output_0: 3c0d858a
/model/language_model/model/layers.1/self_attn/Mul_output_0: 3db0d91d
/model/language_model/model/layers.9/self_attn/Reshape_7_output_0: 3c97f057
/model/language_model/model/layers.3/self_attn/Cast_5_output_0: 3a24c993
/model/language_model/model/layers.3/post_attention_layernorm/Pow_output_0: 49fabfcc
/model/language_model/model/layers.14/mlp/gate_proj/MatMul_output_0: 3df303d8
/model/language_model/model/layers.11/self_attn/MatMul_1_output_0: 3d10e158
/model/language_model/model/layers.12/post_attention_layernorm/Cast_output_0: 40ff84c6
/model/language_model/model/layers.4/self_attn/k_norm/Cast_1_output_0: 3d40042e
/model/language_model/model/layers.4/input_layernorm/Cast_1_output_0: 3df7e714
/model/language_model/model/layers.14/self_attn/Transpose_4_output_0: 3dccc1ae
/model/language_model/model/layers.10/self_attn/k_norm/Div_output_0: 3c76e8e8
/model/language_model/model/layers.2/self_attn/Mul_1_output_0: 3d367664
/model/language_model/model/layers.9/self_attn/Transpose_4_output_0: 3c97f057
/model/language_model/model/layers.3/self_attn/v_proj/MatMul_output_0: 3cbdf29d
/model/language_model/model/layers.13/self_attn/k_norm/Cast_output_0: 3eb41665
/model/language_model/model/layers.13/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.8/self_attn/Reshape_6_output_0: 3d8cc845
ONNXTRT_Broadcast_5156_output: 32074ebd
/model/language_model/model/layers.8/self_attn/Transpose_4_output_0: 3c2e9f4e
/model/language_model/model/layers.15/self_attn/q_norm/Mul_output_0: 3d8924d4
/model/language_model/model/layers.11/self_attn/v_proj/MatMul_output_0: 3dc1336e
/model/language_model/model/layers.13/self_attn/q_norm/Cast_output_0: 3e71b327
ONNXTRT_Broadcast_6758_output: 32074ebd
/model/language_model/model/layers.15/input_layernorm/Cast_output_0: 429e818f
/model/language_model/model/layers.9/self_attn/Reshape_4_output_0: 3e992ea2
/model/language_model/model/layers.12/self_attn/Softmax_output_0: 3a400000
/model/language_model/model/layers.4/input_layernorm/Cast_output_0: 40ff518d
/model/language_model/model/layers.3/self_attn/Cast_4_output_0: 3a24c993
/model/language_model/model/layers.11/input_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.2/input_layernorm/Mul_1_output_0: 3c90c143
/model/language_model/model/layers.7/post_attention_layernorm/Add_output_0: 44aed4e1
/model/language_model/model/layers.4/input_layernorm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.4/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.2/self_attn/Unsqueeze_19_output_0: 3c334541
/model/language_model/model/layers.14/self_attn/q_norm/Constant_3_output_0_output: 3c010a14
/model/language_model/model/layers.3/post_attention_layernorm/Cast_1_output_0: 3dce8f79
/model/language_model/model/layers.1/self_attn/Slice_output_0: 3ddd959a
/model/language_model/model/layers.11/self_attn/Reshape_output_0: 3e5419ec
ONNXTRT_Broadcast_4353_output: 3c810a14
ONNXTRT_Broadcast_6754_output: 3aa4f0e2
ONNXTRT_Broadcast_6760_output: 3c010a14
/model/language_model/model/layers.8/self_attn/q_norm/Constant_output_0_output: 3c810a14
/model/language_model/model/layers.15/self_attn/Transpose_1_output_0: 3ecddd3b
/model/language_model/model/layers.10/mlp/act_fn/Mul_output_0: 3cd6678a
backbone.model.language_model.model.layers.11.self_attn.q_norm.weight_output: 3cb78387
/model/language_model/model/layers.4/self_attn/Mul_2_output_0: 3f5052e9
/model/language_model/model/layers.3/self_attn/k_norm/Cast_1_output_0: 3d5df1d5
/model/language_model/model/layers.4/self_attn/Add_output_0: 3e050be9
/model/language_model/model/layers.4/self_attn/Concat_3_output_0: 3e050bfe
/model/language_model/model/layers.15/self_attn/q_norm/Add_output_0: 4012d946
/model/language_model/model/layers.4/self_attn/Neg_output_0: 3e05a6b8
/model/language_model/model/layers.4/self_attn/Slice_1_output_0: 3e05a6b8
/model/language_model/model/layers.15/self_attn/Reshape_4_output_0: 3ecddb11
/model/language_model/model/layers.6/self_attn/Slice_3_output_0: 3f302559
/model/language_model/model/layers.10/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.11/self_attn/k_norm/Constant_2_output_0_output: 32074ebd
ONNXTRT_Broadcast_7040_output: 3cae70b1
ONNXTRT_Broadcast_6212_output: 3c010a14
ONNXTRT_Broadcast_5427_output: 3c7513e8
/model/language_model/model/layers.9/self_attn/o_proj/MatMul_output_0: 3d0ca17a
/model/language_model/model/layers.11/self_attn/Constant_54_output_0_output: 3a367841
/model/language_model/model/layers.10/self_attn/k_norm/Cast_output_0: 3dfee05a
backbone.model.language_model.model.layers.11.post_attention_layernorm.weight_output: 3c257163
/model/language_model/model/layers.7/self_attn/q_norm/Pow_output_0: 3eb0a0c9
/model/language_model/model/layers.1/self_attn/Slice_1_output_0: 3da3389a
/model/language_model/model/layers.1/self_attn/Neg_output_0: 3da3389a
/model/language_model/model/layers.1/self_attn/Concat_3_output_0: 3dc17808
/model/language_model/model/layers.1/self_attn/Mul_1_output_0: 3d275080
/model/language_model/model/layers.1/self_attn/Add_output_0: 3dc35538
/model/language_model/model/layers.1/self_attn/Mul_2_output_0: 3f4291f7
/model/language_model/model/layers.4/self_attn/Slice_output_0: 3d8b121d
/model/language_model/model/layers.12/post_attention_layernorm/Constant_2_output_0_output: 32074ebd
/model/language_model/model/layers.3/self_attn/Concat_4_output_0: 3f3dbb6c
ONNXTRT_Broadcast_6786_output: 3acdbfaf
/model/language_model/model/layers.10/self_attn/MatMul_1_output_0: 3cc72ccc
ONNXTRT_Broadcast_5686_output: 3a7bc993
/model/language_model/model/layers.6/self_attn/Add_1_output_0: 3f246ce7
/model/language_model/model/layers.7/self_attn/Transpose_3_output_0: 3ef3d49c
/model/language_model/model/layers.14/self_attn/Mul_output_0: 3db4e989
ONNXTRT_Broadcast_7013_output: 3c010a14
/model/language_model/model/layers.8/mlp/up_proj/MatMul_output_0: 3d3bed14
ONNXTRT_Broadcast_3556_output: 3c010a14
/model/language_model/model/layers.8/self_attn/Unsqueeze_10_output_0: 3e6be427
ONNXTRT_Broadcast_5407_output: 3c810a14
/model/language_model/model/layers.3/self_attn/Add_2_output_0: 4481020c
/model/language_model/model/layers.2/self_attn/Expand_1_output_0: 3c334541
/model/language_model/model/layers.3/mlp/act_fn/Mul_output_0: 3c1ef1b9
onnx::MatMul_9915_output: 3aa58f9f
/model/language_model/model/layers.14/self_attn/q_norm/Sqrt_output_0: 3da0494c
/model/language_model/model/layers.3/self_attn/Softmax_output_0: 3a24c993
/model/language_model/model/layers.3/input_layernorm/Add_output_0: 44aed0d3
/model/language_model/model/layers.3/post_attention_layernorm/Div_output_0: 3c5b6be8
